<h1 id="chapter-7-memory---the-agents-notebook">Chapter 7: Memory - The Agent’s Notebook</h1>

<p>In <a href="06_chatcompletioncontext.md">Chapter 6: ChatCompletionContext</a>, we saw how agents manage the <em>short-term</em> history of a single conversation before talking to an LLM. It’s like remembering what was just said in the last few minutes.</p>

<p>But what if an agent needs to remember things for much longer, across <em>multiple</em> conversations or tasks? For example, imagine an assistant agent that learns your preferences:</p>
<ul>
  <li>You tell it: “Please always write emails in a formal style for me.”</li>
  <li>Weeks later, you ask it to draft a new email.</li>
</ul>

<p>How does it remember that preference? The short-term <code class="language-plaintext highlighter-rouge">ChatCompletionContext</code> might have forgotten the earlier instruction, especially if using a strategy like <code class="language-plaintext highlighter-rouge">BufferedChatCompletionContext</code>. The agent needs a <strong>long-term memory</strong>.</p>

<p>This is where the <strong><code class="language-plaintext highlighter-rouge">Memory</code></strong> abstraction comes in. Think of it as the agent’s <strong>long-term notebook or database</strong>. While <code class="language-plaintext highlighter-rouge">ChatCompletionContext</code> is the scratchpad for the current chat, <code class="language-plaintext highlighter-rouge">Memory</code> holds persistent information the agent can add to or look up later.</p>

<h2 id="motivation-remembering-across-conversations">Motivation: Remembering Across Conversations</h2>

<p>Our goal is to give an agent the ability to store a piece of information (like a user preference) and retrieve it later to influence its behavior, even in a completely new conversation. <code class="language-plaintext highlighter-rouge">Memory</code> provides the mechanism for this long-term storage and retrieval.</p>

<h2 id="key-concepts-how-the-notebook-works">Key Concepts: How the Notebook Works</h2>

<ol>
  <li><strong>What it Stores (<code class="language-plaintext highlighter-rouge">MemoryContent</code>):</strong> Agents can store various types of information in their memory. This could be:
    <ul>
      <li>Plain text notes (<code class="language-plaintext highlighter-rouge">text/plain</code>)</li>
      <li>Structured data like JSON (<code class="language-plaintext highlighter-rouge">application/json</code>)</li>
      <li>Even images (<code class="language-plaintext highlighter-rouge">image/*</code>)
Each piece of information is wrapped in a <code class="language-plaintext highlighter-rouge">MemoryContent</code> object, which includes the data itself, its type (<code class="language-plaintext highlighter-rouge">mime_type</code>), and optional descriptive <code class="language-plaintext highlighter-rouge">metadata</code>.</li>
    </ul>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># From: memory/_base_memory.py (Simplified Concept)
</span><span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Union</span>

<span class="c1"># Represents one entry in the memory notebook
</span><span class="k">class</span> <span class="nc">MemoryContent</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">content</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="c1"># The actual data
</span>    <span class="n">mime_type</span><span class="p">:</span> <span class="nb">str</span> <span class="c1"># What kind of data (e.g., "text/plain")
</span>    <span class="n">metadata</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="bp">None</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># Extra info (optional)
</span></code></pre></div>    </div>
    <p>This standard format helps manage different kinds of memories.</p>
  </li>
  <li>
    <p><strong>Adding to Memory (<code class="language-plaintext highlighter-rouge">add</code>):</strong> When an agent learns something important it wants to remember long-term (like the user’s preferred style), it uses the <code class="language-plaintext highlighter-rouge">memory.add(content)</code> method. This is like writing a new entry in the notebook.</p>
  </li>
  <li>
    <p><strong>Querying Memory (<code class="language-plaintext highlighter-rouge">query</code>):</strong> When an agent needs to recall information, it can use <code class="language-plaintext highlighter-rouge">memory.query(query_text)</code>. This is like searching the notebook for relevant entries. How the search works depends on the specific memory implementation (it could be a simple text match, or a sophisticated vector search in more advanced memories).</p>
  </li>
  <li><strong>Updating Chat Context (<code class="language-plaintext highlighter-rouge">update_context</code>):</strong> This is a crucial link! Before an agent talks to the LLM (using the <code class="language-plaintext highlighter-rouge">ChatCompletionClient</code> from <a href="05_chatcompletionclient.md">Chapter 5</a>), it can use <code class="language-plaintext highlighter-rouge">memory.update_context(chat_context)</code> method. This method:
    <ul>
      <li>Looks at the current conversation (<code class="language-plaintext highlighter-rouge">chat_context</code>).</li>
      <li>Queries the long-term memory (<code class="language-plaintext highlighter-rouge">Memory</code>) for relevant information.</li>
      <li>Injects the retrieved memories <em>into</em> the <code class="language-plaintext highlighter-rouge">chat_context</code>, often as a <code class="language-plaintext highlighter-rouge">SystemMessage</code>.
This way, the LLM gets the benefit of the long-term memory <em>in addition</em> to the short-term conversation history, right before generating its response.</li>
    </ul>
  </li>
  <li><strong>Different Memory Implementations:</strong> Just like there are different <code class="language-plaintext highlighter-rouge">ChatCompletionContext</code> strategies, there can be different <code class="language-plaintext highlighter-rouge">Memory</code> implementations:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">ListMemory</code>: A very simple memory that stores everything in a Python list (like a simple chronological notebook).</li>
      <li><em>Future Possibilities</em>: More advanced implementations could use databases or vector stores for more efficient storage and retrieval of vast amounts of information.</li>
    </ul>
  </li>
</ol>

<h2 id="use-case-example-remembering-user-preferences-with-listmemory">Use Case Example: Remembering User Preferences with <code class="language-plaintext highlighter-rouge">ListMemory</code></h2>

<p>Let’s implement our user preference use case using the simple <code class="language-plaintext highlighter-rouge">ListMemory</code>.</p>

<p><strong>Goal:</strong></p>
<ol>
  <li>Create a <code class="language-plaintext highlighter-rouge">ListMemory</code>.</li>
  <li>Add a user preference (“formal style”) to it.</li>
  <li>Start a <em>new</em> chat context.</li>
  <li>Use <code class="language-plaintext highlighter-rouge">update_context</code> to inject the preference into the new chat context.</li>
  <li>Show how the chat context looks <em>before</em> being sent to the LLM.</li>
</ol>

<p><strong>Step 1: Create the Memory</strong></p>

<p>We’ll use <code class="language-plaintext highlighter-rouge">ListMemory</code>, the simplest implementation provided by AutoGen Core.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># File: create_list_memory.py
</span><span class="kn">from</span> <span class="nn">autogen_core.memory</span> <span class="kn">import</span> <span class="n">ListMemory</span>

<span class="c1"># Create a simple list-based memory instance
</span><span class="n">user_prefs_memory</span> <span class="o">=</span> <span class="n">ListMemory</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">"user_preferences"</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Created memory: </span><span class="si">{</span><span class="n">user_prefs_memory</span><span class="p">.</span><span class="n">name</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Initial content: </span><span class="si">{</span><span class="n">user_prefs_memory</span><span class="p">.</span><span class="n">content</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="c1"># Output:
# Created memory: user_preferences
# Initial content: []
</span></code></pre></div></div>
<p>We have an empty memory notebook named “user_preferences”.</p>

<p><strong>Step 2: Add the Preference</strong></p>

<p>Let’s add the user’s preference as a piece of text memory.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># File: add_preference.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">autogen_core.memory</span> <span class="kn">import</span> <span class="n">MemoryContent</span>
<span class="c1"># Assume user_prefs_memory exists from the previous step
</span>
<span class="c1"># Define the preference as MemoryContent
</span><span class="n">preference</span> <span class="o">=</span> <span class="n">MemoryContent</span><span class="p">(</span>
    <span class="n">content</span><span class="o">=</span><span class="s">"User prefers all communication to be written in a formal style."</span><span class="p">,</span>
    <span class="n">mime_type</span><span class="o">=</span><span class="s">"text/plain"</span><span class="p">,</span> <span class="c1"># It's just text
</span>    <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s">"source"</span><span class="p">:</span> <span class="s">"user_instruction_conversation_1"</span><span class="p">}</span> <span class="c1"># Optional info
</span><span class="p">)</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">add_to_memory</span><span class="p">():</span>
    <span class="c1"># Add the content to our memory instance
</span>    <span class="k">await</span> <span class="n">user_prefs_memory</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">preference</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Memory content after adding: </span><span class="si">{</span><span class="n">user_prefs_memory</span><span class="p">.</span><span class="n">content</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">add_to_memory</span><span class="p">())</span>
<span class="c1"># Output (will show the MemoryContent object):
# Memory content after adding: [MemoryContent(content='User prefers...', mime_type='text/plain', metadata={'source': '...'})]
</span></code></pre></div></div>
<p>We’ve successfully written the preference into our <code class="language-plaintext highlighter-rouge">ListMemory</code> notebook.</p>

<p><strong>Step 3: Start a New Chat Context</strong></p>

<p>Imagine time passes, and the user starts a new conversation asking for an email draft. We create a fresh <code class="language-plaintext highlighter-rouge">ChatCompletionContext</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># File: start_new_chat.py
</span><span class="kn">from</span> <span class="nn">autogen_core.model_context</span> <span class="kn">import</span> <span class="n">UnboundedChatCompletionContext</span>
<span class="kn">from</span> <span class="nn">autogen_core.models</span> <span class="kn">import</span> <span class="n">UserMessage</span>

<span class="c1"># Start a new, empty chat context for a new task
</span><span class="n">new_chat_context</span> <span class="o">=</span> <span class="n">UnboundedChatCompletionContext</span><span class="p">()</span>

<span class="c1"># Add the user's new request
</span><span class="n">new_request</span> <span class="o">=</span> <span class="n">UserMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s">"Draft an email to the team about the Q3 results."</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="s">"User"</span><span class="p">)</span>
<span class="c1"># await new_chat_context.add_message(new_request) # In a real app, add the request
</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Created a new, empty chat context."</span><span class="p">)</span>
<span class="c1"># Output: Created a new, empty chat context.
</span></code></pre></div></div>
<p>This context currently <em>doesn’t</em> know about the “formal style” preference stored in our long-term memory.</p>

<p><strong>Step 4: Inject Memory into Chat Context</strong></p>

<p>Before sending the <code class="language-plaintext highlighter-rouge">new_chat_context</code> to the LLM, we use <code class="language-plaintext highlighter-rouge">update_context</code> to bring in relevant long-term memories.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># File: update_chat_with_memory.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="c1"># Assume user_prefs_memory exists (with the preference added)
# Assume new_chat_context exists (empty or with just the new request)
# Assume new_request exists
</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># --- This is where Memory connects to Chat Context ---
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"Updating chat context with memory..."</span><span class="p">)</span>
    <span class="n">update_result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">user_prefs_memory</span><span class="p">.</span><span class="n">update_context</span><span class="p">(</span><span class="n">new_chat_context</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Memories injected: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">update_result</span><span class="p">.</span><span class="n">memories</span><span class="p">.</span><span class="n">results</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

    <span class="c1"># Now let's add the actual user request for this task
</span>    <span class="k">await</span> <span class="n">new_chat_context</span><span class="p">.</span><span class="n">add_message</span><span class="p">(</span><span class="n">new_request</span><span class="p">)</span>

    <span class="c1"># See what messages are now in the context
</span>    <span class="n">messages_for_llm</span> <span class="o">=</span> <span class="k">await</span> <span class="n">new_chat_context</span><span class="p">.</span><span class="n">get_messages</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Messages to be sent to LLM:"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="n">messages_for_llm</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"- [</span><span class="si">{</span><span class="n">msg</span><span class="p">.</span><span class="nb">type</span><span class="si">}</span><span class="s">]: </span><span class="si">{</span><span class="n">msg</span><span class="p">.</span><span class="n">content</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div>

<p><strong>Expected Output:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Updating chat context with memory...
Memories injected: 1

Messages to be sent to LLM:
- [SystemMessage]:
Relevant memory content (in chronological order):
1. User prefers all communication to be written in a formal style.

- [UserMessage]: Draft an email to the team about the Q3 results.
</code></pre></div></div>
<p>Look! The <code class="language-plaintext highlighter-rouge">ListMemory.update_context</code> method automatically queried the memory (in this simple case, it just takes <em>all</em> entries) and added a <code class="language-plaintext highlighter-rouge">SystemMessage</code> to the <code class="language-plaintext highlighter-rouge">new_chat_context</code>. This message explicitly tells the LLM about the stored preference <em>before</em> it sees the user’s request to draft the email.</p>

<p><strong>Step 5: (Conceptual) Sending to LLM</strong></p>

<p>Now, if we were to send <code class="language-plaintext highlighter-rouge">messages_for_llm</code> to the <code class="language-plaintext highlighter-rouge">ChatCompletionClient</code> (Chapter 5):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Conceptual code - Requires a configured client
# response = await llm_client.create(messages=messages_for_llm)
</span></code></pre></div></div>
<p>The LLM would receive both the instruction about the formal style preference (from Memory) and the request to draft the email. It’s much more likely to follow the preference now!</p>

<p><strong>Step 6: Direct Query (Optional)</strong></p>

<p>We can also directly query the memory if needed, without involving a chat context.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># File: query_memory.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="c1"># Assume user_prefs_memory exists
</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># Query the memory (ListMemory returns all items regardless of query text)
</span>    <span class="n">query_result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">user_prefs_memory</span><span class="p">.</span><span class="n">query</span><span class="p">(</span><span class="s">"style preference"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Direct query result:"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">query_result</span><span class="p">.</span><span class="n">results</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"- Content: </span><span class="si">{</span><span class="n">item</span><span class="p">.</span><span class="n">content</span><span class="si">}</span><span class="s">, Type: </span><span class="si">{</span><span class="n">item</span><span class="p">.</span><span class="n">mime_type</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
<span class="c1"># Output:
# Direct query result:
# - Content: User prefers all communication to be written in a formal style., Type: text/plain
</span></code></pre></div></div>
<p>This shows how an agent could specifically look things up in its notebook.</p>

<h2 id="under-the-hood-how-listmemory-injects-context">Under the Hood: How <code class="language-plaintext highlighter-rouge">ListMemory</code> Injects Context</h2>

<p>Let’s trace the <code class="language-plaintext highlighter-rouge">update_context</code> call for <code class="language-plaintext highlighter-rouge">ListMemory</code>.</p>

<p><strong>Conceptual Flow:</strong></p>

<pre><code class="language-mermaid">sequenceDiagram
    participant AgentLogic as Agent Logic
    participant ListMem as ListMemory
    participant InternalList as Memory's Internal List
    participant ChatCtx as ChatCompletionContext

    AgentLogic-&gt;&gt;+ListMem: update_context(chat_context)
    ListMem-&gt;&gt;+InternalList: Get all stored MemoryContent items
    InternalList--&gt;&gt;-ListMem: Return list of [pref_content]
    alt Memory list is NOT empty
        ListMem-&gt;&gt;ListMem: Format memories into a single string (e.g., "1. pref_content")
        ListMem-&gt;&gt;ListMem: Create SystemMessage with formatted string
        ListMem-&gt;&gt;+ChatCtx: add_message(SystemMessage)
        ChatCtx--&gt;&gt;-ListMem: Context updated
    end
    ListMem-&gt;&gt;ListMem: Create UpdateContextResult(memories=[pref_content])
    ListMem--&gt;&gt;-AgentLogic: Return UpdateContextResult
</code></pre>

<ol>
  <li>The agent calls <code class="language-plaintext highlighter-rouge">user_prefs_memory.update_context(new_chat_context)</code>.</li>
  <li>The <code class="language-plaintext highlighter-rouge">ListMemory</code> instance accesses its internal <code class="language-plaintext highlighter-rouge">_contents</code> list.</li>
  <li>It checks if the list is empty. If not:</li>
  <li>It iterates through the <code class="language-plaintext highlighter-rouge">MemoryContent</code> items in the list.</li>
  <li>It formats them into a numbered string (like “Relevant memory content…\n1. Item 1\n2. Item 2…”).</li>
  <li>It creates a single <code class="language-plaintext highlighter-rouge">SystemMessage</code> containing this formatted string.</li>
  <li>It calls <code class="language-plaintext highlighter-rouge">new_chat_context.add_message()</code> to add this <code class="language-plaintext highlighter-rouge">SystemMessage</code> to the chat history that will be sent to the LLM.</li>
  <li>It returns an <code class="language-plaintext highlighter-rouge">UpdateContextResult</code> containing the list of memories it just processed.</li>
</ol>

<p><strong>Code Glimpse:</strong></p>

<ul>
  <li>
    <p><strong><code class="language-plaintext highlighter-rouge">Memory</code> Protocol (<code class="language-plaintext highlighter-rouge">memory/_base_memory.py</code>):</strong> Defines the required methods for any memory implementation.</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># From: memory/_base_memory.py (Simplified ABC)
</span><span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="c1"># ... other imports: MemoryContent, MemoryQueryResult, UpdateContextResult, ChatCompletionContext
</span>
<span class="k">class</span> <span class="nc">Memory</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="n">component_type</span> <span class="o">=</span> <span class="s">"memory"</span>

    <span class="o">@</span><span class="n">abstractmethod</span>
    <span class="k">async</span> <span class="k">def</span> <span class="nf">update_context</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_context</span><span class="p">:</span> <span class="n">ChatCompletionContext</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">UpdateContextResult</span><span class="p">:</span> <span class="p">...</span>

    <span class="o">@</span><span class="n">abstractmethod</span>
    <span class="k">async</span> <span class="k">def</span> <span class="nf">query</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">MemoryContent</span><span class="p">,</span> <span class="p">...)</span> <span class="o">-&gt;</span> <span class="n">MemoryQueryResult</span><span class="p">:</span> <span class="p">...</span>

    <span class="o">@</span><span class="n">abstractmethod</span>
    <span class="k">async</span> <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">content</span><span class="p">:</span> <span class="n">MemoryContent</span><span class="p">,</span> <span class="p">...)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span> <span class="p">...</span>

    <span class="o">@</span><span class="n">abstractmethod</span>
    <span class="k">async</span> <span class="k">def</span> <span class="nf">clear</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span> <span class="p">...</span>

    <span class="o">@</span><span class="n">abstractmethod</span>
    <span class="k">async</span> <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span> <span class="p">...</span>
</code></pre></div>    </div>
    <p>Any class wanting to act as Memory must provide these methods.</p>
  </li>
  <li>
    <p><strong><code class="language-plaintext highlighter-rouge">ListMemory</code> Implementation (<code class="language-plaintext highlighter-rouge">memory/_list_memory.py</code>):</strong></p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># From: memory/_list_memory.py (Simplified)
</span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="c1"># ... other imports: Memory, MemoryContent, ..., SystemMessage, ChatCompletionContext
</span>
<span class="k">class</span> <span class="nc">ListMemory</span><span class="p">(</span><span class="n">Memory</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="p">...,</span> <span class="n">memory_contents</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">MemoryContent</span><span class="p">]</span> <span class="o">|</span> <span class="bp">None</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="c1"># Stores memory items in a simple list
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">_contents</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">MemoryContent</span><span class="p">]</span> <span class="o">=</span> <span class="n">memory_contents</span> <span class="ow">or</span> <span class="p">[]</span>

    <span class="k">async</span> <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">content</span><span class="p">:</span> <span class="n">MemoryContent</span><span class="p">,</span> <span class="p">...)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="s">"""Add new content to the internal list."""</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_contents</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>

    <span class="k">async</span> <span class="k">def</span> <span class="nf">query</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">MemoryContent</span> <span class="o">=</span> <span class="s">""</span><span class="p">,</span> <span class="p">...)</span> <span class="o">-&gt;</span> <span class="n">MemoryQueryResult</span><span class="p">:</span>
        <span class="s">"""Return all memories, ignoring the query."""</span>
        <span class="c1"># Simple implementation: just return everything
</span>        <span class="k">return</span> <span class="n">MemoryQueryResult</span><span class="p">(</span><span class="n">results</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">_contents</span><span class="p">)</span>

    <span class="k">async</span> <span class="k">def</span> <span class="nf">update_context</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_context</span><span class="p">:</span> <span class="n">ChatCompletionContext</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">UpdateContextResult</span><span class="p">:</span>
        <span class="s">"""Add all memories as a SystemMessage to the chat context."""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">_contents</span><span class="p">:</span> <span class="c1"># Do nothing if memory is empty
</span>            <span class="k">return</span> <span class="n">UpdateContextResult</span><span class="p">(</span><span class="n">memories</span><span class="o">=</span><span class="n">MemoryQueryResult</span><span class="p">(</span><span class="n">results</span><span class="o">=</span><span class="p">[]))</span>

        <span class="c1"># Format all memories into a numbered list string
</span>        <span class="n">memory_strings</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">. </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">mem</span><span class="p">.</span><span class="n">content</span><span class="p">)</span><span class="si">}</span><span class="s">"</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">mem</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_contents</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="n">memory_context_str</span> <span class="o">=</span> <span class="s">"Relevant memory content...</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">memory_strings</span><span class="p">)</span> <span class="o">+</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span>

        <span class="c1"># Add this string as a SystemMessage to the provided chat context
</span>        <span class="k">await</span> <span class="n">model_context</span><span class="p">.</span><span class="n">add_message</span><span class="p">(</span><span class="n">SystemMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">memory_context_str</span><span class="p">))</span>

        <span class="c1"># Return info about which memories were added
</span>        <span class="k">return</span> <span class="n">UpdateContextResult</span><span class="p">(</span><span class="n">memories</span><span class="o">=</span><span class="n">MemoryQueryResult</span><span class="p">(</span><span class="n">results</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">_contents</span><span class="p">))</span>

    <span class="c1"># ... clear(), close(), config methods ...
</span></code></pre></div>    </div>
    <p>This shows the straightforward logic of <code class="language-plaintext highlighter-rouge">ListMemory</code>: store in a list, retrieve the whole list, and inject the whole list as a single system message into the chat context. More complex memories might use smarter retrieval (e.g., based on the <code class="language-plaintext highlighter-rouge">query</code> in <code class="language-plaintext highlighter-rouge">query()</code> or the last message in <code class="language-plaintext highlighter-rouge">update_context</code>) and inject memories differently.</p>
  </li>
</ul>

<h2 id="next-steps">Next Steps</h2>

<p>You’ve learned about <code class="language-plaintext highlighter-rouge">Memory</code>, AutoGen Core’s mechanism for giving agents long-term recall beyond the immediate conversation (<code class="language-plaintext highlighter-rouge">ChatCompletionContext</code>). We saw how <code class="language-plaintext highlighter-rouge">MemoryContent</code> holds information, <code class="language-plaintext highlighter-rouge">add</code> stores it, <code class="language-plaintext highlighter-rouge">query</code> retrieves it, and <code class="language-plaintext highlighter-rouge">update_context</code> injects relevant memories into the LLM’s working context. We explored the simple <code class="language-plaintext highlighter-rouge">ListMemory</code> as a basic example.</p>

<p>Memory systems are crucial for agents that learn, adapt, or need to maintain state across interactions.</p>

<p>This concludes our deep dive into the core abstractions of AutoGen Core! We’ve covered Agents, Messaging, Runtime, Tools, LLM Clients, Chat Context, and now Memory. There’s one final concept that ties many of these together from a configuration perspective:</p>

<ul>
  <li><a href="08_component.md">Chapter 8: Component</a>: Understand the general <code class="language-plaintext highlighter-rouge">Component</code> model in AutoGen Core, how it allows pieces like <code class="language-plaintext highlighter-rouge">Memory</code>, <code class="language-plaintext highlighter-rouge">ChatCompletionContext</code>, and <code class="language-plaintext highlighter-rouge">ChatCompletionClient</code> to be configured and managed consistently.</li>
</ul>

<hr />

<p>Generated by <a href="https://github.com/The-Pocket/Tutorial-Codebase-Knowledge">AI Codebase Knowledge Builder</a></p>
