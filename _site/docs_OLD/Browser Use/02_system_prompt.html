<h1 id="chapter-2-the-system-prompt---setting-the-rules-for-your-ai-assistant">Chapter 2: The System Prompt - Setting the Rules for Your AI Assistant</h1>

<p>In <a href="01_agent.md">Chapter 1: The Agent</a>, we met the <code class="language-plaintext highlighter-rouge">Agent</code>, our project manager for automating browser tasks. We saw it consults a Large Language Model (LLM) – the “planner” – to decide the next steps based on the current state of the webpage. But how does the Agent tell the LLM <em>how</em> it should think, behave, and respond? Just giving it the task isn’t enough!</p>

<p>Imagine hiring a new assistant. You wouldn’t just say, “Organize my files!” You’d give them specific instructions: “Please sort the files alphabetically by client name, put them in the blue folders, and give me a summary list when you’re done.” Without these rules, the assistant might do something completely different!</p>

<p>The <strong>System Prompt</strong> solves this exact problem for our LLM. It’s the set of core instructions and rules we give the LLM at the very beginning, telling it exactly how to act as a browser automation assistant and, crucially, how to format its responses so the <code class="language-plaintext highlighter-rouge">Agent</code> can understand them.</p>

<h2 id="what-is-the-system-prompt-the-ais-rulebook">What is the System Prompt? The AI’s Rulebook</h2>

<p>Think of the System Prompt like the AI assistant’s fundamental operating manual, its “Prime Directive,” or the rules of a board game. It defines:</p>

<ol>
  <li><strong>Persona:</strong> “You are an AI agent designed to automate browser tasks.”</li>
  <li><strong>Goal:</strong> “Your goal is to accomplish the ultimate task…”</li>
  <li><strong>Input:</strong> How to understand the information it receives about the webpage (<a href="04_dom_representation.md">DOM Representation</a>).</li>
  <li><strong>Capabilities:</strong> What actions it can take (<a href="05_action_controller___registry.md">Action Controller &amp; Registry</a>).</li>
  <li><strong>Limitations:</strong> What it <em>shouldn’t</em> do (e.g., hallucinate actions).</li>
  <li><strong>Response Format:</strong> The <em>exact</em> structure (JSON format) its thoughts and planned actions must follow.</li>
</ol>

<p>Without this rulebook, the LLM might just chat casually, give vague suggestions, or produce output in a format the <code class="language-plaintext highlighter-rouge">Agent</code> code can’t parse. The System Prompt ensures the LLM behaves like the specialized tool we need.</p>

<h2 id="why-is-the-response-format-so-important">Why is the Response Format So Important?</h2>

<p>This is a critical point. The <code class="language-plaintext highlighter-rouge">Agent</code> code isn’t a human reading the LLM’s response. It’s a program expecting data in a very specific structure. The System Prompt tells the LLM to <em>always</em> respond in a JSON format that looks something like this (simplified):</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"current_state"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"evaluation_previous_goal"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Success - Found the search bar."</span><span class="p">,</span><span class="w">
    </span><span class="nl">"memory"</span><span class="p">:</span><span class="w"> </span><span class="s2">"On google.com main page. Need to search for cats."</span><span class="p">,</span><span class="w">
    </span><span class="nl">"next_goal"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Type 'cute cat pictures' into the search bar."</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"action"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"input_text"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"index"</span><span class="p">:</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="err">//</span><span class="w"> </span><span class="err">The</span><span class="w"> </span><span class="err">index</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">search</span><span class="w"> </span><span class="err">bar</span><span class="w"> </span><span class="err">element</span><span class="w">
        </span><span class="nl">"text"</span><span class="p">:</span><span class="w"> </span><span class="s2">"cute cat pictures"</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"press_keys"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"keys"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Enter"</span><span class="w"> </span><span class="err">//</span><span class="w"> </span><span class="err">Press</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">Enter</span><span class="w"> </span><span class="err">key</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">Agent</code> can easily read this JSON:</p>
<ul>
  <li>It understands the LLM’s thoughts (<code class="language-plaintext highlighter-rouge">current_state</code>).</li>
  <li>It sees the exact <code class="language-plaintext highlighter-rouge">action</code> list the LLM wants to perform.</li>
  <li>It passes these actions (like <code class="language-plaintext highlighter-rouge">input_text</code> or <code class="language-plaintext highlighter-rouge">press_keys</code>) to the <a href="05_action_controller___registry.md">Action Controller &amp; Registry</a> to execute them in the browser.</li>
</ul>

<p>If the LLM responded with just “Okay, I’ll type ‘cute cat pictures’ into the search bar and press Enter,” the <code class="language-plaintext highlighter-rouge">Agent</code> wouldn’t know <em>which</em> element index corresponds to the search bar or exactly which actions to call. The strict JSON format is essential for automation.</p>

<h2 id="a-peek-inside-the-rulebook-system_promptmd">A Peek Inside the Rulebook (<code class="language-plaintext highlighter-rouge">system_prompt.md</code>)</h2>

<p>The actual instructions live in a text file within the <code class="language-plaintext highlighter-rouge">Browser Use</code> library: <code class="language-plaintext highlighter-rouge">browser_use/agent/system_prompt.md</code>. It’s quite detailed, but here’s a tiny snippet focusing on the response format rule:</p>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gh"># Response Rules</span>
<span class="p">1.</span> RESPONSE FORMAT: You must ALWAYS respond with valid JSON in this exact format:
current_state,
"action":[one_action_name}}, ...]}}
<span class="p">
2.</span> ACTIONS: You can specify multiple actions in the list... Use maximum  actions...
</code></pre></div></div>
<p><em>(This is heavily simplified! The real file has many more rules about element interaction, error handling, task completion, etc.)</em></p>

<p>This file clearly defines the JSON structure (<code class="language-plaintext highlighter-rouge">current_state</code> and <code class="language-plaintext highlighter-rouge">action</code>) and other crucial behaviors required from the LLM.</p>

<h2 id="how-the-agent-uses-the-system-prompt">How the Agent Uses the System Prompt</h2>

<p>The <code class="language-plaintext highlighter-rouge">Agent</code> uses a helper class called <code class="language-plaintext highlighter-rouge">SystemPrompt</code> (found in <code class="language-plaintext highlighter-rouge">agent/prompts.py</code>) to manage these rules. Here’s the flow:</p>

<ol>
  <li><strong>Loading:</strong> When you create an <code class="language-plaintext highlighter-rouge">Agent</code>, it internally creates a <code class="language-plaintext highlighter-rouge">SystemPrompt</code> object. This object reads the rules from the <code class="language-plaintext highlighter-rouge">system_prompt.md</code> file.</li>
  <li><strong>Formatting:</strong> The <code class="language-plaintext highlighter-rouge">SystemPrompt</code> object formats these rules into a special <code class="language-plaintext highlighter-rouge">SystemMessage</code> object that LLMs understand as foundational instructions.</li>
  <li><strong>Conversation Start:</strong> This <code class="language-plaintext highlighter-rouge">SystemMessage</code> is given to the <a href="06_message_manager.md">Message Manager</a>, which keeps track of the conversation history with the LLM. The <code class="language-plaintext highlighter-rouge">SystemMessage</code> becomes the <em>very first message</em>, setting the context for all future interactions in that session.</li>
</ol>

<p>Think of it like starting a meeting: the first thing you do is state the agenda and rules (System Prompt), and then the discussion (LLM interaction) follows based on that foundation.</p>

<p>Let’s look at a simplified view of the <code class="language-plaintext highlighter-rouge">SystemPrompt</code> class loading the rules:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># --- File: agent/prompts.py (Simplified) ---
</span><span class="kn">import</span> <span class="nn">importlib.resources</span> <span class="c1"># Helps find files within the installed library
</span><span class="kn">from</span> <span class="nn">langchain_core.messages</span> <span class="kn">import</span> <span class="n">SystemMessage</span> <span class="c1"># Special message type for LLMs
</span>
<span class="k">class</span> <span class="nc">SystemPrompt</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action_description</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">max_actions_per_step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">):</span>
        <span class="c1"># We ignore these details for now
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">default_action_description</span> <span class="o">=</span> <span class="n">action_description</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">max_actions_per_step</span> <span class="o">=</span> <span class="n">max_actions_per_step</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_load_prompt_template</span><span class="p">()</span> <span class="c1"># &lt;--- Loads the rules file
</span>
    <span class="k">def</span> <span class="nf">_load_prompt_template</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="s">"""Load the prompt rules from the system_prompt.md file."""</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Finds the 'system_prompt.md' file inside the browser_use package
</span>            <span class="n">filepath</span> <span class="o">=</span> <span class="n">importlib</span><span class="p">.</span><span class="n">resources</span><span class="p">.</span><span class="n">files</span><span class="p">(</span><span class="s">'browser_use.agent'</span><span class="p">).</span><span class="n">joinpath</span><span class="p">(</span><span class="s">'system_prompt.md'</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">filepath</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="s">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="n">read</span><span class="p">()</span> <span class="c1"># Read the text content
</span>            <span class="k">print</span><span class="p">(</span><span class="s">"System Prompt template loaded successfully!"</span><span class="p">)</span>
        <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Error loading system prompt: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">prompt_template</span> <span class="o">=</span> <span class="s">"Error: Could not load prompt."</span> <span class="c1"># Fallback
</span>
    <span class="k">def</span> <span class="nf">get_system_message</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SystemMessage</span><span class="p">:</span>
        <span class="s">"""Format the loaded rules into a message for the LLM."""</span>
        <span class="c1"># Replace placeholders like  with actual values
</span>        <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">prompt_template</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">max_actions</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">max_actions_per_step</span><span class="p">)</span>
        <span class="c1"># Wrap the final rules text in a SystemMessage object
</span>        <span class="k">return</span> <span class="n">SystemMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">prompt</span><span class="p">)</span>

<span class="c1"># --- How it plugs into Agent creation (Conceptual) ---
# from browser_use import Agent, SystemPrompt
# from my_llm_setup import my_llm # Your LLM
# ... other setup ...
</span>
<span class="c1"># When you create an Agent:
# agent = Agent(
#     task="Find cat pictures",
#     llm=my_llm,
#     browser_context=...,
#     controller=...,
#     # The Agent's __init__ method does something like this internally:
#     # system_prompt_obj = SystemPrompt(action_description="...", max_actions_per_step=10)
#     # system_message_for_llm = system_prompt_obj.get_system_message()
#     # This system_message_for_llm is then passed to the Message Manager.
# )
</span></code></pre></div></div>

<p>This code shows how the <code class="language-plaintext highlighter-rouge">SystemPrompt</code> class finds and reads the <code class="language-plaintext highlighter-rouge">system_prompt.md</code> file and prepares the instructions as a <code class="language-plaintext highlighter-rouge">SystemMessage</code> ready for the LLM conversation.</p>

<h2 id="under-the-hood-initialization-and-conversation-flow">Under the Hood: Initialization and Conversation Flow</h2>

<p>Let’s visualize how the System Prompt fits into the Agent’s setup and interaction loop:</p>

<pre><code class="language-mermaid">sequenceDiagram
    participant User
    participant Agent_Init as Agent Initialization
    participant SP as SystemPrompt Class
    participant MM as Message Manager
    participant Agent_Run as Agent Run Loop
    participant LLM

    User-&gt;&gt;Agent_Init: Create Agent(task, llm, ...)
    Note over Agent_Init: Agent needs the rules!
    Agent_Init-&gt;&gt;SP: Create SystemPrompt(...)
    SP-&gt;&gt;SP: _load_prompt_template() reads system_prompt.md
    SP--&gt;&gt;Agent_Init: SystemPrompt instance
    Agent_Init-&gt;&gt;SP: get_system_message()
    SP--&gt;&gt;Agent_Init: system_message (The Formatted Rules)
    Note over Agent_Init: Pass rules to conversation manager
    Agent_Init-&gt;&gt;MM: Initialize MessageManager(task, system_message)
    MM-&gt;&gt;MM: Store system_message as message #1
    MM--&gt;&gt;Agent_Init: MessageManager instance ready
    Agent_Init--&gt;&gt;User: Agent created and ready

    User-&gt;&gt;Agent_Run: agent.run() starts the task
    Note over Agent_Run: Agent needs context for LLM
    Agent_Run-&gt;&gt;MM: get_messages()
    MM--&gt;&gt;Agent_Run: [system_message, user_message(state), ...]
    Note over Agent_Run: Send rules + current state to LLM
    Agent_Run-&gt;&gt;LLM: Ask for next action (Input includes rules)
    LLM--&gt;&gt;Agent_Run: JSON response (LLM followed rules!)
    Agent_Run-&gt;&gt;MM: add_model_output(...)
    Note over Agent_Run: Loop continues...
</code></pre>

<p>Internally, the <code class="language-plaintext highlighter-rouge">Agent</code>’s initialization code (<code class="language-plaintext highlighter-rouge">__init__</code> in <code class="language-plaintext highlighter-rouge">agent/service.py</code>) explicitly creates the <code class="language-plaintext highlighter-rouge">SystemPrompt</code> and passes its output to the <code class="language-plaintext highlighter-rouge">MessageManager</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># --- File: agent/service.py (Simplified Agent __init__) ---
# ... other imports ...
</span><span class="kn">from</span> <span class="nn">browser_use.agent.prompts</span> <span class="kn">import</span> <span class="n">SystemPrompt</span> <span class="c1"># Import the class
</span><span class="kn">from</span> <span class="nn">browser_use.agent.message_manager.service</span> <span class="kn">import</span> <span class="n">MessageManager</span><span class="p">,</span> <span class="n">MessageManagerSettings</span>

<span class="k">class</span> <span class="nc">Agent</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">task</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">llm</span><span class="p">:</span> <span class="n">BaseChatModel</span><span class="p">,</span>
        <span class="n">browser_context</span><span class="p">:</span> <span class="n">BrowserContext</span><span class="p">,</span>
        <span class="n">controller</span><span class="p">:</span> <span class="n">Controller</span><span class="p">,</span>
        <span class="n">system_prompt_class</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">SystemPrompt</span><span class="p">]</span> <span class="o">=</span> <span class="n">SystemPrompt</span><span class="p">,</span> <span class="c1"># Allows customizing the prompt class
</span>        <span class="n">max_actions_per_step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
         <span class="c1"># ... other parameters ...
</span>        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">task</span> <span class="o">=</span> <span class="n">task</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">llm</span> <span class="o">=</span> <span class="n">llm</span>
        <span class="c1"># ... store other components ...
</span>
        <span class="c1"># Get the list of available actions from the controller
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">available_actions</span> <span class="o">=</span> <span class="n">controller</span><span class="p">.</span><span class="n">registry</span><span class="p">.</span><span class="n">get_prompt_description</span><span class="p">()</span>

        <span class="c1"># 1. Create the SystemPrompt instance using the provided class
</span>        <span class="n">system_prompt_instance</span> <span class="o">=</span> <span class="n">system_prompt_class</span><span class="p">(</span>
            <span class="n">action_description</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">available_actions</span><span class="p">,</span>
            <span class="n">max_actions_per_step</span><span class="o">=</span><span class="n">max_actions_per_step</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># 2. Get the formatted SystemMessage (the rules)
</span>        <span class="n">system_message</span> <span class="o">=</span> <span class="n">system_prompt_instance</span><span class="p">.</span><span class="n">get_system_message</span><span class="p">()</span>

        <span class="c1"># 3. Initialize the Message Manager with the task and the rules
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">_message_manager</span> <span class="o">=</span> <span class="n">MessageManager</span><span class="p">(</span>
            <span class="n">task</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">task</span><span class="p">,</span>
            <span class="n">system_message</span><span class="o">=</span><span class="n">system_message</span><span class="p">,</span> <span class="c1"># &lt;--- Pass the rules here!
</span>            <span class="n">settings</span><span class="o">=</span><span class="n">MessageManagerSettings</span><span class="p">(...)</span>
            <span class="c1"># ... other message manager setup ...
</span>        <span class="p">)</span>
        <span class="c1"># ... rest of initialization ...
</span>        <span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Agent initialized with System Prompt."</span><span class="p">)</span>
</code></pre></div></div>

<p>When the <code class="language-plaintext highlighter-rouge">Agent</code> runs its loop (<code class="language-plaintext highlighter-rouge">agent.run()</code> calls <code class="language-plaintext highlighter-rouge">agent.step()</code>), it asks the <code class="language-plaintext highlighter-rouge">MessageManager</code> for the current conversation history (<code class="language-plaintext highlighter-rouge">self._message_manager.get_messages()</code>). The <code class="language-plaintext highlighter-rouge">MessageManager</code> always ensures that the <code class="language-plaintext highlighter-rouge">SystemMessage</code> (containing the rules) is the very first item in that history list sent to the LLM.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The System Prompt is the essential rulebook that governs the LLM’s behavior within the <code class="language-plaintext highlighter-rouge">Browser Use</code> framework. It tells the LLM how to interpret the browser state, what actions it can take, and most importantly, dictates the exact JSON format for its responses. This structured communication is key to enabling the <code class="language-plaintext highlighter-rouge">Agent</code> to reliably understand the LLM’s plan and execute browser automation tasks.</p>

<p>Without a clear System Prompt, the LLM would be like an untrained assistant – potentially intelligent, but unable to follow the specific procedures needed for the job.</p>

<p>Now that we understand how the <code class="language-plaintext highlighter-rouge">Agent</code> gets its fundamental instructions, how does it actually perceive the webpage it’s supposed to interact with? In the next chapter, we’ll explore the component responsible for representing the browser’s state: the <a href="03_browsercontext.md">BrowserContext</a>.</p>

<p><a href="03_browsercontext.md">Next Chapter: BrowserContext</a></p>

<hr />

<p>Generated by <a href="https://github.com/The-Pocket/Tutorial-Codebase-Knowledge">AI Codebase Knowledge Builder</a></p>
