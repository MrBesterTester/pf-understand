<h1 id="chapter-1-how-we-fetch-webpages---asynccrawlerstrategy">Chapter 1: How We Fetch Webpages - AsyncCrawlerStrategy</h1>

<p>Welcome to the Crawl4AI tutorial series! Our goal is to build intelligent agents that can understand and extract information from the web. The very first step in this process is actually <em>getting</em> the content from a webpage. This chapter explains how Crawl4AI handles that fundamental task.</p>

<p>Imagine you need to pick up a package from a specific address. How do you get there and retrieve it?</p>
<ul>
  <li>You could send a <strong>simple, fast drone</strong> that just grabs the package off the porch (if it’s easily accessible). This is quick but might fail if the package is inside or requires a signature.</li>
  <li>Or, you could send a <strong>full delivery truck with a driver</strong>. The driver can ring the bell, wait, sign for the package, and even handle complex instructions. This is more versatile but takes more time and resources.</li>
</ul>

<p>In Crawl4AI, the <code class="language-plaintext highlighter-rouge">AsyncCrawlerStrategy</code> is like choosing your delivery vehicle. It defines <em>how</em> the crawler fetches the raw content (like the HTML, CSS, and maybe JavaScript results) of a webpage.</p>

<h2 id="what-exactly-is-asynccrawlerstrategy">What Exactly is AsyncCrawlerStrategy?</h2>

<p><code class="language-plaintext highlighter-rouge">AsyncCrawlerStrategy</code> is a core concept in Crawl4AI that represents the <strong>method</strong> or <strong>technique</strong> used to download the content of a given URL. Think of it as a blueprint: it specifies <em>that</em> we need a way to fetch content, but the specific <em>details</em> of how it’s done can vary.</p>

<p>This “blueprint” approach is powerful because it allows us to swap out the fetching mechanism depending on our needs, without changing the rest of our crawling logic.</p>

<h2 id="the-default-asyncplaywrightcrawlerstrategy-the-delivery-truck">The Default: AsyncPlaywrightCrawlerStrategy (The Delivery Truck)</h2>

<p>By default, Crawl4AI uses <code class="language-plaintext highlighter-rouge">AsyncPlaywrightCrawlerStrategy</code>. This strategy uses a real, automated web browser engine (like Chrome, Firefox, or WebKit) behind the scenes.</p>

<p><strong>Why use a full browser?</strong></p>

<ul>
  <li><strong>Handles JavaScript:</strong> Modern websites rely heavily on JavaScript to load content, change the layout, or fetch data after the initial page load. <code class="language-plaintext highlighter-rouge">AsyncPlaywrightCrawlerStrategy</code> runs this JavaScript, just like your normal browser does.</li>
  <li><strong>Simulates User Interaction:</strong> It can wait for elements to appear, handle dynamic content, and see the page <em>after</em> scripts have run.</li>
  <li><strong>Gets the “Final” View:</strong> It fetches the content as a user would see it in their browser.</li>
</ul>

<p>This is our “delivery truck” – powerful and capable of handling complex websites. However, like a real truck, it’s slower and uses more memory and CPU compared to simpler methods.</p>

<p>You generally don’t need to <em>do</em> anything to use it, as it’s the default! When you start Crawl4AI, it picks this strategy automatically.</p>

<h2 id="another-option-asynchttpcrawlerstrategy-the-delivery-drone">Another Option: AsyncHTTPCrawlerStrategy (The Delivery Drone)</h2>

<p>Crawl4AI also offers <code class="language-plaintext highlighter-rouge">AsyncHTTPCrawlerStrategy</code>. This strategy is much simpler. It directly requests the URL and downloads the <em>initial</em> HTML source code that the web server sends back.</p>

<p><strong>Why use this simpler strategy?</strong></p>

<ul>
  <li><strong>Speed:</strong> It’s significantly faster because it doesn’t need to start a browser, render the page, or execute JavaScript.</li>
  <li><strong>Efficiency:</strong> It uses much less memory and CPU.</li>
</ul>

<p>This is our “delivery drone” – super fast and efficient for simple tasks.</p>

<p><strong>What’s the catch?</strong></p>

<ul>
  <li><strong>No JavaScript:</strong> It won’t run any JavaScript on the page. If content is loaded dynamically by scripts, this strategy will likely miss it.</li>
  <li><strong>Basic HTML Only:</strong> You get the raw HTML source, not necessarily what a user <em>sees</em> after the browser processes everything.</li>
</ul>

<p>This strategy is great for websites with simple, static HTML content or when you only need the basic structure and metadata very quickly.</p>

<h2 id="why-have-different-strategies-the-power-of-abstraction">Why Have Different Strategies? (The Power of Abstraction)</h2>

<p>Having <code class="language-plaintext highlighter-rouge">AsyncCrawlerStrategy</code> as a distinct concept offers several advantages:</p>

<ol>
  <li><strong>Flexibility:</strong> You can choose the best tool for the job. Need to crawl complex, dynamic sites? Use the default <code class="language-plaintext highlighter-rouge">AsyncPlaywrightCrawlerStrategy</code>. Need to quickly fetch basic HTML from thousands of simple pages? Switch to <code class="language-plaintext highlighter-rouge">AsyncHTTPCrawlerStrategy</code>.</li>
  <li><strong>Maintainability:</strong> The logic for <em>fetching</em> content is kept separate from the logic for <em>processing</em> it.</li>
  <li><strong>Extensibility:</strong> Advanced users could even create their <em>own</em> custom strategies for specialized fetching needs (though that’s beyond this beginner tutorial).</li>
</ol>

<h2 id="how-it-works-conceptually">How It Works Conceptually</h2>

<p>When you ask Crawl4AI to crawl a URL, the main <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> doesn’t fetch the content itself. Instead, it delegates the task to the currently selected <code class="language-plaintext highlighter-rouge">AsyncCrawlerStrategy</code>.</p>

<p>Here’s a simplified flow:</p>

<pre><code class="language-mermaid">sequenceDiagram
    participant C as AsyncWebCrawler
    participant S as AsyncCrawlerStrategy
    participant W as Website

    C-&gt;&gt;S: Please crawl("https://example.com")
    Note over S: I'm using my method (e.g., Browser or HTTP)
    S-&gt;&gt;W: Request Page Content
    W--&gt;&gt;S: Return Raw Content (HTML, etc.)
    S--&gt;&gt;C: Here's the result (AsyncCrawlResponse)
</code></pre>

<p>The <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> only needs to know how to talk to <em>any</em> strategy through a common interface (the <code class="language-plaintext highlighter-rouge">crawl</code> method). The strategy handles the specific details of the fetching process.</p>

<h2 id="using-the-default-strategy-youre-already-doing-it">Using the Default Strategy (You’re Already Doing It!)</h2>

<p>Let’s see how you use the default <code class="language-plaintext highlighter-rouge">AsyncPlaywrightCrawlerStrategy</code> without even needing to specify it.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># main_example.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlerRunConfig</span><span class="p">,</span> <span class="n">CacheMode</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># When you create AsyncWebCrawler without specifying a strategy,
</span>    <span class="c1"># it automatically uses AsyncPlaywrightCrawlerStrategy!
</span>    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Crawler is ready using the default strategy (Playwright)."</span><span class="p">)</span>

        <span class="c1"># Let's crawl a simple page that just returns HTML
</span>        <span class="c1"># We use CacheMode.BYPASS to ensure we fetch it fresh each time for this demo.
</span>        <span class="n">config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span><span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">BYPASS</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="s">"https://httpbin.org/html"</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="n">config</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">success</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Successfully fetched content!"</span><span class="p">)</span>
            <span class="c1"># The strategy fetched the raw HTML.
</span>            <span class="c1"># AsyncWebCrawler then processes it (more on that later).
</span>            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"First 100 chars of fetched HTML: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">html</span><span class="p">[</span><span class="si">:</span><span class="mi">100</span><span class="p">]</span><span class="si">}</span><span class="s">..."</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Failed to fetch content: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">error_message</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div>

<p><strong>Explanation:</strong></p>

<ol>
  <li>We import <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> and supporting classes.</li>
  <li>We create an instance of <code class="language-plaintext highlighter-rouge">AsyncWebCrawler()</code> inside an <code class="language-plaintext highlighter-rouge">async with</code> block (this handles setup and cleanup). Since we didn’t tell it <em>which</em> strategy to use, it defaults to <code class="language-plaintext highlighter-rouge">AsyncPlaywrightCrawlerStrategy</code>.</li>
  <li>We call <code class="language-plaintext highlighter-rouge">crawler.arun()</code> to crawl the URL. Under the hood, the <code class="language-plaintext highlighter-rouge">AsyncPlaywrightCrawlerStrategy</code> starts a browser, navigates to the page, gets the content, and returns it.</li>
  <li>We print the first part of the fetched HTML from the <code class="language-plaintext highlighter-rouge">result</code>.</li>
</ol>

<h2 id="explicitly-choosing-the-http-strategy">Explicitly Choosing the HTTP Strategy</h2>

<p>What if you know the page is simple and want the speed of the “delivery drone”? You can explicitly tell <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> to use <code class="language-plaintext highlighter-rouge">AsyncHTTPCrawlerStrategy</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># http_strategy_example.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlerRunConfig</span><span class="p">,</span> <span class="n">CacheMode</span>
<span class="c1"># Import the specific strategies we want to use
</span><span class="kn">from</span> <span class="nn">crawl4ai.async_crawler_strategy</span> <span class="kn">import</span> <span class="n">AsyncHTTPCrawlerStrategy</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># 1. Create an instance of the strategy you want
</span>    <span class="n">http_strategy</span> <span class="o">=</span> <span class="n">AsyncHTTPCrawlerStrategy</span><span class="p">()</span>

    <span class="c1"># 2. Pass the strategy instance when creating the AsyncWebCrawler
</span>    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">(</span><span class="n">crawler_strategy</span><span class="o">=</span><span class="n">http_strategy</span><span class="p">)</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Crawler is ready using the explicit HTTP strategy."</span><span class="p">)</span>

        <span class="c1"># Crawl the same simple page
</span>        <span class="n">config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span><span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">BYPASS</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="s">"https://httpbin.org/html"</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="n">config</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">success</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Successfully fetched content using HTTP strategy!"</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"First 100 chars of fetched HTML: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">html</span><span class="p">[</span><span class="si">:</span><span class="mi">100</span><span class="p">]</span><span class="si">}</span><span class="s">..."</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Failed to fetch content: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">error_message</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div>

<p><strong>Explanation:</strong></p>

<ol>
  <li>We now also import <code class="language-plaintext highlighter-rouge">AsyncHTTPCrawlerStrategy</code>.</li>
  <li>We create an instance: <code class="language-plaintext highlighter-rouge">http_strategy = AsyncHTTPCrawlerStrategy()</code>.</li>
  <li>We pass this instance to the <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> constructor: <code class="language-plaintext highlighter-rouge">AsyncWebCrawler(crawler_strategy=http_strategy)</code>.</li>
  <li>The rest of the code is the same, but now <code class="language-plaintext highlighter-rouge">crawler.arun()</code> will use the faster, simpler HTTP GET request method defined by <code class="language-plaintext highlighter-rouge">AsyncHTTPCrawlerStrategy</code>.</li>
</ol>

<p>For a simple page like <code class="language-plaintext highlighter-rouge">httpbin.org/html</code>, both strategies will likely return the same HTML content, but the HTTP strategy would generally be faster and use fewer resources. On a complex JavaScript-heavy site, the HTTP strategy might fail to get the full content, while the Playwright strategy would handle it correctly.</p>

<h2 id="a-glimpse-under-the-hood">A Glimpse Under the Hood</h2>

<p>You don’t <em>need</em> to know the deep internals to use the strategies, but it helps to understand the structure. Inside the <code class="language-plaintext highlighter-rouge">crawl4ai</code> library, you’d find a file like <code class="language-plaintext highlighter-rouge">async_crawler_strategy.py</code>.</p>

<p>It defines the “blueprint” (an Abstract Base Class):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified from async_crawler_strategy.py
</span><span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">.models</span> <span class="kn">import</span> <span class="n">AsyncCrawlResponse</span> <span class="c1"># Defines the structure of the result
</span>
<span class="k">class</span> <span class="nc">AsyncCrawlerStrategy</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="s">"""
    Abstract base class for crawler strategies.
    """</span>
    <span class="o">@</span><span class="n">abstractmethod</span>
    <span class="k">async</span> <span class="k">def</span> <span class="nf">crawl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AsyncCrawlResponse</span><span class="p">:</span>
        <span class="s">"""Fetch content from the URL."""</span>
        <span class="k">pass</span> <span class="c1"># Each specific strategy must implement this
</span></code></pre></div></div>

<p>And then the specific implementations:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified from async_crawler_strategy.py
</span><span class="kn">from</span> <span class="nn">playwright.async_api</span> <span class="kn">import</span> <span class="n">Page</span> <span class="c1"># Playwright library for browser automation
# ... other imports
</span>
<span class="k">class</span> <span class="nc">AsyncPlaywrightCrawlerStrategy</span><span class="p">(</span><span class="n">AsyncCrawlerStrategy</span><span class="p">):</span>
    <span class="c1"># ... (Initialization code to manage browsers)
</span>
    <span class="k">async</span> <span class="k">def</span> <span class="nf">crawl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">CrawlerRunConfig</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AsyncCrawlResponse</span><span class="p">:</span>
        <span class="c1"># Uses Playwright to:
</span>        <span class="c1"># 1. Get a browser page
</span>        <span class="c1"># 2. Navigate to the url (page.goto(url))
</span>        <span class="c1"># 3. Wait for content, run JS, etc.
</span>        <span class="c1"># 4. Get the final HTML (page.content())
</span>        <span class="c1"># 5. Optionally take screenshots, etc.
</span>        <span class="c1"># 6. Return an AsyncCrawlResponse
</span>        <span class="c1"># ... implementation details ...
</span>        <span class="k">pass</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified from async_crawler_strategy.py
</span><span class="kn">import</span> <span class="nn">aiohttp</span> <span class="c1"># Library for making HTTP requests asynchronously
# ... other imports
</span>
<span class="k">class</span> <span class="nc">AsyncHTTPCrawlerStrategy</span><span class="p">(</span><span class="n">AsyncCrawlerStrategy</span><span class="p">):</span>
    <span class="c1"># ... (Initialization code to manage HTTP sessions)
</span>
    <span class="k">async</span> <span class="k">def</span> <span class="nf">crawl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">CrawlerRunConfig</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AsyncCrawlResponse</span><span class="p">:</span>
        <span class="c1"># Uses aiohttp to:
</span>        <span class="c1"># 1. Make an HTTP GET (or other method) request to the url
</span>        <span class="c1"># 2. Read the response body (HTML)
</span>        <span class="c1"># 3. Get response headers and status code
</span>        <span class="c1"># 4. Return an AsyncCrawlResponse
</span>        <span class="c1"># ... implementation details ...
</span>        <span class="k">pass</span>
</code></pre></div></div>

<p>The key takeaway is that both strategies implement the same <code class="language-plaintext highlighter-rouge">crawl</code> method, allowing <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> to use them interchangeably.</p>

<h2 id="conclusion">Conclusion</h2>

<p>You’ve learned about <code class="language-plaintext highlighter-rouge">AsyncCrawlerStrategy</code>, the core concept defining <em>how</em> Crawl4AI fetches webpage content.</p>

<ul>
  <li>It’s like choosing a vehicle: a powerful browser (<code class="language-plaintext highlighter-rouge">AsyncPlaywrightCrawlerStrategy</code>, the default) or a fast, simple HTTP request (<code class="language-plaintext highlighter-rouge">AsyncHTTPCrawlerStrategy</code>).</li>
  <li>This abstraction gives you flexibility to choose the right fetching method for your task.</li>
  <li>You usually don’t need to worry about it, as the default handles most modern websites well.</li>
</ul>

<p>Now that we understand how the raw content is fetched, the next step is to look at the main class that orchestrates the entire crawling process.</p>

<p><strong>Next:</strong> Let’s dive into the <a href="02_asyncwebcrawler.md">AsyncWebCrawler</a> itself!</p>

<hr />

<p>Generated by <a href="https://github.com/The-Pocket/Tutorial-Codebase-Knowledge">AI Codebase Knowledge Builder</a></p>
