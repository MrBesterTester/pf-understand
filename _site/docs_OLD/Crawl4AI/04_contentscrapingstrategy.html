<h1 id="chapter-4-cleaning-up-the-mess---contentscrapingstrategy">Chapter 4: Cleaning Up the Mess - ContentScrapingStrategy</h1>

<p>In <a href="03_crawlerrunconfig.md">Chapter 3: Giving Instructions - CrawlerRunConfig</a>, we learned how to give specific instructions to our <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> using <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code>. This included telling it <em>how</em> to fetch the page and potentially take screenshots or PDFs.</p>

<p>Now, imagine the crawler has successfully fetched the raw HTML content of a webpage. What’s next? Raw HTML is often messy! It contains not just the main article or product description you might care about, but also:</p>

<ul>
  <li>Navigation menus</li>
  <li>Advertisements</li>
  <li>Headers and footers</li>
  <li>Hidden code like JavaScript (<code class="language-plaintext highlighter-rouge">&lt;script&gt;</code>) and styling information (<code class="language-plaintext highlighter-rouge">&lt;style&gt;</code>)</li>
  <li>Comments left by developers</li>
</ul>

<p>Before we can really understand the <em>meaning</em> of the page or extract specific important information, we need to clean up this mess and get a basic understanding of its structure.</p>

<h2 id="what-problem-does-contentscrapingstrategy-solve">What Problem Does <code class="language-plaintext highlighter-rouge">ContentScrapingStrategy</code> Solve?</h2>

<p>Think of the raw HTML fetched by the crawler as a very rough first draft of a book manuscript. It has the core story, but it’s full of editor’s notes, coffee stains, layout instructions for the printer, and maybe even doodles in the margins.</p>

<p>Before the <em>main</em> editor (who focuses on plot and character) can work on it, someone needs to do an initial cleanup. This “First Pass Editor” would:</p>

<ol>
  <li>Remove the coffee stains and doodles (irrelevant stuff like ads, scripts, styles).</li>
  <li>Identify the basic structure: chapter headings (like the page title), paragraph text, image captions (image alt text), and maybe a list of illustrations (links).</li>
  <li>Produce a tidier version of the manuscript, ready for more detailed analysis.</li>
</ol>

<p>In Crawl4AI, the <code class="language-plaintext highlighter-rouge">ContentScrapingStrategy</code> acts as this <strong>First Pass Editor</strong>. It takes the raw HTML and performs an initial cleanup and structure extraction. Its job is to transform the messy HTML into a more manageable format, identifying key elements like text content, links, images, and basic page metadata (like the title).</p>

<h2 id="what-is-contentscrapingstrategy">What is <code class="language-plaintext highlighter-rouge">ContentScrapingStrategy</code>?</h2>

<p><code class="language-plaintext highlighter-rouge">ContentScrapingStrategy</code> is an abstract concept (like a job description) in Crawl4AI that defines <em>how</em> the initial processing of raw HTML should happen. It specifies <em>that</em> we need a method to clean HTML and extract basic structure, but the specific tools and techniques used can vary.</p>

<p>This allows Crawl4AI to be flexible. Different strategies might use different underlying libraries or have different performance characteristics.</p>

<h2 id="the-implementations-meet-the-editors">The Implementations: Meet the Editors</h2>

<p>Crawl4AI provides concrete implementations (the actual editors doing the work) of this strategy:</p>

<ol>
  <li><strong><code class="language-plaintext highlighter-rouge">WebScrapingStrategy</code> (The Default Editor):</strong>
    <ul>
      <li>This is the strategy used by default if you don’t specify otherwise.</li>
      <li>It uses a popular Python library called <code class="language-plaintext highlighter-rouge">BeautifulSoup</code> behind the scenes to parse and manipulate the HTML.</li>
      <li>It’s generally robust and good at handling imperfect HTML.</li>
      <li>Think of it as a reliable, experienced editor who does a thorough job.</li>
    </ul>
  </li>
  <li><strong><code class="language-plaintext highlighter-rouge">LXMLWebScrapingStrategy</code> (The Speedy Editor):</strong>
    <ul>
      <li>This strategy uses another powerful library called <code class="language-plaintext highlighter-rouge">lxml</code>.</li>
      <li><code class="language-plaintext highlighter-rouge">lxml</code> is often faster than <code class="language-plaintext highlighter-rouge">BeautifulSoup</code>, especially on large or complex pages.</li>
      <li>Think of it as a very fast editor who might be slightly stricter about the manuscript’s format but gets the job done quickly.</li>
    </ul>
  </li>
</ol>

<p>For most beginners, the default <code class="language-plaintext highlighter-rouge">WebScrapingStrategy</code> works perfectly fine! You usually don’t need to worry about switching unless you encounter performance issues on very large-scale crawls (which is a more advanced topic).</p>

<h2 id="how-it-works-conceptually">How It Works Conceptually</h2>

<p>Here’s the flow:</p>

<ol>
  <li>The <a href="02_asyncwebcrawler.md">AsyncWebCrawler</a> receives the raw HTML from the <a href="01_asynccrawlerstrategy.md">AsyncCrawlerStrategy</a> (the fetcher).</li>
  <li>It looks at the <a href="03_crawlerrunconfig.md">CrawlerRunConfig</a> to see which <code class="language-plaintext highlighter-rouge">ContentScrapingStrategy</code> to use (defaulting to <code class="language-plaintext highlighter-rouge">WebScrapingStrategy</code> if none is specified).</li>
  <li>It hands the raw HTML over to the chosen strategy’s <code class="language-plaintext highlighter-rouge">scrap</code> method.</li>
  <li>The strategy parses the HTML, removes unwanted tags (like <code class="language-plaintext highlighter-rouge">&lt;script&gt;</code>, <code class="language-plaintext highlighter-rouge">&lt;style&gt;</code>, <code class="language-plaintext highlighter-rouge">&lt;nav&gt;</code>, <code class="language-plaintext highlighter-rouge">&lt;aside&gt;</code>, etc., based on its internal rules), extracts all links (<code class="language-plaintext highlighter-rouge">&lt;a&gt;</code> tags), images (<code class="language-plaintext highlighter-rouge">&lt;img&gt;</code> tags with their <code class="language-plaintext highlighter-rouge">alt</code> text), and metadata (like the <code class="language-plaintext highlighter-rouge">&lt;title&gt;</code> tag).</li>
  <li>It returns the results packaged in a <code class="language-plaintext highlighter-rouge">ScrapingResult</code> object, containing the cleaned HTML, lists of links and media items, and extracted metadata.</li>
  <li>The <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> then takes this <code class="language-plaintext highlighter-rouge">ScrapingResult</code> and uses its contents (along with other info) to build the final <a href="07_crawlresult.md">CrawlResult</a>.</li>
</ol>

<pre><code class="language-mermaid">sequenceDiagram
    participant AWC as AsyncWebCrawler (Manager)
    participant Fetcher as AsyncCrawlerStrategy
    participant HTML as Raw HTML
    participant CSS as ContentScrapingStrategy (Editor)
    participant SR as ScrapingResult (Cleaned Draft)
    participant CR as CrawlResult (Final Report)

    AWC-&gt;&gt;Fetcher: Fetch("https://example.com")
    Fetcher--&gt;&gt;AWC: Here's the Raw HTML
    AWC-&gt;&gt;CSS: Please scrap this Raw HTML (using config)
    Note over CSS: Parsing HTML... Removing scripts, styles, ads... Extracting links, images, title...
    CSS--&gt;&gt;AWC: Here's the ScrapingResult (Cleaned HTML, Links, Media, Metadata)
    AWC-&gt;&gt;CR: Combine ScrapingResult with other info
    AWC--&gt;&gt;User: Return final CrawlResult
</code></pre>

<h2 id="using-the-default-strategy-webscrapingstrategy">Using the Default Strategy (<code class="language-plaintext highlighter-rouge">WebScrapingStrategy</code>)</h2>

<p>You’re likely already using it without realizing it! When you run a basic crawl, <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> automatically employs <code class="language-plaintext highlighter-rouge">WebScrapingStrategy</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chapter4_example_1.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlerRunConfig</span><span class="p">,</span> <span class="n">CacheMode</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># Uses the default AsyncPlaywrightCrawlerStrategy (fetching)
</span>    <span class="c1"># AND the default WebScrapingStrategy (scraping/cleaning)
</span>    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">url_to_crawl</span> <span class="o">=</span> <span class="s">"https://httpbin.org/html"</span> <span class="c1"># A very simple HTML page
</span>
        <span class="c1"># We don't specify a scraping_strategy in the config, so it uses the default
</span>        <span class="n">config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span><span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">BYPASS</span><span class="p">)</span> <span class="c1"># Fetch fresh
</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Crawling </span><span class="si">{</span><span class="n">url_to_crawl</span><span class="si">}</span><span class="s"> using default scraping strategy..."</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url_to_crawl</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">success</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Success! Content fetched and scraped."</span><span class="p">)</span>
            <span class="c1"># The 'result' object now contains info processed by WebScrapingStrategy
</span>
            <span class="c1"># 1. Metadata extracted (e.g., page title)
</span>            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Page Title: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">metadata</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'title'</span><span class="p">,</span> <span class="s">'N/A'</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

            <span class="c1"># 2. Links extracted
</span>            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Found </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="n">internal</span><span class="p">)</span><span class="si">}</span><span class="s"> internal links and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="n">external</span><span class="p">)</span><span class="si">}</span><span class="s"> external links."</span><span class="p">)</span>
            <span class="c1"># Example: print first external link if exists
</span>            <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="n">external</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Example external link: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="n">external</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">href</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

            <span class="c1"># 3. Media extracted (images, videos, etc.)
</span>            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Found </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">media</span><span class="p">.</span><span class="n">images</span><span class="p">)</span><span class="si">}</span><span class="s"> images."</span><span class="p">)</span>
             <span class="c1"># Example: print first image alt text if exists
</span>            <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">media</span><span class="p">.</span><span class="n">images</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Example image alt text: '</span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">media</span><span class="p">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">alt</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>

            <span class="c1"># 4. Cleaned HTML (scripts, styles etc. removed) - might still be complex
</span>            <span class="c1"># print(f"\nCleaned HTML snippet:\n---\n{result.cleaned_html[:200]}...\n---")
</span>
            <span class="c1"># 5. Markdown representation (generated AFTER scraping)
</span>            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Markdown snippet:</span><span class="se">\n</span><span class="s">---</span><span class="se">\n</span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">markdown</span><span class="p">.</span><span class="n">raw_markdown</span><span class="p">[</span><span class="si">:</span><span class="mi">200</span><span class="p">]</span><span class="si">}</span><span class="s">...</span><span class="se">\n</span><span class="s">---"</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Failed: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">error_message</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div>

<p><strong>Explanation:</strong></p>

<ol>
  <li>We create <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> and <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> as usual.</li>
  <li>We <strong>don’t</strong> set the <code class="language-plaintext highlighter-rouge">scraping_strategy</code> parameter in <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code>. Crawl4AI automatically picks <code class="language-plaintext highlighter-rouge">WebScrapingStrategy</code>.</li>
  <li>When <code class="language-plaintext highlighter-rouge">crawler.arun</code> executes, after fetching the HTML, it internally calls <code class="language-plaintext highlighter-rouge">WebScrapingStrategy.scrap()</code>.</li>
  <li>The <code class="language-plaintext highlighter-rouge">result</code> (a <a href="07_crawlresult.md">CrawlResult</a> object) contains fields populated by the scraping strategy:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">result.metadata</code>: Contains things like the page title found in <code class="language-plaintext highlighter-rouge">&lt;title&gt;</code> tags.</li>
      <li><code class="language-plaintext highlighter-rouge">result.links</code>: Contains lists of internal and external links found (<code class="language-plaintext highlighter-rouge">&lt;a&gt;</code> tags).</li>
      <li><code class="language-plaintext highlighter-rouge">result.media</code>: Contains lists of images (<code class="language-plaintext highlighter-rouge">&lt;img&gt;</code>), videos (<code class="language-plaintext highlighter-rouge">&lt;video&gt;</code>), etc.</li>
      <li><code class="language-plaintext highlighter-rouge">result.cleaned_html</code>: The HTML after the strategy removed unwanted tags and attributes (this is then used to generate the Markdown).</li>
      <li><code class="language-plaintext highlighter-rouge">result.markdown</code>: While not <em>directly</em> created by the scraping strategy, the cleaned HTML it produces is the input for generating the Markdown representation.</li>
    </ul>
  </li>
</ol>

<h2 id="explicitly-choosing-a-strategy-eg-lxmlwebscrapingstrategy">Explicitly Choosing a Strategy (e.g., <code class="language-plaintext highlighter-rouge">LXMLWebScrapingStrategy</code>)</h2>

<p>What if you want to try the potentially faster <code class="language-plaintext highlighter-rouge">LXMLWebScrapingStrategy</code>? You can specify it in the <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chapter4_example_2.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlerRunConfig</span><span class="p">,</span> <span class="n">CacheMode</span>
<span class="c1"># 1. Import the specific strategy you want to use
</span><span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">LXMLWebScrapingStrategy</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># 2. Create an instance of the desired scraping strategy
</span>    <span class="n">lxml_editor</span> <span class="o">=</span> <span class="n">LXMLWebScrapingStrategy</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Using scraper: </span><span class="si">{</span><span class="n">lxml_editor</span><span class="p">.</span><span class="n">__class__</span><span class="p">.</span><span class="n">__name__</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">url_to_crawl</span> <span class="o">=</span> <span class="s">"https://httpbin.org/html"</span>

        <span class="c1"># 3. Create a CrawlerRunConfig and pass the strategy instance
</span>        <span class="n">config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span>
            <span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">BYPASS</span><span class="p">,</span>
            <span class="n">scraping_strategy</span><span class="o">=</span><span class="n">lxml_editor</span> <span class="c1"># Tell the config which strategy to use
</span>        <span class="p">)</span>

        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Crawling </span><span class="si">{</span><span class="n">url_to_crawl</span><span class="si">}</span><span class="s"> with explicit LXML scraping strategy..."</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url_to_crawl</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">success</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Success! Content fetched and scraped using LXML."</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Page Title: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">metadata</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'title'</span><span class="p">,</span> <span class="s">'N/A'</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Found </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="n">external</span><span class="p">)</span><span class="si">}</span><span class="s"> external links."</span><span class="p">)</span>
            <span class="c1"># Output should be largely the same as the default strategy for simple pages
</span>        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Failed: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">error_message</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div>

<p><strong>Explanation:</strong></p>

<ol>
  <li><strong>Import:</strong> We import <code class="language-plaintext highlighter-rouge">LXMLWebScrapingStrategy</code> alongside the other classes.</li>
  <li><strong>Instantiate:</strong> We create an instance: <code class="language-plaintext highlighter-rouge">lxml_editor = LXMLWebScrapingStrategy()</code>.</li>
  <li><strong>Configure:</strong> We create <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> and pass our instance to the <code class="language-plaintext highlighter-rouge">scraping_strategy</code> parameter: <code class="language-plaintext highlighter-rouge">CrawlerRunConfig(..., scraping_strategy=lxml_editor)</code>.</li>
  <li><strong>Run:</strong> Now, when <code class="language-plaintext highlighter-rouge">crawler.arun</code> is called with this config, it will use <code class="language-plaintext highlighter-rouge">LXMLWebScrapingStrategy</code> instead of the default <code class="language-plaintext highlighter-rouge">WebScrapingStrategy</code> for the initial HTML processing step.</li>
</ol>

<p>For simple pages, the results from both strategies will often be very similar. The choice typically comes down to performance considerations in more advanced scenarios.</p>

<h2 id="a-glimpse-under-the-hood">A Glimpse Under the Hood</h2>

<p>Inside the <code class="language-plaintext highlighter-rouge">crawl4ai</code> library, the file <code class="language-plaintext highlighter-rouge">content_scraping_strategy.py</code> defines the blueprint and the implementations.</p>

<p><strong>The Blueprint (Abstract Base Class):</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified from crawl4ai/content_scraping_strategy.py
</span><span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">.models</span> <span class="kn">import</span> <span class="n">ScrapingResult</span> <span class="c1"># Defines the structure of the result
</span>
<span class="k">class</span> <span class="nc">ContentScrapingStrategy</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="s">"""Abstract base class for content scraping strategies."""</span>

    <span class="o">@</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">scrap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">html</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScrapingResult</span><span class="p">:</span>
        <span class="s">"""
        Synchronous method to scrape content.
        Takes raw HTML, returns structured ScrapingResult.
        """</span>
        <span class="k">pass</span>

    <span class="o">@</span><span class="n">abstractmethod</span>
    <span class="k">async</span> <span class="k">def</span> <span class="nf">ascrap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">html</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScrapingResult</span><span class="p">:</span>
        <span class="s">"""
        Asynchronous method to scrape content.
        Takes raw HTML, returns structured ScrapingResult.
        """</span>
        <span class="k">pass</span>
</code></pre></div></div>

<p><strong>The Implementations:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified from crawl4ai/content_scraping_strategy.py
</span><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span> <span class="c1"># Library used by WebScrapingStrategy
# ... other imports like models ...
</span>
<span class="k">class</span> <span class="nc">WebScrapingStrategy</span><span class="p">(</span><span class="n">ContentScrapingStrategy</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logger</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">logger</span>
        <span class="c1"># ... potentially other setup ...
</span>
    <span class="k">def</span> <span class="nf">scrap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">html</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScrapingResult</span><span class="p">:</span>
        <span class="c1"># 1. Parse HTML using BeautifulSoup
</span>        <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s">'lxml'</span><span class="p">)</span> <span class="c1"># Or another parser
</span>
        <span class="c1"># 2. Find the main content area (maybe using kwargs['css_selector'])
</span>        <span class="c1"># 3. Remove unwanted tags (scripts, styles, nav, footer, ads...)
</span>        <span class="c1"># 4. Extract metadata (title, description...)
</span>        <span class="c1"># 5. Extract all links (&lt;a&gt; tags)
</span>        <span class="c1"># 6. Extract all images (&lt;img&gt; tags) and other media
</span>        <span class="c1"># 7. Get the remaining cleaned HTML text content
</span>
        <span class="c1"># ... complex cleaning and extraction logic using BeautifulSoup methods ...
</span>
        <span class="c1"># 8. Package results into a ScrapingResult object
</span>        <span class="n">cleaned_html_content</span> <span class="o">=</span> <span class="s">"&lt;html&gt;&lt;body&gt;Cleaned content...&lt;/body&gt;&lt;/html&gt;"</span> <span class="c1"># Placeholder
</span>        <span class="n">links_data</span> <span class="o">=</span> <span class="n">Links</span><span class="p">(...)</span>
        <span class="n">media_data</span> <span class="o">=</span> <span class="n">Media</span><span class="p">(...)</span>
        <span class="n">metadata_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s">"title"</span><span class="p">:</span> <span class="s">"Page Title"</span><span class="p">}</span>

        <span class="k">return</span> <span class="n">ScrapingResult</span><span class="p">(</span>
            <span class="n">cleaned_html</span><span class="o">=</span><span class="n">cleaned_html_content</span><span class="p">,</span>
            <span class="n">links</span><span class="o">=</span><span class="n">links_data</span><span class="p">,</span>
            <span class="n">media</span><span class="o">=</span><span class="n">media_data</span><span class="p">,</span>
            <span class="n">metadata</span><span class="o">=</span><span class="n">metadata_dict</span><span class="p">,</span>
            <span class="n">success</span><span class="o">=</span><span class="bp">True</span>
        <span class="p">)</span>

    <span class="k">async</span> <span class="k">def</span> <span class="nf">ascrap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">html</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScrapingResult</span><span class="p">:</span>
        <span class="c1"># Often delegates to the synchronous version for CPU-bound tasks
</span>        <span class="k">return</span> <span class="k">await</span> <span class="n">asyncio</span><span class="p">.</span><span class="n">to_thread</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">scrap</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">html</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified from crawl4ai/content_scraping_strategy.py
</span><span class="kn">from</span> <span class="nn">lxml</span> <span class="kn">import</span> <span class="n">html</span> <span class="k">as</span> <span class="n">lhtml</span> <span class="c1"># Library used by LXMLWebScrapingStrategy
# ... other imports like models ...
</span>
<span class="k">class</span> <span class="nc">LXMLWebScrapingStrategy</span><span class="p">(</span><span class="n">WebScrapingStrategy</span><span class="p">):</span> <span class="c1"># Often inherits for shared logic
</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logger</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">logger</span><span class="p">)</span>
        <span class="c1"># ... potentially LXML specific setup ...
</span>
    <span class="k">def</span> <span class="nf">scrap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">html</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScrapingResult</span><span class="p">:</span>
        <span class="c1"># 1. Parse HTML using lxml
</span>        <span class="n">doc</span> <span class="o">=</span> <span class="n">lhtml</span><span class="p">.</span><span class="n">document_fromstring</span><span class="p">(</span><span class="n">html</span><span class="p">)</span>

        <span class="c1"># 2. Find main content, remove unwanted tags, extract info
</span>        <span class="c1"># ... complex cleaning and extraction logic using lxml's XPath or CSS selectors ...
</span>
        <span class="c1"># 3. Package results into a ScrapingResult object
</span>        <span class="n">cleaned_html_content</span> <span class="o">=</span> <span class="s">"&lt;html&gt;&lt;body&gt;Cleaned LXML content...&lt;/body&gt;&lt;/html&gt;"</span> <span class="c1"># Placeholder
</span>        <span class="n">links_data</span> <span class="o">=</span> <span class="n">Links</span><span class="p">(...)</span>
        <span class="n">media_data</span> <span class="o">=</span> <span class="n">Media</span><span class="p">(...)</span>
        <span class="n">metadata_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s">"title"</span><span class="p">:</span> <span class="s">"Page Title LXML"</span><span class="p">}</span>

        <span class="k">return</span> <span class="n">ScrapingResult</span><span class="p">(</span>
            <span class="n">cleaned_html</span><span class="o">=</span><span class="n">cleaned_html_content</span><span class="p">,</span>
            <span class="n">links</span><span class="o">=</span><span class="n">links_data</span><span class="p">,</span>
            <span class="n">media</span><span class="o">=</span><span class="n">media_data</span><span class="p">,</span>
            <span class="n">metadata</span><span class="o">=</span><span class="n">metadata_dict</span><span class="p">,</span>
            <span class="n">success</span><span class="o">=</span><span class="bp">True</span>
        <span class="p">)</span>

    <span class="c1"># ascrap might also delegate or have specific async optimizations
</span></code></pre></div></div>

<p>The key takeaway is that both strategies implement the <code class="language-plaintext highlighter-rouge">scrap</code> (and <code class="language-plaintext highlighter-rouge">ascrap</code>) method, taking raw HTML and returning a structured <code class="language-plaintext highlighter-rouge">ScrapingResult</code>. The <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> can use either one thanks to this common interface.</p>

<h2 id="conclusion">Conclusion</h2>

<p>You’ve learned about <code class="language-plaintext highlighter-rouge">ContentScrapingStrategy</code>, Crawl4AI’s “First Pass Editor” for raw HTML.</p>

<ul>
  <li>It tackles the problem of messy HTML by cleaning it and extracting basic structure.</li>
  <li>It acts as a blueprint, with <code class="language-plaintext highlighter-rouge">WebScrapingStrategy</code> (default, using BeautifulSoup) and <code class="language-plaintext highlighter-rouge">LXMLWebScrapingStrategy</code> (using lxml) as concrete implementations.</li>
  <li>It’s used automatically by <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> after fetching content.</li>
  <li>You can specify which strategy to use via <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code>.</li>
  <li>Its output (cleaned HTML, links, media, metadata) is packaged into a <code class="language-plaintext highlighter-rouge">ScrapingResult</code> and contributes significantly to the final <code class="language-plaintext highlighter-rouge">CrawlResult</code>.</li>
</ul>

<p>Now that we have this initially cleaned and structured content, we might want to further filter it. What if we only care about the parts of the page that are <em>relevant</em> to a specific topic?</p>

<p><strong>Next:</strong> Let’s explore how to filter content for relevance with <a href="05_relevantcontentfilter.md">Chapter 5: Focusing on What Matters - RelevantContentFilter</a>.</p>

<hr />

<p>Generated by <a href="https://github.com/The-Pocket/Tutorial-Codebase-Knowledge">AI Codebase Knowledge Builder</a></p>
