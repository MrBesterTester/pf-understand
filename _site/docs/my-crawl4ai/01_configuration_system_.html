<h1 id="chapter-1-configuration-system">Chapter 1: Configuration System</h1>

<p>Welcome to the first chapter of our Crawl4AI tutorial! Today, we’re going to learn about the Configuration System, which is the foundation for controlling how our web crawler works.</p>

<h2 id="what-is-the-configuration-system">What is the Configuration System?</h2>

<p>Imagine you’re setting up a smart camera to take photos of a building. First, you need to adjust the camera settings (like focus, zoom, and flash), and then you decide how to process the photos (like applying filters or cropping).</p>

<p>The Configuration System in Crawl4AI works in a similar way:</p>

<ol>
  <li><strong>BrowserConfig</strong>: Like adjusting your camera settings, this configures the web browser that will visit websites</li>
  <li><strong>CrawlerRunConfig</strong>: Like choosing how to process your photos, this determines how the web content is processed after it’s fetched</li>
</ol>

<p>Let’s explore how to use these configurations to control our web crawler!</p>

<h2 id="browserconfig-setting-up-your-browser">BrowserConfig: Setting Up Your Browser</h2>

<p>The <code class="language-plaintext highlighter-rouge">BrowserConfig</code> class allows you to customize the browser that Crawl4AI will use to visit websites. Here’s a simple example:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">BrowserConfig</span><span class="p">,</span> <span class="n">AsyncWebCrawler</span>

<span class="c1"># Create a browser configuration
</span><span class="n">browser_config</span> <span class="o">=</span> <span class="n">BrowserConfig</span><span class="p">(</span>
    <span class="n">browser_type</span><span class="o">=</span><span class="s">"chromium"</span><span class="p">,</span>
    <span class="n">headless</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">user_agent</span><span class="o">=</span><span class="s">"Mozilla/5.0 ..."</span>
<span class="p">)</span>

<span class="c1"># Create a crawler with our browser configuration
</span><span class="n">crawler</span> <span class="o">=</span> <span class="n">AsyncWebCrawler</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">browser_config</span><span class="p">)</span>
</code></pre></div></div>

<p>In this example, we’re configuring:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">browser_type</code>: We’re using “chromium” (you could also use “firefox”)</li>
  <li><code class="language-plaintext highlighter-rouge">headless</code>: When set to True, the browser runs in the background without a visible window</li>
  <li><code class="language-plaintext highlighter-rouge">user_agent</code>: This is how the browser identifies itself to websites</li>
</ul>

<p>Think of <code class="language-plaintext highlighter-rouge">BrowserConfig</code> as setting up your tools before you start working.</p>

<h2 id="crawlerrunconfig-processing-the-content">CrawlerRunConfig: Processing the Content</h2>

<p>Once the browser has loaded a webpage, <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> controls what happens next. This includes how content is extracted, transformed, and cached:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">CrawlerRunConfig</span>
<span class="kn">from</span> <span class="nn">crawl4ai.cache_context</span> <span class="kn">import</span> <span class="n">CacheMode</span>

<span class="c1"># Create a crawler configuration
</span><span class="n">crawler_config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span>
    <span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">ENABLED</span><span class="p">,</span>
    <span class="n">screenshot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>
</code></pre></div></div>

<p>In this example:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">cache_mode</code>: Determines if and how to use the cache (store previously visited pages)</li>
  <li><code class="language-plaintext highlighter-rouge">screenshot</code>: Whether to capture a screenshot of the webpage</li>
  <li><code class="language-plaintext highlighter-rouge">verbose</code>: Whether to provide detailed logging information</li>
</ul>

<p>Think of <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> as giving instructions to a photographer about what kind of photos you want.</p>

<h2 id="putting-it-all-together-a-complete-example">Putting It All Together: A Complete Example</h2>

<p>Let’s see how to use both configurations together:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">BrowserConfig</span><span class="p">,</span> <span class="n">CrawlerRunConfig</span>
<span class="kn">from</span> <span class="nn">crawl4ai.cache_context</span> <span class="kn">import</span> <span class="n">CacheMode</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">crawl_website</span><span class="p">():</span>
    <span class="c1"># Set up the browser
</span>    <span class="n">browser_config</span> <span class="o">=</span> <span class="n">BrowserConfig</span><span class="p">(</span><span class="n">browser_type</span><span class="o">=</span><span class="s">"chromium"</span><span class="p">,</span> <span class="n">headless</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    
    <span class="c1"># Set up the crawler behavior
</span>    <span class="n">crawler_config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span><span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">ENABLED</span><span class="p">,</span> <span class="n">screenshot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    
    <span class="c1"># Create and start the crawler
</span>    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">browser_config</span><span class="p">)</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="c1"># Crawl a website with our configuration
</span>        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s">"https://example.com"</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">crawler_config</span><span class="p">)</span>
        
        <span class="c1"># Print the markdown content we extracted
</span>        <span class="k">print</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">markdown</span><span class="p">)</span>

<span class="c1"># Run the async function
</span><span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">crawl_website</span><span class="p">())</span>
</code></pre></div></div>

<p>This code:</p>
<ol>
  <li>Sets up a headless Chromium browser</li>
  <li>Configures the crawler to use caching and take screenshots</li>
  <li>Creates a crawler with our browser configuration</li>
  <li>Runs the crawler on example.com using our crawler configuration</li>
  <li>Prints the extracted markdown content</li>
</ol>

<h2 id="understanding-cache-modes">Understanding Cache Modes</h2>

<p>One important aspect of configuration is controlling how caching works. The <code class="language-plaintext highlighter-rouge">CacheMode</code> enum offers several options:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai.cache_context</span> <span class="kn">import</span> <span class="n">CacheMode</span>

<span class="c1"># Use the cache (read and write)
</span><span class="n">config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span><span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">ENABLED</span><span class="p">)</span>

<span class="c1"># Don't use the cache at all
</span><span class="n">config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span><span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">DISABLED</span><span class="p">)</span>

<span class="c1"># Only read from cache, don't write
</span><span class="n">config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span><span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">READ_ONLY</span><span class="p">)</span>
</code></pre></div></div>

<p>Caching can greatly improve performance by avoiding unnecessary repeated downloads of the same content.</p>

<h2 id="what-happens-under-the-hood">What Happens Under the Hood?</h2>

<p>To understand how these configurations work together, let’s look at the flow of a typical crawl operation:</p>

<pre><code class="language-mermaid">sequenceDiagram
    participant User
    participant WebCrawler
    participant Browser
    participant Cache
    participant Processor

    User-&gt;&gt;WebCrawler: Create with BrowserConfig
    WebCrawler-&gt;&gt;Browser: Initialize with settings
    User-&gt;&gt;WebCrawler: arun(url, CrawlerRunConfig)
    WebCrawler-&gt;&gt;Cache: Check if URL is cached
    
    alt URL is cached and cache_mode allows reading
        Cache-&gt;&gt;WebCrawler: Return cached content
    else URL not cached or bypass cache
        WebCrawler-&gt;&gt;Browser: Request URL
        Browser-&gt;&gt;WebCrawler: Return HTML content
        WebCrawler-&gt;&gt;Cache: Store in cache if enabled
    end
    
    WebCrawler-&gt;&gt;Processor: Process content (extract, transform)
    Processor-&gt;&gt;WebCrawler: Return processed result
    WebCrawler-&gt;&gt;User: Return final result
</code></pre>

<p>Let’s explore the implementation details:</p>

<p>When you create an <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> with a <code class="language-plaintext highlighter-rouge">BrowserConfig</code>, the crawler initializes a browser instance with your specified settings:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># From crawl4ai/async_webcrawler.py
</span><span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">crawler_strategy</span><span class="p">:</span> <span class="n">AsyncCrawlerStrategy</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="n">config</span><span class="p">:</span> <span class="n">BrowserConfig</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="n">base_directory</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span>
        <span class="n">os</span><span class="p">.</span><span class="n">getenv</span><span class="p">(</span><span class="s">"CRAWL4_AI_BASE_DIRECTORY"</span><span class="p">,</span> <span class="n">Path</span><span class="p">.</span><span class="n">home</span><span class="p">())),</span>
    <span class="n">thread_safe</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
    <span class="n">logger</span><span class="p">:</span> <span class="n">AsyncLoggerBase</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
    <span class="c1"># Handle browser configuration
</span>    <span class="n">browser_config</span> <span class="o">=</span> <span class="n">config</span> <span class="ow">or</span> <span class="n">BrowserConfig</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">browser_config</span> <span class="o">=</span> <span class="n">browser_config</span>
    
    <span class="c1"># Initialize crawler strategy
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">crawler_strategy</span> <span class="o">=</span> <span class="n">crawler_strategy</span> <span class="ow">or</span> <span class="n">AsyncPlaywrightCrawlerStrategy</span><span class="p">(</span>
        <span class="n">browser_config</span><span class="o">=</span><span class="n">browser_config</span><span class="p">,</span>
        <span class="n">logger</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">logger</span><span class="p">,</span>
        <span class="o">**</span><span class="n">params</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></div>

<p>Then, when you call <code class="language-plaintext highlighter-rouge">arun()</code> with a URL and <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code>, the crawler first checks if it should use a cached version:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create cache context
</span><span class="n">cache_context</span> <span class="o">=</span> <span class="n">CacheContext</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">cache_mode</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

<span class="c1"># Try to get cached result if appropriate
</span><span class="k">if</span> <span class="n">cache_context</span><span class="p">.</span><span class="n">should_read</span><span class="p">():</span>
    <span class="n">cached_result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">async_db_manager</span><span class="p">.</span><span class="n">aget_cached_url</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</code></pre></div></div>

<p>If the content isn’t cached or shouldn’t be read from cache, the crawler retrieves it using the browser:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">async_response</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="p">.</span><span class="n">crawler_strategy</span><span class="p">.</span><span class="n">crawl</span><span class="p">(</span>
    <span class="n">url</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>  <span class="c1"># Pass the entire config object
</span><span class="p">)</span>
</code></pre></div></div>

<p>Finally, the HTML content is processed according to your configuration:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">crawl_result</span><span class="p">:</span> <span class="n">CrawlResult</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="p">.</span><span class="n">aprocess_html</span><span class="p">(</span>
    <span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span>
    <span class="n">html</span><span class="o">=</span><span class="n">html</span><span class="p">,</span>
    <span class="n">extracted_content</span><span class="o">=</span><span class="n">extracted_content</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
    <span class="n">screenshot_data</span><span class="o">=</span><span class="n">screenshot_data</span><span class="p">,</span>
    <span class="n">pdf_data</span><span class="o">=</span><span class="n">pdf_data</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">verbose</span><span class="p">,</span>
    <span class="n">is_raw_html</span><span class="o">=</span><span class="bp">True</span> <span class="k">if</span> <span class="n">url</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">"raw:"</span><span class="p">)</span> <span class="k">else</span> <span class="bp">False</span><span class="p">,</span>
    <span class="n">redirected_url</span><span class="o">=</span><span class="n">async_response</span><span class="p">.</span><span class="n">redirected_url</span><span class="p">,</span> 
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div>

<h2 id="common-configuration-options">Common Configuration Options</h2>

<p>Let’s look at some common configuration options you might want to use:</p>

<h3 id="browserconfig-options">BrowserConfig Options</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">browser_config</span> <span class="o">=</span> <span class="n">BrowserConfig</span><span class="p">(</span>
    <span class="n">browser_type</span><span class="o">=</span><span class="s">"chromium"</span><span class="p">,</span>  <span class="c1"># "chromium" or "firefox"
</span>    <span class="n">headless</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>            <span class="c1"># Run without a visible window
</span>    <span class="n">viewport_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1280</span><span class="p">,</span> <span class="mi">720</span><span class="p">),</span>  <span class="c1"># Width and height of browser window
</span>    <span class="n">user_agent</span><span class="o">=</span><span class="s">"Custom User Agent"</span><span class="p">,</span>  <span class="c1"># Browser identification
</span>    <span class="n">timeout</span><span class="o">=</span><span class="mi">30000</span><span class="p">,</span>            <span class="c1"># Timeout in milliseconds
</span>    <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span>             <span class="c1"># Detailed logging
</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="crawlerrunconfig-options">CrawlerRunConfig Options</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai.extraction_strategy</span> <span class="kn">import</span> <span class="n">SimpleExtractionStrategy</span>
<span class="kn">from</span> <span class="nn">crawl4ai.chunking_strategy</span> <span class="kn">import</span> <span class="n">RegexChunking</span>

<span class="n">crawler_config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span>
    <span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">ENABLED</span><span class="p">,</span>  <span class="c1"># Cache behavior
</span>    <span class="n">screenshot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>               <span class="c1"># Take screenshots
</span>    <span class="n">pdf</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>                     <span class="c1"># Generate PDF
</span>    <span class="n">extraction_strategy</span><span class="o">=</span><span class="n">SimpleExtractionStrategy</span><span class="p">(),</span>  <span class="c1"># How to extract content
</span>    <span class="n">chunking_strategy</span><span class="o">=</span><span class="n">RegexChunking</span><span class="p">(),</span>  <span class="c1"># How to chunk content
</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>In this chapter, we learned about the Configuration System in Crawl4AI, which consists of two main components:</p>

<ol>
  <li><strong>BrowserConfig</strong>: Controls how the browser behaves when visiting websites</li>
  <li><strong>CrawlerRunConfig</strong>: Controls how the content is processed after it’s fetched</li>
</ol>

<p>By using these configurations together, you can customize how Crawl4AI interacts with websites and processes their content. This flexibility allows you to adapt the crawler to different use cases and requirements.</p>

<p>In the next chapter, <a href="02_asyncwebcrawler_.md">AsyncWebCrawler</a>, we’ll dive deeper into how to use the AsyncWebCrawler class to fetch and process web content using the configurations we’ve learned about here.</p>

<hr />

<p>Generated by <a href="https://github.com/The-Pocket/Tutorial-Codebase-Knowledge">AI Codebase Knowledge Builder</a></p>
