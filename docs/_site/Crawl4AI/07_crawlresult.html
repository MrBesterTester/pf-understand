<h1 id="chapter-7-understanding-the-results---crawlresult">Chapter 7: Understanding the Results - CrawlResult</h1>

<p>In the previous chapter, <a href="06_extractionstrategy.md">Chapter 6: Getting Specific Data - ExtractionStrategy</a>, we learned how to teach Crawl4AI to act like an analyst, extracting specific, structured data points from a webpage using an <code class="language-plaintext highlighter-rouge">ExtractionStrategy</code>. We’ve seen how Crawl4AI can fetch pages, clean them, filter them, and even extract precise information.</p>

<p>But after all that work, where does all the gathered information go? When you ask the <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> to crawl a URL using <code class="language-plaintext highlighter-rouge">arun()</code>, what do you actually get back?</p>

<h2 id="what-problem-does-crawlresult-solve">What Problem Does <code class="language-plaintext highlighter-rouge">CrawlResult</code> Solve?</h2>

<p>Imagine you sent a research assistant to the library (a website) with a set of instructions: “Find this book (URL), make a clean copy of the relevant chapter (clean HTML/Markdown), list all the cited references (links), take photos of the illustrations (media), find the author and publication date (metadata), and maybe extract specific quotes (structured data).”</p>

<p>When the assistant returns, they wouldn’t just hand you a single piece of paper. They’d likely give you a folder containing everything you asked for: the clean copy, the list of references, the photos, the metadata notes, and the extracted quotes, all neatly organized. They might also include a note if they encountered any problems (errors).</p>

<p><code class="language-plaintext highlighter-rouge">CrawlResult</code> is exactly this <strong>final report folder</strong> or <strong>delivery package</strong>. It’s a single object that neatly contains <em>all</em> the information Crawl4AI gathered and processed for a specific URL during a crawl operation. Instead of getting lots of separate pieces of data back, you get one convenient container.</p>

<h2 id="what-is-crawlresult">What is <code class="language-plaintext highlighter-rouge">CrawlResult</code>?</h2>

<p><code class="language-plaintext highlighter-rouge">CrawlResult</code> is a Python object (specifically, a Pydantic model, which is like a super-powered dictionary) that acts as a data container. It holds the results of a single crawl task performed by <code class="language-plaintext highlighter-rouge">AsyncWebCrawler.arun()</code> or one of the results from <code class="language-plaintext highlighter-rouge">arun_many()</code>.</p>

<p>Think of it as a toolbox filled with different tools and information related to the crawled page.</p>

<p><strong>Key Information Stored in <code class="language-plaintext highlighter-rouge">CrawlResult</code>:</strong></p>

<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">url</code> (string):</strong> The original URL that was requested.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">success</code> (boolean):</strong> Did the crawl complete without critical errors? <code class="language-plaintext highlighter-rouge">True</code> if successful, <code class="language-plaintext highlighter-rouge">False</code> otherwise. <strong>Always check this first!</strong></li>
  <li><strong><code class="language-plaintext highlighter-rouge">html</code> (string):</strong> The raw, original HTML source code fetched from the page.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">cleaned_html</code> (string):</strong> The HTML after initial cleaning by the <a href="04_contentscrapingstrategy.md">ContentScrapingStrategy</a> (e.g., scripts, styles removed).</li>
  <li><strong><code class="language-plaintext highlighter-rouge">markdown</code> (object):</strong> An object containing different Markdown representations of the content.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">markdown.raw_markdown</code>: Basic Markdown generated from <code class="language-plaintext highlighter-rouge">cleaned_html</code>.</li>
      <li><code class="language-plaintext highlighter-rouge">markdown.fit_markdown</code>: Markdown generated <em>only</em> from content deemed relevant by a <a href="05_relevantcontentfilter.md">RelevantContentFilter</a> (if one was used). Might be empty if no filter was applied.</li>
      <li><em>(Other fields like <code class="language-plaintext highlighter-rouge">markdown_with_citations</code> might exist)</em></li>
    </ul>
  </li>
  <li><strong><code class="language-plaintext highlighter-rouge">extracted_content</code> (string):</strong> If you used an <a href="06_extractionstrategy.md">ExtractionStrategy</a>, this holds the extracted structured data, usually formatted as a JSON string. <code class="language-plaintext highlighter-rouge">None</code> if no extraction was performed or nothing was found.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">metadata</code> (dictionary):</strong> Information extracted from the page’s metadata tags, like the page title (<code class="language-plaintext highlighter-rouge">metadata['title']</code>), description, keywords, etc.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">links</code> (object):</strong> Contains lists of links found on the page.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">links.internal</code>: List of links pointing to the same website.</li>
      <li><code class="language-plaintext highlighter-rouge">links.external</code>: List of links pointing to other websites.</li>
    </ul>
  </li>
  <li><strong><code class="language-plaintext highlighter-rouge">media</code> (object):</strong> Contains lists of media items found.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">media.images</code>: List of images (<code class="language-plaintext highlighter-rouge">&lt;img&gt;</code> tags).</li>
      <li><code class="language-plaintext highlighter-rouge">media.videos</code>: List of videos (<code class="language-plaintext highlighter-rouge">&lt;video&gt;</code> tags).</li>
      <li><em>(Other media types might be included)</em></li>
    </ul>
  </li>
  <li><strong><code class="language-plaintext highlighter-rouge">screenshot</code> (string):</strong> If you requested a screenshot (<code class="language-plaintext highlighter-rouge">screenshot=True</code> in <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code>), this holds the file path to the saved image. <code class="language-plaintext highlighter-rouge">None</code> otherwise.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">pdf</code> (bytes):</strong> If you requested a PDF (<code class="language-plaintext highlighter-rouge">pdf=True</code> in <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code>), this holds the PDF data as bytes. <code class="language-plaintext highlighter-rouge">None</code> otherwise. (Note: Previously might have been a path, now often bytes).</li>
  <li><strong><code class="language-plaintext highlighter-rouge">error_message</code> (string):</strong> If <code class="language-plaintext highlighter-rouge">success</code> is <code class="language-plaintext highlighter-rouge">False</code>, this field usually contains details about what went wrong.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">status_code</code> (integer):</strong> The HTTP status code received from the server (e.g., 200 for OK, 404 for Not Found).</li>
  <li><strong><code class="language-plaintext highlighter-rouge">response_headers</code> (dictionary):</strong> The HTTP response headers sent by the server.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">redirected_url</code> (string):</strong> If the original URL redirected, this shows the final URL the crawler landed on.</li>
</ul>

<h2 id="accessing-the-crawlresult">Accessing the <code class="language-plaintext highlighter-rouge">CrawlResult</code></h2>

<p>You get a <code class="language-plaintext highlighter-rouge">CrawlResult</code> object back every time you <code class="language-plaintext highlighter-rouge">await</code> a call to <code class="language-plaintext highlighter-rouge">crawler.arun()</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chapter7_example_1.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">url</span> <span class="o">=</span> <span class="s">"https://httpbin.org/html"</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Crawling </span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s">..."</span><span class="p">)</span>

        <span class="c1"># The 'arun' method returns a CrawlResult object
</span>        <span class="n">result</span><span class="p">:</span> <span class="n">CrawlResult</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">)</span> <span class="c1"># Type hint optional
</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Crawl finished!"</span><span class="p">)</span>
        <span class="c1"># Now 'result' holds all the information
</span>        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Result object type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div>

<p><strong>Explanation:</strong></p>

<ol>
  <li>We call <code class="language-plaintext highlighter-rouge">crawler.arun(url=url)</code>.</li>
  <li>The <code class="language-plaintext highlighter-rouge">await</code> keyword pauses execution until the crawl is complete.</li>
  <li>The value returned by <code class="language-plaintext highlighter-rouge">arun</code> is assigned to the <code class="language-plaintext highlighter-rouge">result</code> variable.</li>
  <li>This <code class="language-plaintext highlighter-rouge">result</code> variable is our <code class="language-plaintext highlighter-rouge">CrawlResult</code> object.</li>
</ol>

<p>If you use <code class="language-plaintext highlighter-rouge">crawler.arun_many()</code>, it returns a list where each item is a <code class="language-plaintext highlighter-rouge">CrawlResult</code> object for one of the requested URLs (or an async generator if <code class="language-plaintext highlighter-rouge">stream=True</code>).</p>

<h2 id="exploring-the-attributes-using-the-toolbox">Exploring the Attributes: Using the Toolbox</h2>

<p>Once you have the <code class="language-plaintext highlighter-rouge">result</code> object, you can access its attributes using dot notation (e.g., <code class="language-plaintext highlighter-rouge">result.success</code>, <code class="language-plaintext highlighter-rouge">result.markdown</code>).</p>

<p><strong>1. Checking for Success (Most Important!)</strong></p>

<p>Before you try to use any data, always check if the crawl was successful:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chapter7_example_2.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlResult</span> <span class="c1"># Import CrawlResult for type hint
</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">url</span> <span class="o">=</span> <span class="s">"https://httpbin.org/html"</span> <span class="c1"># A working URL
</span>        <span class="c1"># url = "https://httpbin.org/status/404" # Try this URL to see failure
</span>        <span class="n">result</span><span class="p">:</span> <span class="n">CrawlResult</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">)</span>

        <span class="c1"># --- ALWAYS CHECK 'success' FIRST! ---
</span>        <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">success</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"✅ Successfully crawled: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">url</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="c1"># Now it's safe to access other attributes
</span>            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"   Page Title: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">metadata</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'title'</span><span class="p">,</span> <span class="s">'N/A'</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"❌ Failed to crawl: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">url</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"   Error: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">error_message</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"   Status Code: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">status_code</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div>

<p><strong>Explanation:</strong></p>

<ul>
  <li>We use an <code class="language-plaintext highlighter-rouge">if result.success:</code> block.</li>
  <li>If <code class="language-plaintext highlighter-rouge">True</code>, we proceed to access other data like <code class="language-plaintext highlighter-rouge">result.metadata</code>.</li>
  <li>If <code class="language-plaintext highlighter-rouge">False</code>, we print the <code class="language-plaintext highlighter-rouge">result.error_message</code> and <code class="language-plaintext highlighter-rouge">result.status_code</code> to understand why it failed.</li>
</ul>

<p><strong>2. Accessing Content (HTML, Markdown)</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chapter7_example_3.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlResult</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">url</span> <span class="o">=</span> <span class="s">"https://httpbin.org/html"</span>
        <span class="n">result</span><span class="p">:</span> <span class="n">CrawlResult</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">success</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"--- Content ---"</span><span class="p">)</span>
            <span class="c1"># Print the first 150 chars of raw HTML
</span>            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Raw HTML snippet: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">html</span><span class="p">[</span><span class="si">:</span><span class="mi">150</span><span class="p">]</span><span class="si">}</span><span class="s">..."</span><span class="p">)</span>

            <span class="c1"># Access the raw markdown
</span>            <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">markdown</span><span class="p">:</span> <span class="c1"># Check if markdown object exists
</span>                 <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Markdown snippet: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">markdown</span><span class="p">.</span><span class="n">raw_markdown</span><span class="p">[</span><span class="si">:</span><span class="mi">150</span><span class="p">]</span><span class="si">}</span><span class="s">..."</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                 <span class="k">print</span><span class="p">(</span><span class="s">"Markdown not generated."</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Crawl failed: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">error_message</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div>

<p><strong>Explanation:</strong></p>

<ul>
  <li>We access <code class="language-plaintext highlighter-rouge">result.html</code> for the original HTML.</li>
  <li>We access <code class="language-plaintext highlighter-rouge">result.markdown.raw_markdown</code> for the main Markdown content. Note the two dots: <code class="language-plaintext highlighter-rouge">result.markdown</code> gives the <code class="language-plaintext highlighter-rouge">MarkdownGenerationResult</code> object, and <code class="language-plaintext highlighter-rouge">.raw_markdown</code> accesses the specific string within it. We also check <code class="language-plaintext highlighter-rouge">if result.markdown:</code> first, just in case markdown generation failed for some reason.</li>
</ul>

<p><strong>3. Getting Metadata, Links, and Media</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chapter7_example_4.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlResult</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">url</span> <span class="o">=</span> <span class="s">"https://httpbin.org/links/10/0"</span> <span class="c1"># A page with links
</span>        <span class="n">result</span><span class="p">:</span> <span class="n">CrawlResult</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">success</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"--- Metadata &amp; Links ---"</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Title: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">metadata</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'title'</span><span class="p">,</span> <span class="s">'N/A'</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Found </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="n">internal</span><span class="p">)</span><span class="si">}</span><span class="s"> internal links."</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Found </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="n">external</span><span class="p">)</span><span class="si">}</span><span class="s"> external links."</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="n">internal</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  First internal link text: '</span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="n">internal</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">text</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
            <span class="c1"># Similarly access result.media.images etc.
</span>        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Crawl failed: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">error_message</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div>

<p><strong>Explanation:</strong></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">result.metadata</code> is a dictionary; use <code class="language-plaintext highlighter-rouge">.get()</code> for safe access.</li>
  <li><code class="language-plaintext highlighter-rouge">result.links</code> and <code class="language-plaintext highlighter-rouge">result.media</code> are objects containing lists (<code class="language-plaintext highlighter-rouge">internal</code>, <code class="language-plaintext highlighter-rouge">external</code>, <code class="language-plaintext highlighter-rouge">images</code>, etc.). We can check their lengths (<code class="language-plaintext highlighter-rouge">len()</code>) and access individual items by index (e.g., <code class="language-plaintext highlighter-rouge">[0]</code>).</li>
</ul>

<p><strong>4. Checking for Extracted Data, Screenshots, PDFs</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chapter7_example_5.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlResult</span><span class="p">,</span> <span class="n">CrawlerRunConfig</span><span class="p">,</span>
    <span class="n">JsonCssExtractionStrategy</span> <span class="c1"># Example extractor
</span><span class="p">)</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># Define a simple extraction strategy (from Chapter 6)
</span>    <span class="n">schema</span> <span class="o">=</span> <span class="p">{</span><span class="s">"baseSelector"</span><span class="p">:</span> <span class="s">"body"</span><span class="p">,</span> <span class="s">"fields"</span><span class="p">:</span> <span class="p">[{</span><span class="s">"name"</span><span class="p">:</span> <span class="s">"heading"</span><span class="p">,</span> <span class="s">"selector"</span><span class="p">:</span> <span class="s">"h1"</span><span class="p">,</span> <span class="s">"type"</span><span class="p">:</span> <span class="s">"text"</span><span class="p">}]}</span>
    <span class="n">extractor</span> <span class="o">=</span> <span class="n">JsonCssExtractionStrategy</span><span class="p">(</span><span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">)</span>

    <span class="c1"># Configure the run to extract and take a screenshot
</span>    <span class="n">config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span>
        <span class="n">extraction_strategy</span><span class="o">=</span><span class="n">extractor</span><span class="p">,</span>
        <span class="n">screenshot</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>

    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">url</span> <span class="o">=</span> <span class="s">"https://httpbin.org/html"</span>
        <span class="n">result</span><span class="p">:</span> <span class="n">CrawlResult</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">success</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"--- Extracted Data &amp; Media ---"</span><span class="p">)</span>
            <span class="c1"># Check if structured data was extracted
</span>            <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">extracted_content</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="s">"Extracted Data found:"</span><span class="p">)</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">loads</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">extracted_content</span><span class="p">)</span> <span class="c1"># Parse the JSON string
</span>                <span class="k">print</span><span class="p">(</span><span class="n">json</span><span class="p">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="s">"No structured data extracted."</span><span class="p">)</span>

            <span class="c1"># Check if a screenshot was taken
</span>            <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">screenshot</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Screenshot saved to: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">screenshot</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="s">"Screenshot not taken."</span><span class="p">)</span>

            <span class="c1"># Check for PDF (would be bytes if requested and successful)
</span>            <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">pdf</span><span class="p">:</span>
                 <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"PDF data captured (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">pdf</span><span class="p">)</span><span class="si">}</span><span class="s"> bytes)."</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                 <span class="k">print</span><span class="p">(</span><span class="s">"PDF not generated."</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Crawl failed: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">error_message</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div>

<p><strong>Explanation:</strong></p>

<ul>
  <li>We check if <code class="language-plaintext highlighter-rouge">result.extracted_content</code> is not <code class="language-plaintext highlighter-rouge">None</code> or empty before trying to parse it as JSON.</li>
  <li>We check if <code class="language-plaintext highlighter-rouge">result.screenshot</code> is not <code class="language-plaintext highlighter-rouge">None</code> to see if the file path exists.</li>
  <li>We check if <code class="language-plaintext highlighter-rouge">result.pdf</code> is not <code class="language-plaintext highlighter-rouge">None</code> to see if the PDF data (bytes) was captured.</li>
</ul>

<h2 id="how-is-crawlresult-created-under-the-hood">How is <code class="language-plaintext highlighter-rouge">CrawlResult</code> Created? (Under the Hood)</h2>

<p>You don’t interact with the <code class="language-plaintext highlighter-rouge">CrawlResult</code> constructor directly. The <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> creates it for you at the very end of the <code class="language-plaintext highlighter-rouge">arun</code> process, typically inside its internal <code class="language-plaintext highlighter-rouge">aprocess_html</code> method (or just before returning if fetching from cache).</p>

<p>Here’s a simplified sequence:</p>

<ol>
  <li><strong>Fetch:</strong> <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> calls the <a href="01_asynccrawlerstrategy.md">AsyncCrawlerStrategy</a> to get the raw <code class="language-plaintext highlighter-rouge">html</code>, <code class="language-plaintext highlighter-rouge">status_code</code>, <code class="language-plaintext highlighter-rouge">response_headers</code>, etc.</li>
  <li><strong>Scrape:</strong> It passes the <code class="language-plaintext highlighter-rouge">html</code> to the <a href="04_contentscrapingstrategy.md">ContentScrapingStrategy</a> to get <code class="language-plaintext highlighter-rouge">cleaned_html</code>, <code class="language-plaintext highlighter-rouge">links</code>, <code class="language-plaintext highlighter-rouge">media</code>, <code class="language-plaintext highlighter-rouge">metadata</code>.</li>
  <li><strong>Markdown:</strong> It generates Markdown using the configured generator, possibly involving a <a href="05_relevantcontentfilter.md">RelevantContentFilter</a>, resulting in a <code class="language-plaintext highlighter-rouge">MarkdownGenerationResult</code> object.</li>
  <li><strong>Extract (Optional):</strong> If an <a href="06_extractionstrategy.md">ExtractionStrategy</a> is configured, it runs it on the appropriate content (HTML or Markdown) to get <code class="language-plaintext highlighter-rouge">extracted_content</code>.</li>
  <li><strong>Screenshot/PDF (Optional):</strong> If requested, the fetching strategy captures the <code class="language-plaintext highlighter-rouge">screenshot</code> path or <code class="language-plaintext highlighter-rouge">pdf</code> data.</li>
  <li><strong>Package:</strong> <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> gathers all these pieces (<code class="language-plaintext highlighter-rouge">url</code>, <code class="language-plaintext highlighter-rouge">html</code>, <code class="language-plaintext highlighter-rouge">cleaned_html</code>, the markdown object, <code class="language-plaintext highlighter-rouge">links</code>, <code class="language-plaintext highlighter-rouge">media</code>, <code class="language-plaintext highlighter-rouge">metadata</code>, <code class="language-plaintext highlighter-rouge">extracted_content</code>, <code class="language-plaintext highlighter-rouge">screenshot</code>, <code class="language-plaintext highlighter-rouge">pdf</code>, <code class="language-plaintext highlighter-rouge">success</code> status, <code class="language-plaintext highlighter-rouge">error_message</code>, etc.).</li>
  <li><strong>Instantiate:</strong> It creates the <code class="language-plaintext highlighter-rouge">CrawlResult</code> object, passing all the gathered data into its constructor.</li>
  <li><strong>Return:</strong> It returns this fully populated <code class="language-plaintext highlighter-rouge">CrawlResult</code> object to your code.</li>
</ol>

<h2 id="code-glimpse-modelspy">Code Glimpse (<code class="language-plaintext highlighter-rouge">models.py</code>)</h2>

<p>The <code class="language-plaintext highlighter-rouge">CrawlResult</code> is defined in the <code class="language-plaintext highlighter-rouge">crawl4ai/models.py</code> file. It uses Pydantic, a library that helps define data structures with type hints and validation. Here’s a simplified view:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified from crawl4ai/models.py
</span><span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">HttpUrl</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Any</span>

<span class="c1"># Other related models (simplified)
</span><span class="k">class</span> <span class="nc">MarkdownGenerationResult</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">raw_markdown</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">fit_markdown</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="c1"># ... other markdown fields ...
</span>
<span class="k">class</span> <span class="nc">Links</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">internal</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">external</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">class</span> <span class="nc">Media</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">images</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">videos</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># The main CrawlResult model
</span><span class="k">class</span> <span class="nc">CrawlResult</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">url</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">html</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">success</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">cleaned_html</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">media</span><span class="p">:</span> <span class="n">Media</span> <span class="o">=</span> <span class="n">Media</span><span class="p">()</span> <span class="c1"># Use the Media model
</span>    <span class="n">links</span><span class="p">:</span> <span class="n">Links</span> <span class="o">=</span> <span class="n">Links</span><span class="p">()</span> <span class="c1"># Use the Links model
</span>    <span class="n">screenshot</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">pdf</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bytes</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="c1"># Uses a private attribute and property for markdown for compatibility
</span>    <span class="n">_markdown</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MarkdownGenerationResult</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># Actual storage
</span>    <span class="n">extracted_content</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># JSON string
</span>    <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">error_message</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">status_code</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">response_headers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">redirected_url</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="c1"># ... other fields like session_id, ssl_certificate ...
</span>
    <span class="c1"># Custom property to access markdown data
</span>    <span class="o">@</span><span class="nb">property</span>
    <span class="k">def</span> <span class="nf">markdown</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MarkdownGenerationResult</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_markdown</span>

    <span class="c1"># Configuration for Pydantic
</span>    <span class="k">class</span> <span class="nc">Config</span><span class="p">:</span>
        <span class="n">arbitrary_types_allowed</span> <span class="o">=</span> <span class="bp">True</span>

    <span class="c1"># Custom init and model_dump might exist for backward compatibility handling
</span>    <span class="c1"># ... (omitted for simplicity) ...
</span></code></pre></div></div>

<p><strong>Explanation:</strong></p>

<ul>
  <li>It’s defined as a <code class="language-plaintext highlighter-rouge">class CrawlResult(BaseModel):</code>.</li>
  <li>Each attribute (like <code class="language-plaintext highlighter-rouge">url</code>, <code class="language-plaintext highlighter-rouge">html</code>, <code class="language-plaintext highlighter-rouge">success</code>) is defined with a type hint (like <code class="language-plaintext highlighter-rouge">str</code>, <code class="language-plaintext highlighter-rouge">bool</code>, <code class="language-plaintext highlighter-rouge">Optional[str]</code>). <code class="language-plaintext highlighter-rouge">Optional[str]</code> means the field can be a string or <code class="language-plaintext highlighter-rouge">None</code>.</li>
  <li>Some attributes are themselves complex objects defined by other Pydantic models (like <code class="language-plaintext highlighter-rouge">media: Media</code>, <code class="language-plaintext highlighter-rouge">links: Links</code>).</li>
  <li>The <code class="language-plaintext highlighter-rouge">markdown</code> field uses a common pattern (property wrapping a private attribute) to provide the <code class="language-plaintext highlighter-rouge">MarkdownGenerationResult</code> object while maintaining some backward compatibility. You access it simply as <code class="language-plaintext highlighter-rouge">result.markdown</code>.</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>You’ve now met the <code class="language-plaintext highlighter-rouge">CrawlResult</code> object – the final, comprehensive report delivered by Crawl4AI after processing a URL.</p>

<ul>
  <li>It acts as a <strong>container</strong> holding all gathered information (HTML, Markdown, metadata, links, media, extracted data, errors, etc.).</li>
  <li>It’s the <strong>return value</strong> of <code class="language-plaintext highlighter-rouge">AsyncWebCrawler.arun()</code> and <code class="language-plaintext highlighter-rouge">arun_many()</code>.</li>
  <li>The most crucial attribute is <strong><code class="language-plaintext highlighter-rouge">success</code> (boolean)</strong>, which you should always check first.</li>
  <li>You can easily <strong>access</strong> all the different pieces of information using dot notation (e.g., <code class="language-plaintext highlighter-rouge">result.metadata['title']</code>, <code class="language-plaintext highlighter-rouge">result.markdown.raw_markdown</code>, <code class="language-plaintext highlighter-rouge">result.links.external</code>).</li>
</ul>

<p>Understanding the <code class="language-plaintext highlighter-rouge">CrawlResult</code> is key to effectively using the information Crawl4AI provides.</p>

<p>So far, we’ve focused on crawling single pages or lists of specific URLs. But what if you want to start at one page and automatically discover and crawl linked pages, exploring a website more deeply?</p>

<p><strong>Next:</strong> Let’s explore how to perform multi-page crawls with <a href="08_deepcrawlstrategy.md">Chapter 8: Exploring Websites - DeepCrawlStrategy</a>.</p>

<hr />

<p>Generated by <a href="https://github.com/The-Pocket/Tutorial-Codebase-Knowledge">AI Codebase Knowledge Builder</a></p>
