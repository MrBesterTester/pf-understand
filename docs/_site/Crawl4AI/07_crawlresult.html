<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>CrawlResult | Two Tutorials for Mojo using Pocket Flow</title> <meta name="generator" content="Jekyll v4.3.4" /> <meta property="og:title" content="CrawlResult" /> <meta name="author" content="Sam Kirk" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Documentation generated using AI to explain codebases" /> <meta property="og:description" content="Documentation generated using AI to explain codebases" /> <link rel="canonical" href="http://localhost:4000/Crawl4AI/07_crawlresult.html" /> <meta property="og:url" content="http://localhost:4000/Crawl4AI/07_crawlresult.html" /> <meta property="og:site_name" content="Two Tutorials for Mojo using Pocket Flow" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="CrawlResult" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Sam Kirk","url":"https://www.columbia.edu/~zh2408/"},"description":"Documentation generated using AI to explain codebases","headline":"CrawlResult","url":"http://localhost:4000/Crawl4AI/07_crawlresult.html"}</script> <!-- End Jekyll SEO tag --> <!-- Add Mermaid support --> <script src="https://cdn.jsdelivr.net/npm/mermaid@11.6.0/dist/mermaid.min.js"></script> <script> document.addEventListener("DOMContentLoaded", function() { mermaid.initialize({ startOnLoad: true, theme: "default" }); // Process code blocks document.querySelectorAll('pre code.language-mermaid').forEach(function(block) { // Create a div with class 'mermaid' var mermaidDiv = document.createElement('div'); mermaidDiv.className = 'mermaid'; mermaidDiv.innerHTML = block.textContent; // Replace the parent pre with the mermaid div block.parentNode.parentNode.replaceChild(mermaidDiv, block.parentNode); console.log("Processed Mermaid block:", mermaidDiv.innerHTML.substring(0, 50) + "..."); }); console.log("Mermaid initialization complete. Version:", mermaid.version()); }); </script> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> Two Tutorials for Mojo using Pocket Flow </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </a> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a></li><li class="nav-list-item active"><button class="nav-list-expander btn-reset" aria-label="toggle items in Crawl4AI category" aria-pressed="true"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/Crawl4AI/" class="nav-list-link">Crawl4AI</a><ul class="nav-list"><li class="nav-list-item "><a href="/Crawl4AI/01_asynccrawlerstrategy.html" class="nav-list-link">AsyncCrawlerStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/01_configuration_system_.html" class="nav-list-link">Chapter 1: Configuration System</a></li><li class="nav-list-item "><a href="/Crawl4AI/02_asyncwebcrawler.html" class="nav-list-link">AsyncWebCrawler</a></li><li class="nav-list-item "><a href="/Crawl4AI/02_asyncwebcrawler_.html" class="nav-list-link">Chapter 2: AsyncWebCrawler</a></li><li class="nav-list-item "><a href="/Crawl4AI/03_content_extraction_pipeline_.html" class="nav-list-link">Chapter 3: Content Extraction Pipeline</a></li><li class="nav-list-item "><a href="/Crawl4AI/03_crawlerrunconfig.html" class="nav-list-link">CrawlerRunConfig</a></li><li class="nav-list-item "><a href="/Crawl4AI/04_url_filtering___scoring_.html" class="nav-list-link">Chapter 4: URL Filtering & Scoring</a></li><li class="nav-list-item "><a href="/Crawl4AI/04_contentscrapingstrategy.html" class="nav-list-link">ContentScrapingStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/05_deep_crawling_system_.html" class="nav-list-link">Chapter 5: Deep Crawling System</a></li><li class="nav-list-item "><a href="/Crawl4AI/05_relevantcontentfilter.html" class="nav-list-link">RelevantContentFilter</a></li><li class="nav-list-item "><a href="/Crawl4AI/06_caching_system_.html" class="nav-list-link">Chapter 6: Caching System</a></li><li class="nav-list-item "><a href="/Crawl4AI/06_extractionstrategy.html" class="nav-list-link">ExtractionStrategy</a></li><li class="nav-list-item active"><a href="/Crawl4AI/07_crawlresult.html" class="nav-list-link active">CrawlResult</a></li><li class="nav-list-item "><a href="/Crawl4AI/07_dispatcher_framework_.html" class="nav-list-link">Chapter 7: Dispatcher Framework</a></li><li class="nav-list-item "><a href="/Crawl4AI/08_deepcrawlstrategy.html" class="nav-list-link">DeepCrawlStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/08_async_logging_infrastructure_.html" class="nav-list-link">Chapter 8: Async Logging Infrastructure</a></li><li class="nav-list-item "><a href="/Crawl4AI/09_cachecontext___cachemode.html" class="nav-list-link">CacheContext & CacheMode</a></li><li class="nav-list-item "><a href="/Crawl4AI/09_api___docker_integration_.html" class="nav-list-link">Chapter 9: API & Docker Integration</a></li><li class="nav-list-item "><a href="/Crawl4AI/10_basedispatcher.html" class="nav-list-link">BaseDispatcher</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Crawl4ai category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/my-crawl4AI/" class="nav-list-link">My Tutorial for Crawl4ai</a><ul class="nav-list"><li class="nav-list-item "><a href="/my-crawl4ai/01_configuration_system_.html" class="nav-list-link">Chapter 1: Configuration System</a></li><li class="nav-list-item "><a href="/my-crawl4ai/02_asyncwebcrawler_.html" class="nav-list-link">Chapter 2: AsyncWebCrawler</a></li><li class="nav-list-item "><a href="/my-crawl4ai/03_content_extraction_pipeline_.html" class="nav-list-link">Chapter 3: Content Extraction Pipeline</a></li><li class="nav-list-item "><a href="/my-crawl4ai/04_url_filtering___scoring_.html" class="nav-list-link">Chapter 4: URL Filtering & Scoring</a></li><li class="nav-list-item "><a href="/my-crawl4ai/05_deep_crawling_system_.html" class="nav-list-link">Chapter 5: Deep Crawling System</a></li><li class="nav-list-item "><a href="/my-crawl4ai/06_caching_system_.html" class="nav-list-link">Chapter 6: Caching System</a></li><li class="nav-list-item "><a href="/my-crawl4ai/07_dispatcher_framework_.html" class="nav-list-link">Chapter 7: Dispatcher Framework</a></li><li class="nav-list-item "><a href="/my-crawl4ai/08_async_logging_infrastructure_.html" class="nav-list-link">Chapter 8: Async Logging Infrastructure</a></li><li class="nav-list-item "><a href="/my-crawl4ai/09_api___docker_integration_.html" class="nav-list-link">Chapter 9: API & Docker Integration</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Modular's Max category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/modular_max/" class="nav-list-link">My Tutorial for Modular's Max</a><ul class="nav-list"><li class="nav-list-item "><a href="/modular_max/01_settings___settings__class__.html" class="nav-list-link">Chapter 1: Settings Class</a></li><li class="nav-list-item "><a href="/modular_max/02_serving_api_layer__fastapi_app___routers__.html" class="nav-list-link">Chapter 2: Serving API Layer</a></li><li class="nav-list-item "><a href="/modular_max/03_llm_pipeline_orchestrator___tokengeneratorpipeline___.html" class="nav-list-link">Chapter 3: LLM Pipeline Orchestrator</a></li><li class="nav-list-item "><a href="/modular_max/04_model_worker_.html" class="nav-list-link">Chapter 4: Model Worker</a></li><li class="nav-list-item "><a href="/modular_max/05_scheduler___tokengenerationscheduler____embeddingsscheduler___.html" class="nav-list-link">Chapter 5: Scheduler</a></li><li class="nav-list-item "><a href="/modular_max/06_kv_cache_management_.html" class="nav-list-link">Chapter 6: KV Cache Management</a></li><li class="nav-list-item "><a href="/modular_max/07_enginequeue_.html" class="nav-list-link">Chapter 7: EngineQueue</a></li><li class="nav-list-item "><a href="/modular_max/08_telemetry_and_metrics___metrics____metricclient___.html" class="nav-list-link">Chapter 8: Telemetry and Metrics</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Mojo v1 category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/mojo-v1/" class="nav-list-link">My Tutorial for Mojo v1</a><ul class="nav-list"><li class="nav-list-item "><a href="/mojo-v1/01_addressspace_.html" class="nav-list-link">Chapter 1: AddressSpace</a></li><li class="nav-list-item "><a href="/mojo-v1/02_unsafepointer_.html" class="nav-list-link">Chapter 2: UnsafePointer</a></li><li class="nav-list-item "><a href="/mojo-v1/03_indexlist_.html" class="nav-list-link">Chapter 3: IndexList</a></li><li class="nav-list-item "><a href="/mojo-v1/04_dimlist_.html" class="nav-list-link">Chapter 4: DimList</a></li><li class="nav-list-item "><a href="/mojo-v1/05_ndbuffer_.html" class="nav-list-link">Chapter 5: NDBuffer</a></li><li class="nav-list-item "><a href="/mojo-v1/06_n_d_to_1d_indexing_logic__strided_memory_access__.html" class="nav-list-link">Chapter 6: N-D to 1D Indexing Logic</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Mojo v2 category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/mojo-v2/" class="nav-list-link">My Tutorial for Mojo v2</a><ul class="nav-list"><li class="nav-list-item "><a href="/mojo-v2/01_unsafepointer__as_used_by_ndbuffer__.html" class="nav-list-link">Chapter 1: UnsafePointer</a></li><li class="nav-list-item "><a href="/mojo-v2/02_dimlist_and_dim_.html" class="nav-list-link">Chapter 2: DimList and Dim</a></li><li class="nav-list-item "><a href="/mojo-v2/03_ndbuffer_.html" class="nav-list-link">Chapter 3: NDBuffer</a></li><li class="nav-list-item "><a href="/mojo-v2/04_strides_and_offset_computation_.html" class="nav-list-link">Chapter 4: Strides and Offset Computation</a></li><li class="nav-list-item "><a href="/mojo-v2/05_simd_data_access_.html" class="nav-list-link">Chapter 5: SIMD Data Access</a></li></ul></li><li class="nav-list-item"><a href="/design.html" class="nav-list-link">System Design</a></li></ul> <div class="nav-category">Crawl4AI</div> <ul class="nav-list"></ul> <div class="nav-category">Modular Max</div> <ul class="nav-list"></ul> <div class="nav-category">Mojo (v1)</div> <ul class="nav-list"></ul> <div class="nav-category">Mojo (v2)</div> <ul class="nav-list"></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Two Tutorials for Mojo using Pocket Flow" aria-label="Search Two Tutorials for Mojo using Pocket Flow" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="https://github.com/MrBesterTester/pf-understand" class="site-button" > View on GitHub </a> </li> </ul> </nav> </div> <div id="main-content-wrap" class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/Crawl4AI/">Crawl4AI</a></li> <li class="breadcrumb-nav-list-item"><span>CrawlResult</span></li> </ol> </nav> <div id="main-content" class="main-content"> <main> <h1 id="chapter-7-understanding-the-results---crawlresult"> <a href="#chapter-7-understanding-the-results---crawlresult" class="anchor-heading" aria-labelledby="chapter-7-understanding-the-results---crawlresult"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Chapter 7: Understanding the Results - CrawlResult </h1> <p>In the previous chapter, <a href="06_extractionstrategy.md">Chapter 6: Getting Specific Data - ExtractionStrategy</a>, we learned how to teach Crawl4AI to act like an analyst, extracting specific, structured data points from a webpage using an <code class="language-plaintext highlighter-rouge">ExtractionStrategy</code>. We’ve seen how Crawl4AI can fetch pages, clean them, filter them, and even extract precise information.</p> <p>But after all that work, where does all the gathered information go? When you ask the <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> to crawl a URL using <code class="language-plaintext highlighter-rouge">arun()</code>, what do you actually get back?</p> <h2 id="what-problem-does-crawlresult-solve"> <a href="#what-problem-does-crawlresult-solve" class="anchor-heading" aria-labelledby="what-problem-does-crawlresult-solve"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> What Problem Does <code class="language-plaintext highlighter-rouge">CrawlResult</code> Solve? </h2> <p>Imagine you sent a research assistant to the library (a website) with a set of instructions: “Find this book (URL), make a clean copy of the relevant chapter (clean HTML/Markdown), list all the cited references (links), take photos of the illustrations (media), find the author and publication date (metadata), and maybe extract specific quotes (structured data).”</p> <p>When the assistant returns, they wouldn’t just hand you a single piece of paper. They’d likely give you a folder containing everything you asked for: the clean copy, the list of references, the photos, the metadata notes, and the extracted quotes, all neatly organized. They might also include a note if they encountered any problems (errors).</p> <p><code class="language-plaintext highlighter-rouge">CrawlResult</code> is exactly this <strong>final report folder</strong> or <strong>delivery package</strong>. It’s a single object that neatly contains <em>all</em> the information Crawl4AI gathered and processed for a specific URL during a crawl operation. Instead of getting lots of separate pieces of data back, you get one convenient container.</p> <h2 id="what-is-crawlresult"> <a href="#what-is-crawlresult" class="anchor-heading" aria-labelledby="what-is-crawlresult"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> What is <code class="language-plaintext highlighter-rouge">CrawlResult</code>? </h2> <p><code class="language-plaintext highlighter-rouge">CrawlResult</code> is a Python object (specifically, a Pydantic model, which is like a super-powered dictionary) that acts as a data container. It holds the results of a single crawl task performed by <code class="language-plaintext highlighter-rouge">AsyncWebCrawler.arun()</code> or one of the results from <code class="language-plaintext highlighter-rouge">arun_many()</code>.</p> <p>Think of it as a toolbox filled with different tools and information related to the crawled page.</p> <p><strong>Key Information Stored in <code class="language-plaintext highlighter-rouge">CrawlResult</code>:</strong></p> <ul> <li><strong><code class="language-plaintext highlighter-rouge">url</code> (string):</strong> The original URL that was requested.</li> <li><strong><code class="language-plaintext highlighter-rouge">success</code> (boolean):</strong> Did the crawl complete without critical errors? <code class="language-plaintext highlighter-rouge">True</code> if successful, <code class="language-plaintext highlighter-rouge">False</code> otherwise. <strong>Always check this first!</strong></li> <li><strong><code class="language-plaintext highlighter-rouge">html</code> (string):</strong> The raw, original HTML source code fetched from the page.</li> <li><strong><code class="language-plaintext highlighter-rouge">cleaned_html</code> (string):</strong> The HTML after initial cleaning by the <a href="04_contentscrapingstrategy.md">ContentScrapingStrategy</a> (e.g., scripts, styles removed).</li> <li><strong><code class="language-plaintext highlighter-rouge">markdown</code> (object):</strong> An object containing different Markdown representations of the content. <ul> <li><code class="language-plaintext highlighter-rouge">markdown.raw_markdown</code>: Basic Markdown generated from <code class="language-plaintext highlighter-rouge">cleaned_html</code>.</li> <li><code class="language-plaintext highlighter-rouge">markdown.fit_markdown</code>: Markdown generated <em>only</em> from content deemed relevant by a <a href="05_relevantcontentfilter.md">RelevantContentFilter</a> (if one was used). Might be empty if no filter was applied.</li> <li><em>(Other fields like <code class="language-plaintext highlighter-rouge">markdown_with_citations</code> might exist)</em></li> </ul> </li> <li><strong><code class="language-plaintext highlighter-rouge">extracted_content</code> (string):</strong> If you used an <a href="06_extractionstrategy.md">ExtractionStrategy</a>, this holds the extracted structured data, usually formatted as a JSON string. <code class="language-plaintext highlighter-rouge">None</code> if no extraction was performed or nothing was found.</li> <li><strong><code class="language-plaintext highlighter-rouge">metadata</code> (dictionary):</strong> Information extracted from the page’s metadata tags, like the page title (<code class="language-plaintext highlighter-rouge">metadata['title']</code>), description, keywords, etc.</li> <li><strong><code class="language-plaintext highlighter-rouge">links</code> (object):</strong> Contains lists of links found on the page. <ul> <li><code class="language-plaintext highlighter-rouge">links.internal</code>: List of links pointing to the same website.</li> <li><code class="language-plaintext highlighter-rouge">links.external</code>: List of links pointing to other websites.</li> </ul> </li> <li><strong><code class="language-plaintext highlighter-rouge">media</code> (object):</strong> Contains lists of media items found. <ul> <li><code class="language-plaintext highlighter-rouge">media.images</code>: List of images (<code class="language-plaintext highlighter-rouge">&lt;img&gt;</code> tags).</li> <li><code class="language-plaintext highlighter-rouge">media.videos</code>: List of videos (<code class="language-plaintext highlighter-rouge">&lt;video&gt;</code> tags).</li> <li><em>(Other media types might be included)</em></li> </ul> </li> <li><strong><code class="language-plaintext highlighter-rouge">screenshot</code> (string):</strong> If you requested a screenshot (<code class="language-plaintext highlighter-rouge">screenshot=True</code> in <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code>), this holds the file path to the saved image. <code class="language-plaintext highlighter-rouge">None</code> otherwise.</li> <li><strong><code class="language-plaintext highlighter-rouge">pdf</code> (bytes):</strong> If you requested a PDF (<code class="language-plaintext highlighter-rouge">pdf=True</code> in <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code>), this holds the PDF data as bytes. <code class="language-plaintext highlighter-rouge">None</code> otherwise. (Note: Previously might have been a path, now often bytes).</li> <li><strong><code class="language-plaintext highlighter-rouge">error_message</code> (string):</strong> If <code class="language-plaintext highlighter-rouge">success</code> is <code class="language-plaintext highlighter-rouge">False</code>, this field usually contains details about what went wrong.</li> <li><strong><code class="language-plaintext highlighter-rouge">status_code</code> (integer):</strong> The HTTP status code received from the server (e.g., 200 for OK, 404 for Not Found).</li> <li><strong><code class="language-plaintext highlighter-rouge">response_headers</code> (dictionary):</strong> The HTTP response headers sent by the server.</li> <li><strong><code class="language-plaintext highlighter-rouge">redirected_url</code> (string):</strong> If the original URL redirected, this shows the final URL the crawler landed on.</li> </ul> <h2 id="accessing-the-crawlresult"> <a href="#accessing-the-crawlresult" class="anchor-heading" aria-labelledby="accessing-the-crawlresult"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Accessing the <code class="language-plaintext highlighter-rouge">CrawlResult</code> </h2> <p>You get a <code class="language-plaintext highlighter-rouge">CrawlResult</code> object back every time you <code class="language-plaintext highlighter-rouge">await</code> a call to <code class="language-plaintext highlighter-rouge">crawler.arun()</code>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chapter7_example_1.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">url</span> <span class="o">=</span> <span class="s">"https://httpbin.org/html"</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Crawling </span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s">..."</span><span class="p">)</span>

        <span class="c1"># The 'arun' method returns a CrawlResult object
</span>        <span class="n">result</span><span class="p">:</span> <span class="n">CrawlResult</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">)</span> <span class="c1"># Type hint optional
</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Crawl finished!"</span><span class="p">)</span>
        <span class="c1"># Now 'result' holds all the information
</span>        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Result object type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div> <p><strong>Explanation:</strong></p> <ol> <li>We call <code class="language-plaintext highlighter-rouge">crawler.arun(url=url)</code>.</li> <li>The <code class="language-plaintext highlighter-rouge">await</code> keyword pauses execution until the crawl is complete.</li> <li>The value returned by <code class="language-plaintext highlighter-rouge">arun</code> is assigned to the <code class="language-plaintext highlighter-rouge">result</code> variable.</li> <li>This <code class="language-plaintext highlighter-rouge">result</code> variable is our <code class="language-plaintext highlighter-rouge">CrawlResult</code> object.</li> </ol> <p>If you use <code class="language-plaintext highlighter-rouge">crawler.arun_many()</code>, it returns a list where each item is a <code class="language-plaintext highlighter-rouge">CrawlResult</code> object for one of the requested URLs (or an async generator if <code class="language-plaintext highlighter-rouge">stream=True</code>).</p> <h2 id="exploring-the-attributes-using-the-toolbox"> <a href="#exploring-the-attributes-using-the-toolbox" class="anchor-heading" aria-labelledby="exploring-the-attributes-using-the-toolbox"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Exploring the Attributes: Using the Toolbox </h2> <p>Once you have the <code class="language-plaintext highlighter-rouge">result</code> object, you can access its attributes using dot notation (e.g., <code class="language-plaintext highlighter-rouge">result.success</code>, <code class="language-plaintext highlighter-rouge">result.markdown</code>).</p> <p><strong>1. Checking for Success (Most Important!)</strong></p> <p>Before you try to use any data, always check if the crawl was successful:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chapter7_example_2.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlResult</span> <span class="c1"># Import CrawlResult for type hint
</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">url</span> <span class="o">=</span> <span class="s">"https://httpbin.org/html"</span> <span class="c1"># A working URL
</span>        <span class="c1"># url = "https://httpbin.org/status/404" # Try this URL to see failure
</span>        <span class="n">result</span><span class="p">:</span> <span class="n">CrawlResult</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">)</span>

        <span class="c1"># --- ALWAYS CHECK 'success' FIRST! ---
</span>        <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">success</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"✅ Successfully crawled: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">url</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="c1"># Now it's safe to access other attributes
</span>            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"   Page Title: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">metadata</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'title'</span><span class="p">,</span> <span class="s">'N/A'</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"❌ Failed to crawl: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">url</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"   Error: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">error_message</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"   Status Code: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">status_code</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div> <p><strong>Explanation:</strong></p> <ul> <li>We use an <code class="language-plaintext highlighter-rouge">if result.success:</code> block.</li> <li>If <code class="language-plaintext highlighter-rouge">True</code>, we proceed to access other data like <code class="language-plaintext highlighter-rouge">result.metadata</code>.</li> <li>If <code class="language-plaintext highlighter-rouge">False</code>, we print the <code class="language-plaintext highlighter-rouge">result.error_message</code> and <code class="language-plaintext highlighter-rouge">result.status_code</code> to understand why it failed.</li> </ul> <p><strong>2. Accessing Content (HTML, Markdown)</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chapter7_example_3.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlResult</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">url</span> <span class="o">=</span> <span class="s">"https://httpbin.org/html"</span>
        <span class="n">result</span><span class="p">:</span> <span class="n">CrawlResult</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">success</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"--- Content ---"</span><span class="p">)</span>
            <span class="c1"># Print the first 150 chars of raw HTML
</span>            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Raw HTML snippet: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">html</span><span class="p">[</span><span class="si">:</span><span class="mi">150</span><span class="p">]</span><span class="si">}</span><span class="s">..."</span><span class="p">)</span>

            <span class="c1"># Access the raw markdown
</span>            <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">markdown</span><span class="p">:</span> <span class="c1"># Check if markdown object exists
</span>                 <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Markdown snippet: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">markdown</span><span class="p">.</span><span class="n">raw_markdown</span><span class="p">[</span><span class="si">:</span><span class="mi">150</span><span class="p">]</span><span class="si">}</span><span class="s">..."</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                 <span class="k">print</span><span class="p">(</span><span class="s">"Markdown not generated."</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Crawl failed: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">error_message</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div> <p><strong>Explanation:</strong></p> <ul> <li>We access <code class="language-plaintext highlighter-rouge">result.html</code> for the original HTML.</li> <li>We access <code class="language-plaintext highlighter-rouge">result.markdown.raw_markdown</code> for the main Markdown content. Note the two dots: <code class="language-plaintext highlighter-rouge">result.markdown</code> gives the <code class="language-plaintext highlighter-rouge">MarkdownGenerationResult</code> object, and <code class="language-plaintext highlighter-rouge">.raw_markdown</code> accesses the specific string within it. We also check <code class="language-plaintext highlighter-rouge">if result.markdown:</code> first, just in case markdown generation failed for some reason.</li> </ul> <p><strong>3. Getting Metadata, Links, and Media</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chapter7_example_4.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlResult</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">url</span> <span class="o">=</span> <span class="s">"https://httpbin.org/links/10/0"</span> <span class="c1"># A page with links
</span>        <span class="n">result</span><span class="p">:</span> <span class="n">CrawlResult</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">success</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"--- Metadata &amp; Links ---"</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Title: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">metadata</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'title'</span><span class="p">,</span> <span class="s">'N/A'</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Found </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="n">internal</span><span class="p">)</span><span class="si">}</span><span class="s"> internal links."</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Found </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="n">external</span><span class="p">)</span><span class="si">}</span><span class="s"> external links."</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="n">internal</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  First internal link text: '</span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="n">internal</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">text</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
            <span class="c1"># Similarly access result.media.images etc.
</span>        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Crawl failed: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">error_message</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div> <p><strong>Explanation:</strong></p> <ul> <li><code class="language-plaintext highlighter-rouge">result.metadata</code> is a dictionary; use <code class="language-plaintext highlighter-rouge">.get()</code> for safe access.</li> <li><code class="language-plaintext highlighter-rouge">result.links</code> and <code class="language-plaintext highlighter-rouge">result.media</code> are objects containing lists (<code class="language-plaintext highlighter-rouge">internal</code>, <code class="language-plaintext highlighter-rouge">external</code>, <code class="language-plaintext highlighter-rouge">images</code>, etc.). We can check their lengths (<code class="language-plaintext highlighter-rouge">len()</code>) and access individual items by index (e.g., <code class="language-plaintext highlighter-rouge">[0]</code>).</li> </ul> <p><strong>4. Checking for Extracted Data, Screenshots, PDFs</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chapter7_example_5.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlResult</span><span class="p">,</span> <span class="n">CrawlerRunConfig</span><span class="p">,</span>
    <span class="n">JsonCssExtractionStrategy</span> <span class="c1"># Example extractor
</span><span class="p">)</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># Define a simple extraction strategy (from Chapter 6)
</span>    <span class="n">schema</span> <span class="o">=</span> <span class="p">{</span><span class="s">"baseSelector"</span><span class="p">:</span> <span class="s">"body"</span><span class="p">,</span> <span class="s">"fields"</span><span class="p">:</span> <span class="p">[{</span><span class="s">"name"</span><span class="p">:</span> <span class="s">"heading"</span><span class="p">,</span> <span class="s">"selector"</span><span class="p">:</span> <span class="s">"h1"</span><span class="p">,</span> <span class="s">"type"</span><span class="p">:</span> <span class="s">"text"</span><span class="p">}]}</span>
    <span class="n">extractor</span> <span class="o">=</span> <span class="n">JsonCssExtractionStrategy</span><span class="p">(</span><span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">)</span>

    <span class="c1"># Configure the run to extract and take a screenshot
</span>    <span class="n">config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span>
        <span class="n">extraction_strategy</span><span class="o">=</span><span class="n">extractor</span><span class="p">,</span>
        <span class="n">screenshot</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>

    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">url</span> <span class="o">=</span> <span class="s">"https://httpbin.org/html"</span>
        <span class="n">result</span><span class="p">:</span> <span class="n">CrawlResult</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">success</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"--- Extracted Data &amp; Media ---"</span><span class="p">)</span>
            <span class="c1"># Check if structured data was extracted
</span>            <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">extracted_content</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="s">"Extracted Data found:"</span><span class="p">)</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">loads</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">extracted_content</span><span class="p">)</span> <span class="c1"># Parse the JSON string
</span>                <span class="k">print</span><span class="p">(</span><span class="n">json</span><span class="p">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="s">"No structured data extracted."</span><span class="p">)</span>

            <span class="c1"># Check if a screenshot was taken
</span>            <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">screenshot</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Screenshot saved to: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">screenshot</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="s">"Screenshot not taken."</span><span class="p">)</span>

            <span class="c1"># Check for PDF (would be bytes if requested and successful)
</span>            <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">pdf</span><span class="p">:</span>
                 <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"PDF data captured (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">pdf</span><span class="p">)</span><span class="si">}</span><span class="s"> bytes)."</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                 <span class="k">print</span><span class="p">(</span><span class="s">"PDF not generated."</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Crawl failed: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">error_message</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div> <p><strong>Explanation:</strong></p> <ul> <li>We check if <code class="language-plaintext highlighter-rouge">result.extracted_content</code> is not <code class="language-plaintext highlighter-rouge">None</code> or empty before trying to parse it as JSON.</li> <li>We check if <code class="language-plaintext highlighter-rouge">result.screenshot</code> is not <code class="language-plaintext highlighter-rouge">None</code> to see if the file path exists.</li> <li>We check if <code class="language-plaintext highlighter-rouge">result.pdf</code> is not <code class="language-plaintext highlighter-rouge">None</code> to see if the PDF data (bytes) was captured.</li> </ul> <h2 id="how-is-crawlresult-created-under-the-hood"> <a href="#how-is-crawlresult-created-under-the-hood" class="anchor-heading" aria-labelledby="how-is-crawlresult-created-under-the-hood"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> How is <code class="language-plaintext highlighter-rouge">CrawlResult</code> Created? (Under the Hood) </h2> <p>You don’t interact with the <code class="language-plaintext highlighter-rouge">CrawlResult</code> constructor directly. The <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> creates it for you at the very end of the <code class="language-plaintext highlighter-rouge">arun</code> process, typically inside its internal <code class="language-plaintext highlighter-rouge">aprocess_html</code> method (or just before returning if fetching from cache).</p> <p>Here’s a simplified sequence:</p> <ol> <li><strong>Fetch:</strong> <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> calls the <a href="01_asynccrawlerstrategy.md">AsyncCrawlerStrategy</a> to get the raw <code class="language-plaintext highlighter-rouge">html</code>, <code class="language-plaintext highlighter-rouge">status_code</code>, <code class="language-plaintext highlighter-rouge">response_headers</code>, etc.</li> <li><strong>Scrape:</strong> It passes the <code class="language-plaintext highlighter-rouge">html</code> to the <a href="04_contentscrapingstrategy.md">ContentScrapingStrategy</a> to get <code class="language-plaintext highlighter-rouge">cleaned_html</code>, <code class="language-plaintext highlighter-rouge">links</code>, <code class="language-plaintext highlighter-rouge">media</code>, <code class="language-plaintext highlighter-rouge">metadata</code>.</li> <li><strong>Markdown:</strong> It generates Markdown using the configured generator, possibly involving a <a href="05_relevantcontentfilter.md">RelevantContentFilter</a>, resulting in a <code class="language-plaintext highlighter-rouge">MarkdownGenerationResult</code> object.</li> <li><strong>Extract (Optional):</strong> If an <a href="06_extractionstrategy.md">ExtractionStrategy</a> is configured, it runs it on the appropriate content (HTML or Markdown) to get <code class="language-plaintext highlighter-rouge">extracted_content</code>.</li> <li><strong>Screenshot/PDF (Optional):</strong> If requested, the fetching strategy captures the <code class="language-plaintext highlighter-rouge">screenshot</code> path or <code class="language-plaintext highlighter-rouge">pdf</code> data.</li> <li><strong>Package:</strong> <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> gathers all these pieces (<code class="language-plaintext highlighter-rouge">url</code>, <code class="language-plaintext highlighter-rouge">html</code>, <code class="language-plaintext highlighter-rouge">cleaned_html</code>, the markdown object, <code class="language-plaintext highlighter-rouge">links</code>, <code class="language-plaintext highlighter-rouge">media</code>, <code class="language-plaintext highlighter-rouge">metadata</code>, <code class="language-plaintext highlighter-rouge">extracted_content</code>, <code class="language-plaintext highlighter-rouge">screenshot</code>, <code class="language-plaintext highlighter-rouge">pdf</code>, <code class="language-plaintext highlighter-rouge">success</code> status, <code class="language-plaintext highlighter-rouge">error_message</code>, etc.).</li> <li><strong>Instantiate:</strong> It creates the <code class="language-plaintext highlighter-rouge">CrawlResult</code> object, passing all the gathered data into its constructor.</li> <li><strong>Return:</strong> It returns this fully populated <code class="language-plaintext highlighter-rouge">CrawlResult</code> object to your code.</li> </ol> <h2 id="code-glimpse-modelspy"> <a href="#code-glimpse-modelspy" class="anchor-heading" aria-labelledby="code-glimpse-modelspy"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Code Glimpse (<code class="language-plaintext highlighter-rouge">models.py</code>) </h2> <p>The <code class="language-plaintext highlighter-rouge">CrawlResult</code> is defined in the <code class="language-plaintext highlighter-rouge">crawl4ai/models.py</code> file. It uses Pydantic, a library that helps define data structures with type hints and validation. Here’s a simplified view:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified from crawl4ai/models.py
</span><span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">HttpUrl</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Any</span>

<span class="c1"># Other related models (simplified)
</span><span class="k">class</span> <span class="nc">MarkdownGenerationResult</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">raw_markdown</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">fit_markdown</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="c1"># ... other markdown fields ...
</span>
<span class="k">class</span> <span class="nc">Links</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">internal</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">external</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">class</span> <span class="nc">Media</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">images</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">videos</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># The main CrawlResult model
</span><span class="k">class</span> <span class="nc">CrawlResult</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">url</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">html</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">success</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">cleaned_html</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">media</span><span class="p">:</span> <span class="n">Media</span> <span class="o">=</span> <span class="n">Media</span><span class="p">()</span> <span class="c1"># Use the Media model
</span>    <span class="n">links</span><span class="p">:</span> <span class="n">Links</span> <span class="o">=</span> <span class="n">Links</span><span class="p">()</span> <span class="c1"># Use the Links model
</span>    <span class="n">screenshot</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">pdf</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bytes</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="c1"># Uses a private attribute and property for markdown for compatibility
</span>    <span class="n">_markdown</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MarkdownGenerationResult</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># Actual storage
</span>    <span class="n">extracted_content</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># JSON string
</span>    <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">error_message</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">status_code</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">response_headers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">redirected_url</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="c1"># ... other fields like session_id, ssl_certificate ...
</span>
    <span class="c1"># Custom property to access markdown data
</span>    <span class="o">@</span><span class="nb">property</span>
    <span class="k">def</span> <span class="nf">markdown</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MarkdownGenerationResult</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_markdown</span>

    <span class="c1"># Configuration for Pydantic
</span>    <span class="k">class</span> <span class="nc">Config</span><span class="p">:</span>
        <span class="n">arbitrary_types_allowed</span> <span class="o">=</span> <span class="bp">True</span>

    <span class="c1"># Custom init and model_dump might exist for backward compatibility handling
</span>    <span class="c1"># ... (omitted for simplicity) ...
</span></code></pre></div></div> <p><strong>Explanation:</strong></p> <ul> <li>It’s defined as a <code class="language-plaintext highlighter-rouge">class CrawlResult(BaseModel):</code>.</li> <li>Each attribute (like <code class="language-plaintext highlighter-rouge">url</code>, <code class="language-plaintext highlighter-rouge">html</code>, <code class="language-plaintext highlighter-rouge">success</code>) is defined with a type hint (like <code class="language-plaintext highlighter-rouge">str</code>, <code class="language-plaintext highlighter-rouge">bool</code>, <code class="language-plaintext highlighter-rouge">Optional[str]</code>). <code class="language-plaintext highlighter-rouge">Optional[str]</code> means the field can be a string or <code class="language-plaintext highlighter-rouge">None</code>.</li> <li>Some attributes are themselves complex objects defined by other Pydantic models (like <code class="language-plaintext highlighter-rouge">media: Media</code>, <code class="language-plaintext highlighter-rouge">links: Links</code>).</li> <li>The <code class="language-plaintext highlighter-rouge">markdown</code> field uses a common pattern (property wrapping a private attribute) to provide the <code class="language-plaintext highlighter-rouge">MarkdownGenerationResult</code> object while maintaining some backward compatibility. You access it simply as <code class="language-plaintext highlighter-rouge">result.markdown</code>.</li> </ul> <h2 id="conclusion"> <a href="#conclusion" class="anchor-heading" aria-labelledby="conclusion"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Conclusion </h2> <p>You’ve now met the <code class="language-plaintext highlighter-rouge">CrawlResult</code> object – the final, comprehensive report delivered by Crawl4AI after processing a URL.</p> <ul> <li>It acts as a <strong>container</strong> holding all gathered information (HTML, Markdown, metadata, links, media, extracted data, errors, etc.).</li> <li>It’s the <strong>return value</strong> of <code class="language-plaintext highlighter-rouge">AsyncWebCrawler.arun()</code> and <code class="language-plaintext highlighter-rouge">arun_many()</code>.</li> <li>The most crucial attribute is <strong><code class="language-plaintext highlighter-rouge">success</code> (boolean)</strong>, which you should always check first.</li> <li>You can easily <strong>access</strong> all the different pieces of information using dot notation (e.g., <code class="language-plaintext highlighter-rouge">result.metadata['title']</code>, <code class="language-plaintext highlighter-rouge">result.markdown.raw_markdown</code>, <code class="language-plaintext highlighter-rouge">result.links.external</code>).</li> </ul> <p>Understanding the <code class="language-plaintext highlighter-rouge">CrawlResult</code> is key to effectively using the information Crawl4AI provides.</p> <p>So far, we’ve focused on crawling single pages or lists of specific URLs. But what if you want to start at one page and automatically discover and crawl linked pages, exploring a website more deeply?</p> <p><strong>Next:</strong> Let’s explore how to perform multi-page crawls with <a href="08_deepcrawlstrategy.md">Chapter 8: Exploring Websites - DeepCrawlStrategy</a>.</p><hr /> <p>Generated by <a href="https://github.com/The-Pocket/Tutorial-Codebase-Knowledge">AI Codebase Knowledge Builder</a></p> </main> <hr> <footer> <p class="text-small text-grey-dk-100 mb-0">Copyright &copy; 2023 Sam Kirk</p> </footer> </div> </div> <div class="search-overlay"></div> </div> <script type="module"> import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.6.0/dist/mermaid.esm.min.mjs'; var config = {} ; mermaid.initialize(config); mermaid.run({ querySelector: '.language-mermaid', }); </script> </body> </html>
