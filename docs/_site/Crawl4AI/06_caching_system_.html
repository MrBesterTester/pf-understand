<h1 id="chapter-6-caching-system">Chapter 6: Caching System</h1>

<p>In <a href="05_deep_crawling_system_.md">Chapter 5: Deep Crawling System</a>, we learned how to explore websites beyond a single page. As you crawl multiple pages, you might notice something: crawling the same page multiple times wastes time and resources. This is where the Caching System comes in!</p>

<h2 id="what-is-the-caching-system">What is the Caching System?</h2>

<p>Imagine you’re doing research for a school project. When you find a useful article online, you might save a copy or print it out so you don’t have to search for it again later. The Caching System in crawl4ai works the same way:</p>

<ul>
  <li>It stores content you’ve already crawled (like HTML, extracted text, images)</li>
  <li>It lets you retrieve this content later without having to download it again</li>
  <li>It saves time, reduces network traffic, and is more polite to the websites you visit</li>
</ul>

<p>Let’s see how this works with a simple example:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlerRunConfig</span>
<span class="kn">from</span> <span class="nn">crawl4ai.cache_context</span> <span class="kn">import</span> <span class="n">CacheMode</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">crawl_with_cache</span><span class="p">():</span>
    <span class="c1"># First run: will download and cache the page
</span>    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">result1</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="s">"https://example.com"</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="n">CrawlerRunConfig</span><span class="p">(</span><span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">ENABLED</span><span class="p">)</span>
        <span class="p">)</span>
        
    <span class="c1"># Second run: will use the cached version (much faster!)
</span>    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">result2</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="s">"https://example.com"</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="n">CrawlerRunConfig</span><span class="p">(</span><span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">ENABLED</span><span class="p">)</span>
        <span class="p">)</span>
</code></pre></div></div>

<p>In this example, the first crawl downloads the page from the internet and saves it to the cache. The second crawl doesn’t need to download the page again - it just retrieves the saved version from the cache!</p>

<h2 id="how-caching-works-core-components">How Caching Works: Core Components</h2>

<p>The Caching System has three main components:</p>

<h3 id="1-cachemode-enum-controlling-caching-behavior">1. CacheMode Enum: Controlling Caching Behavior</h3>

<p>The <code class="language-plaintext highlighter-rouge">CacheMode</code> enum lets you decide how caching should work for each crawl operation:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai.cache_context</span> <span class="kn">import</span> <span class="n">CacheMode</span>

<span class="c1"># Different caching options
</span><span class="n">enabled</span> <span class="o">=</span> <span class="n">CacheMode</span><span class="p">.</span><span class="n">ENABLED</span>      <span class="c1"># Normal caching (read and write)
</span><span class="n">disabled</span> <span class="o">=</span> <span class="n">CacheMode</span><span class="p">.</span><span class="n">DISABLED</span>    <span class="c1"># No caching at all
</span><span class="n">read_only</span> <span class="o">=</span> <span class="n">CacheMode</span><span class="p">.</span><span class="n">READ_ONLY</span>  <span class="c1"># Only read from cache, don't write
</span><span class="n">write_only</span> <span class="o">=</span> <span class="n">CacheMode</span><span class="p">.</span><span class="n">WRITE_ONLY</span> <span class="c1"># Only write to cache, don't read
</span><span class="n">bypass</span> <span class="o">=</span> <span class="n">CacheMode</span><span class="p">.</span><span class="n">BYPASS</span>        <span class="c1"># Skip cache for this operation
</span></code></pre></div></div>

<p>These modes give you precise control over when to use and update the cache.</p>

<h3 id="2-cachecontext-making-caching-decisions">2. CacheContext: Making Caching Decisions</h3>

<p>The <code class="language-plaintext highlighter-rouge">CacheContext</code> class helps decide whether to read from or write to the cache for a specific URL:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai.cache_context</span> <span class="kn">import</span> <span class="n">CacheContext</span>

<span class="c1"># Create a cache context for a URL
</span><span class="n">context</span> <span class="o">=</span> <span class="n">CacheContext</span><span class="p">(</span>
    <span class="n">url</span><span class="o">=</span><span class="s">"https://example.com"</span><span class="p">,</span>
    <span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">ENABLED</span>
<span class="p">)</span>

<span class="c1"># Check if we should read from cache
</span><span class="k">if</span> <span class="n">context</span><span class="p">.</span><span class="n">should_read</span><span class="p">():</span>
    <span class="c1"># Try to get content from cache
</span>    
<span class="c1"># Check if we should write to cache
</span><span class="k">if</span> <span class="n">context</span><span class="p">.</span><span class="n">should_write</span><span class="p">():</span>
    <span class="c1"># Save content to cache
</span></code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">CacheContext</code> considers both the cache mode and the URL type (for example, you can’t cache raw HTML).</p>

<h3 id="3-asyncdatabasemanager-storing-and-retrieving-data">3. AsyncDatabaseManager: Storing and Retrieving Data</h3>

<p>The <code class="language-plaintext highlighter-rouge">AsyncDatabaseManager</code> is the storage engine that actually saves and retrieves your cached content:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai.async_database</span> <span class="kn">import</span> <span class="n">async_db_manager</span>

<span class="c1"># Check if a URL is in the cache
</span><span class="n">cached_result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">async_db_manager</span><span class="p">.</span><span class="n">aget_cached_url</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="k">if</span> <span class="n">cached_result</span><span class="p">:</span>
    <span class="c1"># Use the cached content
</span>    
<span class="c1"># Store a new result in the cache
</span><span class="k">await</span> <span class="n">async_db_manager</span><span class="p">.</span><span class="n">acache_url</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>

<p>You don’t usually need to use this directly - the <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> handles it for you.</p>

<h2 id="using-the-cache-practical-examples">Using the Cache: Practical Examples</h2>

<p>Let’s look at some common use cases for the Caching System:</p>

<h3 id="example-1-basic-caching-default-behavior">Example 1: Basic Caching (Default Behavior)</h3>

<p>By default, crawl4ai has caching enabled:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">basic_crawl</span><span class="p">():</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="c1"># Caching is enabled by default
</span>        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s">"https://example.com"</span><span class="p">)</span>
</code></pre></div></div>

<p>This automatically saves the result and will use the cached version next time.</p>

<h3 id="example-2-refreshing-the-cache-bypassing">Example 2: Refreshing the Cache (Bypassing)</h3>

<p>Sometimes you want fresh content instead of cached content:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlerRunConfig</span>
<span class="kn">from</span> <span class="nn">crawl4ai.cache_context</span> <span class="kn">import</span> <span class="n">CacheMode</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">refresh_content</span><span class="p">():</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="c1"># Skip cache and fetch fresh content
</span>        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="s">"https://example.com"</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="n">CrawlerRunConfig</span><span class="p">(</span><span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">BYPASS</span><span class="p">)</span>
        <span class="p">)</span>
</code></pre></div></div>

<p>This fetches a fresh copy from the website and updates the cache.</p>

<h3 id="example-3-reading-from-cache-only-offline-mode">Example 3: Reading from Cache Only (Offline Mode)</h3>

<p>If you want to work offline or reduce server load:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlerRunConfig</span>
<span class="kn">from</span> <span class="nn">crawl4ai.cache_context</span> <span class="kn">import</span> <span class="n">CacheMode</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">offline_mode</span><span class="p">():</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="c1"># Only use cache, don't fetch from the internet
</span>        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="s">"https://example.com"</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="n">CrawlerRunConfig</span><span class="p">(</span><span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">READ_ONLY</span><span class="p">)</span>
        <span class="p">)</span>
</code></pre></div></div>

<p>This will only return content if it’s already in the cache, and won’t attempt to download it.</p>

<h2 id="how-it-works-under-the-hood">How It Works Under the Hood</h2>

<p>When you crawl a URL with caching enabled, here’s what happens behind the scenes:</p>

<pre><code class="language-mermaid">sequenceDiagram
    participant User as Your Code
    participant WC as WebCrawler
    participant CC as CacheContext
    participant DB as DatabaseManager
    participant Web as Website

    User-&gt;&gt;WC: arun("https://example.com")
    WC-&gt;&gt;CC: should_read()?
    CC-&gt;&gt;WC: Yes
    WC-&gt;&gt;DB: aget_cached_url()
    
    alt URL is in cache
        DB-&gt;&gt;WC: Return cached content
        WC-&gt;&gt;User: Return CrawlResult
    else URL not in cache
        DB-&gt;&gt;WC: Return None
        WC-&gt;&gt;Web: Download page
        Web-&gt;&gt;WC: Return HTML
        WC-&gt;&gt;CC: should_write()?
        CC-&gt;&gt;WC: Yes
        WC-&gt;&gt;DB: acache_url(result)
        WC-&gt;&gt;User: Return CrawlResult
    end
</code></pre>

<ol>
  <li>Your code calls <code class="language-plaintext highlighter-rouge">crawler.arun()</code> with a URL</li>
  <li>The crawler creates a <code class="language-plaintext highlighter-rouge">CacheContext</code> to determine caching behavior</li>
  <li>If reading from cache is allowed, it checks the database for the URL</li>
  <li>If the URL is in the cache, it returns the cached content</li>
  <li>If not, it downloads the page from the website</li>
  <li>If writing to cache is allowed, it saves the result to the database</li>
  <li>Finally, it returns the result to your code</li>
</ol>

<h2 id="implementation-details">Implementation Details</h2>

<p>Let’s look at how this is implemented in the code. Here’s a simplified version of how caching works in the <code class="language-plaintext highlighter-rouge">arun</code> method:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># From the AsyncWebCrawler.arun method
</span><span class="k">async</span> <span class="k">def</span> <span class="nf">arun</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">CrawlerRunConfig</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
    <span class="c1"># Create cache context
</span>    <span class="n">cache_context</span> <span class="o">=</span> <span class="n">CacheContext</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">cache_mode</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
    
    <span class="c1"># Try to get cached result if appropriate
</span>    <span class="k">if</span> <span class="n">cache_context</span><span class="p">.</span><span class="n">should_read</span><span class="p">():</span>
        <span class="n">cached_result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">async_db_manager</span><span class="p">.</span><span class="n">aget_cached_url</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
        
    <span class="k">if</span> <span class="n">cached_result</span><span class="p">:</span>
        <span class="c1"># Use cached content
</span>        <span class="k">return</span> <span class="n">CrawlResultContainer</span><span class="p">(</span><span class="n">cached_result</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Fetch and process new content
</span>        <span class="n">async_response</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="p">.</span><span class="n">crawler_strategy</span><span class="p">.</span><span class="n">crawl</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
        <span class="n">crawl_result</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="p">.</span><span class="n">aprocess_html</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">html</span><span class="o">=</span><span class="n">async_response</span><span class="p">.</span><span class="n">html</span><span class="p">)</span>
        
        <span class="c1"># Update cache if appropriate
</span>        <span class="k">if</span> <span class="n">cache_context</span><span class="p">.</span><span class="n">should_write</span><span class="p">():</span>
            <span class="k">await</span> <span class="n">async_db_manager</span><span class="p">.</span><span class="n">acache_url</span><span class="p">(</span><span class="n">crawl_result</span><span class="p">)</span>
            
        <span class="k">return</span> <span class="n">CrawlResultContainer</span><span class="p">(</span><span class="n">crawl_result</span><span class="p">)</span>
</code></pre></div></div>

<p>This simplified code shows the core caching logic:</p>
<ol>
  <li>Create a <code class="language-plaintext highlighter-rouge">CacheContext</code> with the URL and cache mode</li>
  <li>If we should read from cache, try to get the cached result</li>
  <li>If we have a cached result, return it</li>
  <li>Otherwise, fetch and process the content</li>
  <li>If we should write to cache, save the result</li>
  <li>Return the result</li>
</ol>

<p>The actual database operations happen in the <code class="language-plaintext highlighter-rouge">AsyncDatabaseManager</code> class. Here’s a simplified example of how it saves content to the database:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># From the AsyncDatabaseManager.acache_url method
</span><span class="k">async</span> <span class="k">def</span> <span class="nf">acache_url</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">result</span><span class="p">:</span> <span class="n">CrawlResult</span><span class="p">):</span>
    <span class="c1"># Store content files and get hashes
</span>    <span class="n">content_hashes</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="p">.</span><span class="n">_store_content_files</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    
    <span class="c1"># Store metadata in SQLite database
</span>    <span class="k">await</span> <span class="bp">self</span><span class="p">.</span><span class="n">execute_with_retry</span><span class="p">(</span>
        <span class="s">"INSERT INTO crawled_data VALUES (?, ?, ?, ?)"</span><span class="p">,</span>
        <span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">url</span><span class="p">,</span> <span class="n">content_hashes</span><span class="p">[</span><span class="s">"html"</span><span class="p">],</span> <span class="n">content_hashes</span><span class="p">[</span><span class="s">"markdown"</span><span class="p">])</span>
    <span class="p">)</span>
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">AsyncDatabaseManager</code> does more than just use a database - it also:</p>
<ol>
  <li>Stores large content (HTML, screenshots) as separate files</li>
  <li>Uses hash values to avoid duplicating content</li>
  <li>Manages database connections efficiently</li>
  <li>Handles errors and retries failed operations</li>
</ol>

<h2 id="advanced-usage-optimizing-caching">Advanced Usage: Optimizing Caching</h2>

<p>Here are some tips for getting the most out of the Caching System:</p>

<h3 id="memory-efficient-crawling">Memory-Efficient Crawling</h3>

<p>If you’re crawling many pages but don’t need to update the cache:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlerRunConfig</span>
<span class="kn">from</span> <span class="nn">crawl4ai.cache_context</span> <span class="kn">import</span> <span class="n">CacheMode</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">memory_efficient_crawl</span><span class="p">():</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span>
        <span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">READ_ONLY</span><span class="p">,</span>  <span class="c1"># Don't write to cache
</span>        <span class="n">screenshot</span><span class="o">=</span><span class="bp">False</span>  <span class="c1"># Screenshots use a lot of storage
</span>    <span class="p">)</span>
    
    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s">"https://example.com"</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="refreshing-specific-content-types">Refreshing Specific Content Types</h3>

<p>Sometimes you want to update screenshots but use cached text:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">async</span> <span class="k">def</span> <span class="nf">refresh_screenshots</span><span class="p">():</span>
    <span class="c1"># First check if we have a cached version
</span>    <span class="n">config_check</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span><span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">READ_ONLY</span><span class="p">)</span>
    
    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">cached</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s">"https://example.com"</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_check</span><span class="p">)</span>
        
        <span class="c1"># If we have text but no screenshot, get a fresh version with screenshot
</span>        <span class="k">if</span> <span class="n">cached</span><span class="p">.</span><span class="n">success</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">cached</span><span class="p">.</span><span class="n">screenshot</span><span class="p">:</span>
            <span class="n">config_refresh</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span>
                <span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">ENABLED</span><span class="p">,</span>
                <span class="n">screenshot</span><span class="o">=</span><span class="bp">True</span>
            <span class="p">)</span>
            <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s">"https://example.com"</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config_refresh</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="clearing-the-cache">Clearing the Cache</h3>

<p>If you need to clear the cache:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai.async_database</span> <span class="kn">import</span> <span class="n">async_db_manager</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">clear_cache</span><span class="p">():</span>
    <span class="c1"># Clear all cached data
</span>    <span class="k">await</span> <span class="n">async_db_manager</span><span class="p">.</span><span class="n">aclear_db</span><span class="p">()</span>
    
    <span class="c1"># Or completely rebuild the database
</span>    <span class="k">await</span> <span class="n">async_db_manager</span><span class="p">.</span><span class="n">aflush_db</span><span class="p">()</span>
    <span class="k">await</span> <span class="n">async_db_manager</span><span class="p">.</span><span class="n">ainit_db</span><span class="p">()</span>
</code></pre></div></div>

<p>Be careful with these operations, as they will delete all your cached data!</p>

<h2 id="conclusion">Conclusion</h2>

<p>The Caching System in crawl4ai is like your personal web library - it stores copies of web content you’ve already downloaded, saving time and resources when you need to access the same content again.</p>

<p>In this chapter, we learned:</p>
<ul>
  <li>How the Caching System stores and retrieves web content</li>
  <li>How to control caching behavior with the <code class="language-plaintext highlighter-rouge">CacheMode</code> enum</li>
  <li>How the <code class="language-plaintext highlighter-rouge">CacheContext</code> and <code class="language-plaintext highlighter-rouge">AsyncDatabaseManager</code> work together</li>
  <li>How to use the cache effectively for different scenarios</li>
</ul>

<p>Using the Caching System makes your web crawling more efficient and respectful to the websites you’re crawling. Instead of repeatedly downloading the same content, you can use your local copies, reducing network traffic and making your crawling faster.</p>

<p>In the next chapter, <a href="07_dispatcher_framework_.md">Dispatcher Framework</a>, we’ll learn how to manage multiple crawling tasks efficiently using the dispatcher system.</p>

<hr />

<p>Generated by <a href="https://github.com/The-Pocket/Tutorial-Codebase-Knowledge">AI Codebase Knowledge Builder</a></p>
