<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>CrawlerRunConfig | Two Tutorials for Mojo using Pocket Flow</title> <meta name="generator" content="Jekyll v4.3.4" /> <meta property="og:title" content="CrawlerRunConfig" /> <meta name="author" content="Sam Kirk" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Documentation generated using AI to explain codebases" /> <meta property="og:description" content="Documentation generated using AI to explain codebases" /> <link rel="canonical" href="http://localhost:4000/Crawl4AI/03_crawlerrunconfig.html" /> <meta property="og:url" content="http://localhost:4000/Crawl4AI/03_crawlerrunconfig.html" /> <meta property="og:site_name" content="Two Tutorials for Mojo using Pocket Flow" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="CrawlerRunConfig" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Sam Kirk","url":"https://www.columbia.edu/~zh2408/"},"description":"Documentation generated using AI to explain codebases","headline":"CrawlerRunConfig","url":"http://localhost:4000/Crawl4AI/03_crawlerrunconfig.html"}</script> <!-- End Jekyll SEO tag --> <!-- Add Mermaid support --> <script src="https://cdn.jsdelivr.net/npm/mermaid@11.6.0/dist/mermaid.min.js"></script> <script> document.addEventListener("DOMContentLoaded", function() { mermaid.initialize({ startOnLoad: true, theme: "default" }); // Process code blocks document.querySelectorAll('pre code.language-mermaid').forEach(function(block) { // Create a div with class 'mermaid' var mermaidDiv = document.createElement('div'); mermaidDiv.className = 'mermaid'; mermaidDiv.innerHTML = block.textContent; // Replace the parent pre with the mermaid div block.parentNode.parentNode.replaceChild(mermaidDiv, block.parentNode); console.log("Processed Mermaid block:", mermaidDiv.innerHTML.substring(0, 50) + "..."); }); console.log("Mermaid initialization complete. Version:", mermaid.version()); }); </script> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> Two Tutorials for Mojo using Pocket Flow </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </a> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Crawl4ai category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/my-crawl4AI/" class="nav-list-link">My Tutorial for Crawl4ai</a><ul class="nav-list"><li class="nav-list-item "><a href="/my-crawl4ai/01_configuration_system_.html" class="nav-list-link">Chapter 1: Configuration System</a></li><li class="nav-list-item "><a href="/my-crawl4ai/02_asyncwebcrawler_.html" class="nav-list-link">Chapter 2: AsyncWebCrawler</a></li><li class="nav-list-item "><a href="/my-crawl4ai/03_content_extraction_pipeline_.html" class="nav-list-link">Chapter 3: Content Extraction Pipeline</a></li><li class="nav-list-item "><a href="/my-crawl4ai/04_url_filtering___scoring_.html" class="nav-list-link">Chapter 4: URL Filtering & Scoring</a></li><li class="nav-list-item "><a href="/my-crawl4ai/05_deep_crawling_system_.html" class="nav-list-link">Chapter 5: Deep Crawling System</a></li><li class="nav-list-item "><a href="/my-crawl4ai/06_caching_system_.html" class="nav-list-link">Chapter 6: Caching System</a></li><li class="nav-list-item "><a href="/my-crawl4ai/07_dispatcher_framework_.html" class="nav-list-link">Chapter 7: Dispatcher Framework</a></li><li class="nav-list-item "><a href="/my-crawl4ai/08_async_logging_infrastructure_.html" class="nav-list-link">Chapter 8: Async Logging Infrastructure</a></li><li class="nav-list-item "><a href="/my-crawl4ai/09_api___docker_integration_.html" class="nav-list-link">Chapter 9: API & Docker Integration</a></li></ul></li><li class="nav-list-item"><a href="/design.html" class="nav-list-link">System Design</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Modular's Max category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/modular_max/" class="nav-list-link">My Tutorial for Modular's Max</a><ul class="nav-list"><li class="nav-list-item "><a href="/modular_max/01_settings___settings__class__.html" class="nav-list-link">Chapter 1: Settings Class</a></li><li class="nav-list-item "><a href="/modular_max/02_serving_api_layer__fastapi_app___routers__.html" class="nav-list-link">Chapter 2: Serving API Layer</a></li><li class="nav-list-item "><a href="/modular_max/03_llm_pipeline_orchestrator___tokengeneratorpipeline___.html" class="nav-list-link">Chapter 3: LLM Pipeline Orchestrator</a></li><li class="nav-list-item "><a href="/modular_max/04_model_worker_.html" class="nav-list-link">Chapter 4: Model Worker</a></li><li class="nav-list-item "><a href="/modular_max/05_scheduler___tokengenerationscheduler____embeddingsscheduler___.html" class="nav-list-link">Chapter 5: Scheduler</a></li><li class="nav-list-item "><a href="/modular_max/06_kv_cache_management_.html" class="nav-list-link">Chapter 6: KV Cache Management</a></li><li class="nav-list-item "><a href="/modular_max/07_enginequeue_.html" class="nav-list-link">Chapter 7: EngineQueue</a></li><li class="nav-list-item "><a href="/modular_max/08_telemetry_and_metrics___metrics____metricclient___.html" class="nav-list-link">Chapter 8: Telemetry and Metrics</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Mojo v1 category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/mojo-v1/" class="nav-list-link">My Tutorial for Mojo v1</a><ul class="nav-list"><li class="nav-list-item "><a href="/mojo-v1/01_addressspace_.html" class="nav-list-link">Chapter 1: AddressSpace</a></li><li class="nav-list-item "><a href="/mojo-v1/02_unsafepointer_.html" class="nav-list-link">Chapter 2: UnsafePointer</a></li><li class="nav-list-item "><a href="/mojo-v1/03_indexlist_.html" class="nav-list-link">Chapter 3: IndexList</a></li><li class="nav-list-item "><a href="/mojo-v1/04_dimlist_.html" class="nav-list-link">Chapter 4: DimList</a></li><li class="nav-list-item "><a href="/mojo-v1/05_ndbuffer_.html" class="nav-list-link">Chapter 5: NDBuffer</a></li><li class="nav-list-item "><a href="/mojo-v1/06_n_d_to_1d_indexing_logic__strided_memory_access__.html" class="nav-list-link">Chapter 6: N-D to 1D Indexing Logic</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Mojo v2 category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/mojo-v2/" class="nav-list-link">My Tutorial for Mojo v2</a><ul class="nav-list"><li class="nav-list-item "><a href="/mojo-v2/01_unsafepointer__as_used_by_ndbuffer__.html" class="nav-list-link">Chapter 1: UnsafePointer</a></li><li class="nav-list-item "><a href="/mojo-v2/02_dimlist_and_dim_.html" class="nav-list-link">Chapter 2: DimList and Dim</a></li><li class="nav-list-item "><a href="/mojo-v2/03_ndbuffer_.html" class="nav-list-link">Chapter 3: NDBuffer</a></li><li class="nav-list-item "><a href="/mojo-v2/04_strides_and_offset_computation_.html" class="nav-list-link">Chapter 4: Strides and Offset Computation</a></li><li class="nav-list-item "><a href="/mojo-v2/05_simd_data_access_.html" class="nav-list-link">Chapter 5: SIMD Data Access</a></li></ul></li><li class="nav-list-item active"><button class="nav-list-expander btn-reset" aria-label="toggle items in Crawl4AI category" aria-pressed="true"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/Crawl4AI/" class="nav-list-link">Crawl4AI</a><ul class="nav-list"><li class="nav-list-item "><a href="/Crawl4AI/01_asynccrawlerstrategy.html" class="nav-list-link">AsyncCrawlerStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/01_configuration_system_.html" class="nav-list-link">Chapter 1: Configuration System</a></li><li class="nav-list-item "><a href="/Crawl4AI/02_asyncwebcrawler.html" class="nav-list-link">AsyncWebCrawler</a></li><li class="nav-list-item "><a href="/Crawl4AI/02_asyncwebcrawler_.html" class="nav-list-link">Chapter 2: AsyncWebCrawler</a></li><li class="nav-list-item "><a href="/Crawl4AI/03_content_extraction_pipeline_.html" class="nav-list-link">Chapter 3: Content Extraction Pipeline</a></li><li class="nav-list-item active"><a href="/Crawl4AI/03_crawlerrunconfig.html" class="nav-list-link active">CrawlerRunConfig</a></li><li class="nav-list-item "><a href="/Crawl4AI/04_contentscrapingstrategy.html" class="nav-list-link">ContentScrapingStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/04_url_filtering___scoring_.html" class="nav-list-link">Chapter 4: URL Filtering & Scoring</a></li><li class="nav-list-item "><a href="/Crawl4AI/05_deep_crawling_system_.html" class="nav-list-link">Chapter 5: Deep Crawling System</a></li><li class="nav-list-item "><a href="/Crawl4AI/05_relevantcontentfilter.html" class="nav-list-link">RelevantContentFilter</a></li><li class="nav-list-item "><a href="/Crawl4AI/06_caching_system_.html" class="nav-list-link">Chapter 6: Caching System</a></li><li class="nav-list-item "><a href="/Crawl4AI/06_extractionstrategy.html" class="nav-list-link">ExtractionStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/07_crawlresult.html" class="nav-list-link">CrawlResult</a></li><li class="nav-list-item "><a href="/Crawl4AI/07_dispatcher_framework_.html" class="nav-list-link">Chapter 7: Dispatcher Framework</a></li><li class="nav-list-item "><a href="/Crawl4AI/08_deepcrawlstrategy.html" class="nav-list-link">DeepCrawlStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/08_async_logging_infrastructure_.html" class="nav-list-link">Chapter 8: Async Logging Infrastructure</a></li><li class="nav-list-item "><a href="/Crawl4AI/09_api___docker_integration_.html" class="nav-list-link">Chapter 9: API & Docker Integration</a></li><li class="nav-list-item "><a href="/Crawl4AI/09_cachecontext___cachemode.html" class="nav-list-link">CacheContext & CacheMode</a></li><li class="nav-list-item "><a href="/Crawl4AI/10_basedispatcher.html" class="nav-list-link">BaseDispatcher</a></li></ul></li></ul> <div class="nav-category">Crawl4AI</div> <ul class="nav-list"></ul> <div class="nav-category">Modular Max</div> <ul class="nav-list"></ul> <div class="nav-category">Mojo (v1)</div> <ul class="nav-list"></ul> <div class="nav-category">Mojo (v2)</div> <ul class="nav-list"></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Two Tutorials for Mojo using Pocket Flow" aria-label="Search Two Tutorials for Mojo using Pocket Flow" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="https://github.com/MrBesterTester/pf-understand" class="site-button" > View on GitHub </a> </li> </ul> </nav> </div> <div id="main-content-wrap" class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/Crawl4AI/">Crawl4AI</a></li> <li class="breadcrumb-nav-list-item"><span>CrawlerRunConfig</span></li> </ol> </nav> <div id="main-content" class="main-content"> <main> <h1 id="chapter-3-giving-instructions---crawlerrunconfig"> <a href="#chapter-3-giving-instructions---crawlerrunconfig" class="anchor-heading" aria-labelledby="chapter-3-giving-instructions---crawlerrunconfig"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Chapter 3: Giving Instructions - CrawlerRunConfig </h1> <p>In <a href="02_asyncwebcrawler.md">Chapter 2: Meet the General Manager - AsyncWebCrawler</a>, we met the <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code>, the central coordinator for our web crawling tasks. We saw how to tell it <em>what</em> URL to crawl using the <code class="language-plaintext highlighter-rouge">arun</code> method.</p> <p>But what if we want to tell the crawler <em>how</em> to crawl that URL? Maybe we want it to take a picture (screenshot) of the page? Or perhaps we only care about a specific section of the page? Or maybe we want to ignore the cache and get the very latest version?</p> <p>Passing all these different instructions individually every time we call <code class="language-plaintext highlighter-rouge">arun</code> could get complicated and messy.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Imagine doing this every time - it gets long!
# result = await crawler.arun(
#     url="https://example.com",
#     take_screenshot=True,
#     ignore_cache=True,
#     only_look_at_this_part="#main-content",
#     wait_for_this_element="#data-table",
#     # ... maybe many more settings ...
# )
</span></code></pre></div></div> <p>That’s where <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> comes in!</p> <h2 id="what-problem-does-crawlerrunconfig-solve"> <a href="#what-problem-does-crawlerrunconfig-solve" class="anchor-heading" aria-labelledby="what-problem-does-crawlerrunconfig-solve"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> What Problem Does <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> Solve? </h2> <p>Think of <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> as the <strong>Instruction Manual</strong> for a <em>specific</em> crawl job. Instead of giving the <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> manager lots of separate instructions each time, you bundle them all neatly into a single <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> object.</p> <p>This object tells the <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> exactly <em>how</em> to handle a particular URL or set of URLs for that specific run. It makes your code cleaner and easier to manage.</p> <h2 id="what-is-crawlerrunconfig"> <a href="#what-is-crawlerrunconfig" class="anchor-heading" aria-labelledby="what-is-crawlerrunconfig"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> What is <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code>? </h2> <p><code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> is a configuration class that holds all the settings for a single crawl operation initiated by <code class="language-plaintext highlighter-rouge">AsyncWebCrawler.arun()</code> or <code class="language-plaintext highlighter-rouge">arun_many()</code>.</p> <p>It allows you to customize various aspects of the crawl, such as:</p> <ul> <li><strong>Taking Screenshots:</strong> Should the crawler capture an image of the page? (<code class="language-plaintext highlighter-rouge">screenshot</code>)</li> <li><strong>Waiting:</strong> How long should the crawler wait for the page or specific elements to load? (<code class="language-plaintext highlighter-rouge">page_timeout</code>, <code class="language-plaintext highlighter-rouge">wait_for</code>)</li> <li><strong>Focusing Content:</strong> Should the crawler only process a specific part of the page? (<code class="language-plaintext highlighter-rouge">css_selector</code>)</li> <li><strong>Extracting Data:</strong> Should the crawler use a specific method to pull out structured data? (<a href="06_extractionstrategy.md">ExtractionStrategy</a>)</li> <li><strong>Caching:</strong> How should the crawler interact with previously saved results? (<a href="09_cachecontext___cachemode.md">CacheMode</a>)</li> <li><strong>And much more!</strong> (like handling JavaScript, filtering links, etc.)</li> </ul> <h2 id="using-crawlerrunconfig"> <a href="#using-crawlerrunconfig" class="anchor-heading" aria-labelledby="using-crawlerrunconfig"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Using <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> </h2> <p>Let’s see how to use it. Remember our basic crawl from Chapter 2?</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chapter3_example_1.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">url_to_crawl</span> <span class="o">=</span> <span class="s">"https://httpbin.org/html"</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Crawling </span><span class="si">{</span><span class="n">url_to_crawl</span><span class="si">}</span><span class="s"> with default settings..."</span><span class="p">)</span>

        <span class="c1"># This uses the default behavior (no specific config)
</span>        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url_to_crawl</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">success</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"Success! Got the content."</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Screenshot taken? </span><span class="si">{</span><span class="s">'Yes'</span> <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">screenshot</span> <span class="k">else</span> <span class="s">'No'</span><span class="si">}</span><span class="s">"</span><span class="p">)</span> <span class="c1"># Likely No
</span>            <span class="c1"># We'll learn about CacheMode later, but it defaults to using the cache
</span>        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Failed: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">error_message</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div> <p>Now, let’s say for this <em>specific</em> crawl, we want to bypass the cache (fetch fresh) and also take a screenshot.</p> <p>We create a <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> instance and pass it to <code class="language-plaintext highlighter-rouge">arun</code>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chapter3_example_2.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">CrawlerRunConfig</span> <span class="c1"># 1. Import the config class
</span><span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">CacheMode</span>        <span class="c1"># Import cache options
</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">url_to_crawl</span> <span class="o">=</span> <span class="s">"https://httpbin.org/html"</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Crawling </span><span class="si">{</span><span class="n">url_to_crawl</span><span class="si">}</span><span class="s"> with custom settings..."</span><span class="p">)</span>

        <span class="c1"># 2. Create an instance of CrawlerRunConfig with our desired settings
</span>        <span class="n">my_instructions</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span>
            <span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">BYPASS</span><span class="p">,</span> <span class="c1"># Don't use the cache, fetch fresh
</span>            <span class="n">screenshot</span><span class="o">=</span><span class="bp">True</span>              <span class="c1"># Take a screenshot
</span>        <span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Instructions: Bypass cache, take screenshot."</span><span class="p">)</span>

        <span class="c1"># 3. Pass the config object to arun()
</span>        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="n">url_to_crawl</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="n">my_instructions</span> <span class="c1"># Pass our instruction manual
</span>        <span class="p">)</span>

        <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">success</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Success! Got the content with custom config."</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Screenshot taken? </span><span class="si">{</span><span class="s">'Yes'</span> <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">screenshot</span> <span class="k">else</span> <span class="s">'No'</span><span class="si">}</span><span class="s">"</span><span class="p">)</span> <span class="c1"># Should be Yes
</span>            <span class="c1"># Check if the screenshot file path exists in result.screenshot
</span>            <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">screenshot</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Screenshot saved to: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">screenshot</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Failed: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">error_message</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div> <p><strong>Explanation:</strong></p> <ol> <li><strong>Import:</strong> We import <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> and <code class="language-plaintext highlighter-rouge">CacheMode</code>.</li> <li><strong>Create Config:</strong> We create an instance: <code class="language-plaintext highlighter-rouge">my_instructions = CrawlerRunConfig(...)</code>. We set <code class="language-plaintext highlighter-rouge">cache_mode</code> to <code class="language-plaintext highlighter-rouge">CacheMode.BYPASS</code> and <code class="language-plaintext highlighter-rouge">screenshot</code> to <code class="language-plaintext highlighter-rouge">True</code>. All other settings remain at their defaults.</li> <li><strong>Pass Config:</strong> We pass this <code class="language-plaintext highlighter-rouge">my_instructions</code> object to <code class="language-plaintext highlighter-rouge">crawler.arun</code> using the <code class="language-plaintext highlighter-rouge">config=</code> parameter.</li> </ol> <p>Now, when <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> runs this job, it will look inside <code class="language-plaintext highlighter-rouge">my_instructions</code> and follow those specific settings for <em>this run only</em>.</p> <h2 id="some-common-crawlerrunconfig-parameters"> <a href="#some-common-crawlerrunconfig-parameters" class="anchor-heading" aria-labelledby="some-common-crawlerrunconfig-parameters"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Some Common <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> Parameters </h2> <p><code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> has many options, but here are a few common ones you might use:</p> <ul> <li><strong><code class="language-plaintext highlighter-rouge">cache_mode</code></strong>: Controls caching behavior. <ul> <li><code class="language-plaintext highlighter-rouge">CacheMode.ENABLED</code> (Default): Use the cache if available, otherwise fetch and save.</li> <li><code class="language-plaintext highlighter-rouge">CacheMode.BYPASS</code>: Always fetch fresh, ignoring any cached version (but still save the new result).</li> <li><code class="language-plaintext highlighter-rouge">CacheMode.DISABLED</code>: Never read from or write to the cache.</li> <li><em>(More details in <a href="09_cachecontext___cachemode.md">Chapter 9: Smart Fetching with Caching - CacheContext / CacheMode</a>)</em></li> </ul> </li> <li><strong><code class="language-plaintext highlighter-rouge">screenshot</code> (bool)</strong>: If <code class="language-plaintext highlighter-rouge">True</code>, takes a screenshot of the fully rendered page. The path to the screenshot file will be in <code class="language-plaintext highlighter-rouge">CrawlResult.screenshot</code>. Default: <code class="language-plaintext highlighter-rouge">False</code>.</li> <li><strong><code class="language-plaintext highlighter-rouge">pdf</code> (bool)</strong>: If <code class="language-plaintext highlighter-rouge">True</code>, generates a PDF of the page. The path to the PDF file will be in <code class="language-plaintext highlighter-rouge">CrawlResult.pdf</code>. Default: <code class="language-plaintext highlighter-rouge">False</code>.</li> <li><strong><code class="language-plaintext highlighter-rouge">css_selector</code> (str)</strong>: If provided (e.g., <code class="language-plaintext highlighter-rouge">"#main-content"</code> or <code class="language-plaintext highlighter-rouge">.article-body</code>), the crawler will try to extract <em>only</em> the HTML content within the element(s) matching this CSS selector. This is great for focusing on the important part of a page. Default: <code class="language-plaintext highlighter-rouge">None</code> (process the whole page).</li> <li><strong><code class="language-plaintext highlighter-rouge">wait_for</code> (str)</strong>: A CSS selector (e.g., <code class="language-plaintext highlighter-rouge">"#data-loaded-indicator"</code>). The crawler will wait until an element matching this selector appears on the page before proceeding. Useful for pages that load content dynamically with JavaScript. Default: <code class="language-plaintext highlighter-rouge">None</code>.</li> <li><strong><code class="language-plaintext highlighter-rouge">page_timeout</code> (int)</strong>: Maximum time in milliseconds to wait for page navigation or certain operations. Default: <code class="language-plaintext highlighter-rouge">60000</code> (60 seconds).</li> <li><strong><code class="language-plaintext highlighter-rouge">extraction_strategy</code></strong>: An object that defines how to extract specific, structured data (like product names and prices) from the page. Default: <code class="language-plaintext highlighter-rouge">None</code>. <em>(See <a href="06_extractionstrategy.md">Chapter 6: Getting Specific Data - ExtractionStrategy</a>)</em></li> <li><strong><code class="language-plaintext highlighter-rouge">scraping_strategy</code></strong>: An object defining how the raw HTML is cleaned and basic content (like text and links) is extracted. Default: <code class="language-plaintext highlighter-rouge">WebScrapingStrategy()</code>. <em>(See <a href="04_contentscrapingstrategy.md">Chapter 4: Cleaning Up the Mess - ContentScrapingStrategy</a>)</em></li> </ul> <p>Let’s try combining a few: focus on a specific part of the page and wait for something to appear.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chapter3_example_3.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlerRunConfig</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># This example site has a heading 'H1' inside a 'body' tag.
</span>    <span class="n">url_to_crawl</span> <span class="o">=</span> <span class="s">"https://httpbin.org/html"</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Crawling </span><span class="si">{</span><span class="n">url_to_crawl</span><span class="si">}</span><span class="s">, focusing on the H1 tag..."</span><span class="p">)</span>

        <span class="c1"># Instructions: Only get the H1 tag, wait max 10s for it
</span>        <span class="n">specific_config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span>
            <span class="n">css_selector</span><span class="o">=</span><span class="s">"h1"</span><span class="p">,</span> <span class="c1"># Only grab content inside &lt;h1&gt; tags
</span>            <span class="n">page_timeout</span><span class="o">=</span><span class="mi">10000</span> <span class="c1"># Set page timeout to 10 seconds
</span>            <span class="c1"># We could also add wait_for="h1" if needed for dynamic loading
</span>        <span class="p">)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url_to_crawl</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">specific_config</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">success</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Success! Focused crawl completed."</span><span class="p">)</span>
            <span class="c1"># The markdown should now ONLY contain the H1 content
</span>            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Markdown content:</span><span class="se">\n</span><span class="s">---</span><span class="se">\n</span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">markdown</span><span class="p">.</span><span class="n">raw_markdown</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s">---"</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Failed: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">error_message</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div> <p>This time, the <code class="language-plaintext highlighter-rouge">result.markdown</code> should only contain the text from the <code class="language-plaintext highlighter-rouge">&lt;h1&gt;</code> tag on that page, because we used <code class="language-plaintext highlighter-rouge">css_selector="h1"</code> in our <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code>.</p> <h2 id="how-asyncwebcrawler-uses-the-config-under-the-hood"> <a href="#how-asyncwebcrawler-uses-the-config-under-the-hood" class="anchor-heading" aria-labelledby="how-asyncwebcrawler-uses-the-config-under-the-hood"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> How <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> Uses the Config (Under the Hood) </h2> <p>You don’t need to know the exact internal code, but it helps to understand the flow. When you call <code class="language-plaintext highlighter-rouge">crawler.arun(url, config=my_config)</code>, the <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> essentially does this:</p> <ol> <li>Receives the <code class="language-plaintext highlighter-rouge">url</code> and the <code class="language-plaintext highlighter-rouge">my_config</code> object.</li> <li>Before fetching, it checks <code class="language-plaintext highlighter-rouge">my_config.cache_mode</code> to see if it should look in the cache first.</li> <li>If fetching is needed, it passes <code class="language-plaintext highlighter-rouge">my_config</code> to the underlying <a href="01_asynccrawlerstrategy.md">AsyncCrawlerStrategy</a>.</li> <li>The strategy uses settings from <code class="language-plaintext highlighter-rouge">my_config</code> like <code class="language-plaintext highlighter-rouge">page_timeout</code>, <code class="language-plaintext highlighter-rouge">wait_for</code>, and whether to take a <code class="language-plaintext highlighter-rouge">screenshot</code>.</li> <li>After getting the raw HTML, <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> uses the <code class="language-plaintext highlighter-rouge">my_config.scraping_strategy</code> and <code class="language-plaintext highlighter-rouge">my_config.css_selector</code> to process the content.</li> <li>If <code class="language-plaintext highlighter-rouge">my_config.extraction_strategy</code> is set, it uses that to extract structured data.</li> <li>Finally, it bundles everything into a <code class="language-plaintext highlighter-rouge">CrawlResult</code> and returns it.</li> </ol> <p>Here’s a simplified view:</p><pre><code class="language-mermaid">sequenceDiagram
    participant User
    participant AWC as AsyncWebCrawler
    participant Config as CrawlerRunConfig
    participant Fetcher as AsyncCrawlerStrategy
    participant Processor as Scraping/Extraction

    User-&gt;&gt;AWC: arun(url, config=my_config)
    AWC-&gt;&gt;Config: Check my_config.cache_mode
    alt Need to Fetch
        AWC-&gt;&gt;Fetcher: crawl(url, config=my_config)
        Note over Fetcher: Uses my_config settings (timeout, wait_for, screenshot...)
        Fetcher--&gt;&gt;AWC: Raw Response (HTML, screenshot?)
        AWC-&gt;&gt;Processor: Process HTML (using my_config.css_selector, my_config.extraction_strategy...)
        Processor--&gt;&gt;AWC: Processed Data
    else Use Cache
        AWC-&gt;&gt;AWC: Retrieve from Cache
    end
    AWC--&gt;&gt;User: Return CrawlResult
</code></pre><p>The <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> acts as a messenger carrying your specific instructions throughout the crawling process.</p> <p>Inside the <code class="language-plaintext highlighter-rouge">crawl4ai</code> library, in the file <code class="language-plaintext highlighter-rouge">async_configs.py</code>, you’ll find the definition of the <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> class. It looks something like this (simplified):</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified from crawl4ai/async_configs.py
</span>
<span class="kn">from</span> <span class="nn">.cache_context</span> <span class="kn">import</span> <span class="n">CacheMode</span>
<span class="kn">from</span> <span class="nn">.extraction_strategy</span> <span class="kn">import</span> <span class="n">ExtractionStrategy</span>
<span class="kn">from</span> <span class="nn">.content_scraping_strategy</span> <span class="kn">import</span> <span class="n">ContentScrapingStrategy</span><span class="p">,</span> <span class="n">WebScrapingStrategy</span>
<span class="c1"># ... other imports ...
</span>
<span class="k">class</span> <span class="nc">CrawlerRunConfig</span><span class="p">():</span>
    <span class="s">"""
    Configuration class for controlling how the crawler runs each crawl operation.
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="c1"># Caching
</span>        <span class="n">cache_mode</span><span class="p">:</span> <span class="n">CacheMode</span> <span class="o">=</span> <span class="n">CacheMode</span><span class="p">.</span><span class="n">BYPASS</span><span class="p">,</span> <span class="c1"># Default behavior if not specified
</span>
        <span class="c1"># Content Selection / Waiting
</span>        <span class="n">css_selector</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
        <span class="n">wait_for</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
        <span class="n">page_timeout</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">60000</span><span class="p">,</span> <span class="c1"># 60 seconds
</span>
        <span class="c1"># Media
</span>        <span class="n">screenshot</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
        <span class="n">pdf</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>

        <span class="c1"># Processing Strategies
</span>        <span class="n">scraping_strategy</span><span class="p">:</span> <span class="n">ContentScrapingStrategy</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="c1"># Defaults internally if None
</span>        <span class="n">extraction_strategy</span><span class="p">:</span> <span class="n">ExtractionStrategy</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>

        <span class="c1"># ... many other parameters omitted for clarity ...
</span>        <span class="o">**</span><span class="n">kwargs</span> <span class="c1"># Allows for flexibility
</span>    <span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">cache_mode</span> <span class="o">=</span> <span class="n">cache_mode</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">css_selector</span> <span class="o">=</span> <span class="n">css_selector</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">wait_for</span> <span class="o">=</span> <span class="n">wait_for</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">page_timeout</span> <span class="o">=</span> <span class="n">page_timeout</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">screenshot</span> <span class="o">=</span> <span class="n">screenshot</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">pdf</span> <span class="o">=</span> <span class="n">pdf</span>
        <span class="c1"># Assign scraping strategy, ensuring a default if None is provided
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">scraping_strategy</span> <span class="o">=</span> <span class="n">scraping_strategy</span> <span class="ow">or</span> <span class="n">WebScrapingStrategy</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">extraction_strategy</span> <span class="o">=</span> <span class="n">extraction_strategy</span>
        <span class="c1"># ... initialize other attributes ...
</span>
    <span class="c1"># Helper methods like 'clone', 'to_dict', 'from_kwargs' might exist too
</span>    <span class="c1"># ...
</span></code></pre></div></div> <p>The key idea is that it’s a class designed to hold various settings together. When you create an instance <code class="language-plaintext highlighter-rouge">CrawlerRunConfig(...)</code>, you’re essentially creating an object that stores your choices for these parameters.</p> <h2 id="conclusion"> <a href="#conclusion" class="anchor-heading" aria-labelledby="conclusion"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Conclusion </h2> <p>You’ve learned about <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code>, the “Instruction Manual” for individual crawl jobs in Crawl4AI!</p> <ul> <li>It solves the problem of passing many settings individually to <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code>.</li> <li>You create an instance of <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> and set the parameters you want to customize (like <code class="language-plaintext highlighter-rouge">cache_mode</code>, <code class="language-plaintext highlighter-rouge">screenshot</code>, <code class="language-plaintext highlighter-rouge">css_selector</code>, <code class="language-plaintext highlighter-rouge">wait_for</code>).</li> <li>You pass this config object to <code class="language-plaintext highlighter-rouge">crawler.arun(url, config=your_config)</code>.</li> <li>This makes your code cleaner and gives you fine-grained control over <em>how</em> each crawl is performed.</li> </ul> <p>Now that we know how to fetch content (<a href="01_asynccrawlerstrategy.md">AsyncCrawlerStrategy</a>), manage the overall process (<a href="02_asyncwebcrawler.md">AsyncWebCrawler</a>), and give specific instructions (<a href="03_crawlerrunconfig.md">CrawlerRunConfig</a>), let’s look at how the raw, messy HTML fetched from the web is initially cleaned up and processed.</p> <p><strong>Next:</strong> Let’s explore <a href="04_contentscrapingstrategy.md">Chapter 4: Cleaning Up the Mess - ContentScrapingStrategy</a>.</p><hr /> <p>Generated by <a href="https://github.com/The-Pocket/Tutorial-Codebase-Knowledge">AI Codebase Knowledge Builder</a></p> </main> <hr> <footer> <p class="text-small text-grey-dk-100 mb-0">Copyright &copy; 2023 Sam Kirk</p> </footer> </div> </div> <div class="search-overlay"></div> </div> <script type="module"> import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.6.0/dist/mermaid.esm.min.mjs'; var config = {} ; mermaid.initialize(config); mermaid.run({ querySelector: '.language-mermaid', }); </script> </body> </html>
