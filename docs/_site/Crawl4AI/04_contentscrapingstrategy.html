<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>ContentScrapingStrategy | Two Tutorials for Mojo using Pocket Flow</title> <meta name="generator" content="Jekyll v4.3.4" /> <meta property="og:title" content="ContentScrapingStrategy" /> <meta name="author" content="Sam Kirk" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Documentation generated using AI to explain codebases" /> <meta property="og:description" content="Documentation generated using AI to explain codebases" /> <link rel="canonical" href="http://localhost:4000/Crawl4AI/04_contentscrapingstrategy.html" /> <meta property="og:url" content="http://localhost:4000/Crawl4AI/04_contentscrapingstrategy.html" /> <meta property="og:site_name" content="Two Tutorials for Mojo using Pocket Flow" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="ContentScrapingStrategy" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Sam Kirk","url":"https://www.columbia.edu/~zh2408/"},"description":"Documentation generated using AI to explain codebases","headline":"ContentScrapingStrategy","url":"http://localhost:4000/Crawl4AI/04_contentscrapingstrategy.html"}</script> <!-- End Jekyll SEO tag --> <!-- Add Mermaid support --> <script src="https://cdn.jsdelivr.net/npm/mermaid@11.6.0/dist/mermaid.min.js"></script> <script> document.addEventListener("DOMContentLoaded", function() { mermaid.initialize({ startOnLoad: true, theme: "default" }); // Process code blocks document.querySelectorAll('pre code.language-mermaid').forEach(function(block) { // Create a div with class 'mermaid' var mermaidDiv = document.createElement('div'); mermaidDiv.className = 'mermaid'; mermaidDiv.innerHTML = block.textContent; // Replace the parent pre with the mermaid div block.parentNode.parentNode.replaceChild(mermaidDiv, block.parentNode); console.log("Processed Mermaid block:", mermaidDiv.innerHTML.substring(0, 50) + "..."); }); console.log("Mermaid initialization complete. Version:", mermaid.version()); }); </script> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> Two Tutorials for Mojo using Pocket Flow </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </a> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Modular's Max category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/modular_max/" class="nav-list-link">My Tutorial for Modular's Max</a><ul class="nav-list"></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Crawl4ai category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/my-crawl4AI/" class="nav-list-link">My Tutorial for Crawl4ai</a><ul class="nav-list"></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Mojo v2 category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/mojo-v2/" class="nav-list-link">My Tutorial for Mojo v2</a><ul class="nav-list"></ul></li><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Mojo v1 category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/mojo-v1/" class="nav-list-link">My Tutorial for Mojo v1</a><ul class="nav-list"></ul></li><li class="nav-list-item"><a href="/design.html" class="nav-list-link">System Design</a></li><li class="nav-list-item active"><button class="nav-list-expander btn-reset" aria-label="toggle items in Crawl4AI category" aria-pressed="true"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/Crawl4AI/" class="nav-list-link">Crawl4AI</a><ul class="nav-list"><li class="nav-list-item "><a href="/Crawl4AI/01_asynccrawlerstrategy.html" class="nav-list-link">AsyncCrawlerStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/02_asyncwebcrawler.html" class="nav-list-link">AsyncWebCrawler</a></li><li class="nav-list-item "><a href="/Crawl4AI/03_crawlerrunconfig.html" class="nav-list-link">CrawlerRunConfig</a></li><li class="nav-list-item active"><a href="/Crawl4AI/04_contentscrapingstrategy.html" class="nav-list-link active">ContentScrapingStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/05_relevantcontentfilter.html" class="nav-list-link">RelevantContentFilter</a></li><li class="nav-list-item "><a href="/Crawl4AI/06_extractionstrategy.html" class="nav-list-link">ExtractionStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/07_crawlresult.html" class="nav-list-link">CrawlResult</a></li><li class="nav-list-item "><a href="/Crawl4AI/08_deepcrawlstrategy.html" class="nav-list-link">DeepCrawlStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/09_cachecontext___cachemode.html" class="nav-list-link">CacheContext & CacheMode</a></li><li class="nav-list-item "><a href="/Crawl4AI/10_basedispatcher.html" class="nav-list-link">BaseDispatcher</a></li></ul></li></ul> <div class="nav-category">Crawl4AI</div> <ul class="nav-list"></ul> <div class="nav-category">Modular Max</div> <ul class="nav-list"></ul> <div class="nav-category">Mojo (v1)</div> <ul class="nav-list"></ul> <div class="nav-category">Mojo (v2)</div> <ul class="nav-list"></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Two Tutorials for Mojo using Pocket Flow" aria-label="Search Two Tutorials for Mojo using Pocket Flow" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="https://github.com/MrBesterTester/pf-understand" class="site-button" > View on GitHub </a> </li> </ul> </nav> </div> <div id="main-content-wrap" class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/Crawl4AI/">Crawl4AI</a></li> <li class="breadcrumb-nav-list-item"><span>ContentScrapingStrategy</span></li> </ol> </nav> <div id="main-content" class="main-content"> <main> <h1 id="chapter-4-cleaning-up-the-mess---contentscrapingstrategy"> <a href="#chapter-4-cleaning-up-the-mess---contentscrapingstrategy" class="anchor-heading" aria-labelledby="chapter-4-cleaning-up-the-mess---contentscrapingstrategy"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Chapter 4: Cleaning Up the Mess - ContentScrapingStrategy </h1> <p>In <a href="03_crawlerrunconfig.md">Chapter 3: Giving Instructions - CrawlerRunConfig</a>, we learned how to give specific instructions to our <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> using <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code>. This included telling it <em>how</em> to fetch the page and potentially take screenshots or PDFs.</p> <p>Now, imagine the crawler has successfully fetched the raw HTML content of a webpage. What’s next? Raw HTML is often messy! It contains not just the main article or product description you might care about, but also:</p> <ul> <li>Navigation menus</li> <li>Advertisements</li> <li>Headers and footers</li> <li>Hidden code like JavaScript (<code class="language-plaintext highlighter-rouge">&lt;script&gt;</code>) and styling information (<code class="language-plaintext highlighter-rouge">&lt;style&gt;</code>)</li> <li>Comments left by developers</li> </ul> <p>Before we can really understand the <em>meaning</em> of the page or extract specific important information, we need to clean up this mess and get a basic understanding of its structure.</p> <h2 id="what-problem-does-contentscrapingstrategy-solve"> <a href="#what-problem-does-contentscrapingstrategy-solve" class="anchor-heading" aria-labelledby="what-problem-does-contentscrapingstrategy-solve"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> What Problem Does <code class="language-plaintext highlighter-rouge">ContentScrapingStrategy</code> Solve? </h2> <p>Think of the raw HTML fetched by the crawler as a very rough first draft of a book manuscript. It has the core story, but it’s full of editor’s notes, coffee stains, layout instructions for the printer, and maybe even doodles in the margins.</p> <p>Before the <em>main</em> editor (who focuses on plot and character) can work on it, someone needs to do an initial cleanup. This “First Pass Editor” would:</p> <ol> <li>Remove the coffee stains and doodles (irrelevant stuff like ads, scripts, styles).</li> <li>Identify the basic structure: chapter headings (like the page title), paragraph text, image captions (image alt text), and maybe a list of illustrations (links).</li> <li>Produce a tidier version of the manuscript, ready for more detailed analysis.</li> </ol> <p>In Crawl4AI, the <code class="language-plaintext highlighter-rouge">ContentScrapingStrategy</code> acts as this <strong>First Pass Editor</strong>. It takes the raw HTML and performs an initial cleanup and structure extraction. Its job is to transform the messy HTML into a more manageable format, identifying key elements like text content, links, images, and basic page metadata (like the title).</p> <h2 id="what-is-contentscrapingstrategy"> <a href="#what-is-contentscrapingstrategy" class="anchor-heading" aria-labelledby="what-is-contentscrapingstrategy"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> What is <code class="language-plaintext highlighter-rouge">ContentScrapingStrategy</code>? </h2> <p><code class="language-plaintext highlighter-rouge">ContentScrapingStrategy</code> is an abstract concept (like a job description) in Crawl4AI that defines <em>how</em> the initial processing of raw HTML should happen. It specifies <em>that</em> we need a method to clean HTML and extract basic structure, but the specific tools and techniques used can vary.</p> <p>This allows Crawl4AI to be flexible. Different strategies might use different underlying libraries or have different performance characteristics.</p> <h2 id="the-implementations-meet-the-editors"> <a href="#the-implementations-meet-the-editors" class="anchor-heading" aria-labelledby="the-implementations-meet-the-editors"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Implementations: Meet the Editors </h2> <p>Crawl4AI provides concrete implementations (the actual editors doing the work) of this strategy:</p> <ol> <li><strong><code class="language-plaintext highlighter-rouge">WebScrapingStrategy</code> (The Default Editor):</strong> <ul> <li>This is the strategy used by default if you don’t specify otherwise.</li> <li>It uses a popular Python library called <code class="language-plaintext highlighter-rouge">BeautifulSoup</code> behind the scenes to parse and manipulate the HTML.</li> <li>It’s generally robust and good at handling imperfect HTML.</li> <li>Think of it as a reliable, experienced editor who does a thorough job.</li> </ul> </li> <li><strong><code class="language-plaintext highlighter-rouge">LXMLWebScrapingStrategy</code> (The Speedy Editor):</strong> <ul> <li>This strategy uses another powerful library called <code class="language-plaintext highlighter-rouge">lxml</code>.</li> <li><code class="language-plaintext highlighter-rouge">lxml</code> is often faster than <code class="language-plaintext highlighter-rouge">BeautifulSoup</code>, especially on large or complex pages.</li> <li>Think of it as a very fast editor who might be slightly stricter about the manuscript’s format but gets the job done quickly.</li> </ul> </li> </ol> <p>For most beginners, the default <code class="language-plaintext highlighter-rouge">WebScrapingStrategy</code> works perfectly fine! You usually don’t need to worry about switching unless you encounter performance issues on very large-scale crawls (which is a more advanced topic).</p> <h2 id="how-it-works-conceptually"> <a href="#how-it-works-conceptually" class="anchor-heading" aria-labelledby="how-it-works-conceptually"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> How It Works Conceptually </h2> <p>Here’s the flow:</p> <ol> <li>The <a href="02_asyncwebcrawler.md">AsyncWebCrawler</a> receives the raw HTML from the <a href="01_asynccrawlerstrategy.md">AsyncCrawlerStrategy</a> (the fetcher).</li> <li>It looks at the <a href="03_crawlerrunconfig.md">CrawlerRunConfig</a> to see which <code class="language-plaintext highlighter-rouge">ContentScrapingStrategy</code> to use (defaulting to <code class="language-plaintext highlighter-rouge">WebScrapingStrategy</code> if none is specified).</li> <li>It hands the raw HTML over to the chosen strategy’s <code class="language-plaintext highlighter-rouge">scrap</code> method.</li> <li>The strategy parses the HTML, removes unwanted tags (like <code class="language-plaintext highlighter-rouge">&lt;script&gt;</code>, <code class="language-plaintext highlighter-rouge">&lt;style&gt;</code>, <code class="language-plaintext highlighter-rouge">&lt;nav&gt;</code>, <code class="language-plaintext highlighter-rouge">&lt;aside&gt;</code>, etc., based on its internal rules), extracts all links (<code class="language-plaintext highlighter-rouge">&lt;a&gt;</code> tags), images (<code class="language-plaintext highlighter-rouge">&lt;img&gt;</code> tags with their <code class="language-plaintext highlighter-rouge">alt</code> text), and metadata (like the <code class="language-plaintext highlighter-rouge">&lt;title&gt;</code> tag).</li> <li>It returns the results packaged in a <code class="language-plaintext highlighter-rouge">ScrapingResult</code> object, containing the cleaned HTML, lists of links and media items, and extracted metadata.</li> <li>The <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> then takes this <code class="language-plaintext highlighter-rouge">ScrapingResult</code> and uses its contents (along with other info) to build the final <a href="07_crawlresult.md">CrawlResult</a>.</li> </ol><pre><code class="language-mermaid">sequenceDiagram
    participant AWC as AsyncWebCrawler (Manager)
    participant Fetcher as AsyncCrawlerStrategy
    participant HTML as Raw HTML
    participant CSS as ContentScrapingStrategy (Editor)
    participant SR as ScrapingResult (Cleaned Draft)
    participant CR as CrawlResult (Final Report)

    AWC-&gt;&gt;Fetcher: Fetch("https://example.com")
    Fetcher--&gt;&gt;AWC: Here's the Raw HTML
    AWC-&gt;&gt;CSS: Please scrap this Raw HTML (using config)
    Note over CSS: Parsing HTML... Removing scripts, styles, ads... Extracting links, images, title...
    CSS--&gt;&gt;AWC: Here's the ScrapingResult (Cleaned HTML, Links, Media, Metadata)
    AWC-&gt;&gt;CR: Combine ScrapingResult with other info
    AWC--&gt;&gt;User: Return final CrawlResult
</code></pre><h2 id="using-the-default-strategy-webscrapingstrategy"> <a href="#using-the-default-strategy-webscrapingstrategy" class="anchor-heading" aria-labelledby="using-the-default-strategy-webscrapingstrategy"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Using the Default Strategy (<code class="language-plaintext highlighter-rouge">WebScrapingStrategy</code>) </h2> <p>You’re likely already using it without realizing it! When you run a basic crawl, <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> automatically employs <code class="language-plaintext highlighter-rouge">WebScrapingStrategy</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chapter4_example_1.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlerRunConfig</span><span class="p">,</span> <span class="n">CacheMode</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># Uses the default AsyncPlaywrightCrawlerStrategy (fetching)
</span>    <span class="c1"># AND the default WebScrapingStrategy (scraping/cleaning)
</span>    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">url_to_crawl</span> <span class="o">=</span> <span class="s">"https://httpbin.org/html"</span> <span class="c1"># A very simple HTML page
</span>
        <span class="c1"># We don't specify a scraping_strategy in the config, so it uses the default
</span>        <span class="n">config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span><span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">BYPASS</span><span class="p">)</span> <span class="c1"># Fetch fresh
</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Crawling </span><span class="si">{</span><span class="n">url_to_crawl</span><span class="si">}</span><span class="s"> using default scraping strategy..."</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url_to_crawl</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">success</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Success! Content fetched and scraped."</span><span class="p">)</span>
            <span class="c1"># The 'result' object now contains info processed by WebScrapingStrategy
</span>
            <span class="c1"># 1. Metadata extracted (e.g., page title)
</span>            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Page Title: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">metadata</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'title'</span><span class="p">,</span> <span class="s">'N/A'</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

            <span class="c1"># 2. Links extracted
</span>            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Found </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="n">internal</span><span class="p">)</span><span class="si">}</span><span class="s"> internal links and </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="n">external</span><span class="p">)</span><span class="si">}</span><span class="s"> external links."</span><span class="p">)</span>
            <span class="c1"># Example: print first external link if exists
</span>            <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="n">external</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Example external link: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="n">external</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">href</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

            <span class="c1"># 3. Media extracted (images, videos, etc.)
</span>            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Found </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">media</span><span class="p">.</span><span class="n">images</span><span class="p">)</span><span class="si">}</span><span class="s"> images."</span><span class="p">)</span>
             <span class="c1"># Example: print first image alt text if exists
</span>            <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">media</span><span class="p">.</span><span class="n">images</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Example image alt text: '</span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">media</span><span class="p">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">alt</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>

            <span class="c1"># 4. Cleaned HTML (scripts, styles etc. removed) - might still be complex
</span>            <span class="c1"># print(f"\nCleaned HTML snippet:\n---\n{result.cleaned_html[:200]}...\n---")
</span>
            <span class="c1"># 5. Markdown representation (generated AFTER scraping)
</span>            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Markdown snippet:</span><span class="se">\n</span><span class="s">---</span><span class="se">\n</span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">markdown</span><span class="p">.</span><span class="n">raw_markdown</span><span class="p">[</span><span class="si">:</span><span class="mi">200</span><span class="p">]</span><span class="si">}</span><span class="s">...</span><span class="se">\n</span><span class="s">---"</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Failed: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">error_message</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div> <p><strong>Explanation:</strong></p> <ol> <li>We create <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> and <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> as usual.</li> <li>We <strong>don’t</strong> set the <code class="language-plaintext highlighter-rouge">scraping_strategy</code> parameter in <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code>. Crawl4AI automatically picks <code class="language-plaintext highlighter-rouge">WebScrapingStrategy</code>.</li> <li>When <code class="language-plaintext highlighter-rouge">crawler.arun</code> executes, after fetching the HTML, it internally calls <code class="language-plaintext highlighter-rouge">WebScrapingStrategy.scrap()</code>.</li> <li>The <code class="language-plaintext highlighter-rouge">result</code> (a <a href="07_crawlresult.md">CrawlResult</a> object) contains fields populated by the scraping strategy: <ul> <li><code class="language-plaintext highlighter-rouge">result.metadata</code>: Contains things like the page title found in <code class="language-plaintext highlighter-rouge">&lt;title&gt;</code> tags.</li> <li><code class="language-plaintext highlighter-rouge">result.links</code>: Contains lists of internal and external links found (<code class="language-plaintext highlighter-rouge">&lt;a&gt;</code> tags).</li> <li><code class="language-plaintext highlighter-rouge">result.media</code>: Contains lists of images (<code class="language-plaintext highlighter-rouge">&lt;img&gt;</code>), videos (<code class="language-plaintext highlighter-rouge">&lt;video&gt;</code>), etc.</li> <li><code class="language-plaintext highlighter-rouge">result.cleaned_html</code>: The HTML after the strategy removed unwanted tags and attributes (this is then used to generate the Markdown).</li> <li><code class="language-plaintext highlighter-rouge">result.markdown</code>: While not <em>directly</em> created by the scraping strategy, the cleaned HTML it produces is the input for generating the Markdown representation.</li> </ul> </li> </ol> <h2 id="explicitly-choosing-a-strategy-eg-lxmlwebscrapingstrategy"> <a href="#explicitly-choosing-a-strategy-eg-lxmlwebscrapingstrategy" class="anchor-heading" aria-labelledby="explicitly-choosing-a-strategy-eg-lxmlwebscrapingstrategy"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Explicitly Choosing a Strategy (e.g., <code class="language-plaintext highlighter-rouge">LXMLWebScrapingStrategy</code>) </h2> <p>What if you want to try the potentially faster <code class="language-plaintext highlighter-rouge">LXMLWebScrapingStrategy</code>? You can specify it in the <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chapter4_example_2.py
</span><span class="kn">import</span> <span class="nn">asyncio</span>
<span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlerRunConfig</span><span class="p">,</span> <span class="n">CacheMode</span>
<span class="c1"># 1. Import the specific strategy you want to use
</span><span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">LXMLWebScrapingStrategy</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># 2. Create an instance of the desired scraping strategy
</span>    <span class="n">lxml_editor</span> <span class="o">=</span> <span class="n">LXMLWebScrapingStrategy</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Using scraper: </span><span class="si">{</span><span class="n">lxml_editor</span><span class="p">.</span><span class="n">__class__</span><span class="p">.</span><span class="n">__name__</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">url_to_crawl</span> <span class="o">=</span> <span class="s">"https://httpbin.org/html"</span>

        <span class="c1"># 3. Create a CrawlerRunConfig and pass the strategy instance
</span>        <span class="n">config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span>
            <span class="n">cache_mode</span><span class="o">=</span><span class="n">CacheMode</span><span class="p">.</span><span class="n">BYPASS</span><span class="p">,</span>
            <span class="n">scraping_strategy</span><span class="o">=</span><span class="n">lxml_editor</span> <span class="c1"># Tell the config which strategy to use
</span>        <span class="p">)</span>

        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Crawling </span><span class="si">{</span><span class="n">url_to_crawl</span><span class="si">}</span><span class="s"> with explicit LXML scraping strategy..."</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url_to_crawl</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">success</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Success! Content fetched and scraped using LXML."</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Page Title: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">metadata</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'title'</span><span class="p">,</span> <span class="s">'N/A'</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Found </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">links</span><span class="p">.</span><span class="n">external</span><span class="p">)</span><span class="si">}</span><span class="s"> external links."</span><span class="p">)</span>
            <span class="c1"># Output should be largely the same as the default strategy for simple pages
</span>        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Failed: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">error_message</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">())</span>
</code></pre></div></div> <p><strong>Explanation:</strong></p> <ol> <li><strong>Import:</strong> We import <code class="language-plaintext highlighter-rouge">LXMLWebScrapingStrategy</code> alongside the other classes.</li> <li><strong>Instantiate:</strong> We create an instance: <code class="language-plaintext highlighter-rouge">lxml_editor = LXMLWebScrapingStrategy()</code>.</li> <li><strong>Configure:</strong> We create <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code> and pass our instance to the <code class="language-plaintext highlighter-rouge">scraping_strategy</code> parameter: <code class="language-plaintext highlighter-rouge">CrawlerRunConfig(..., scraping_strategy=lxml_editor)</code>.</li> <li><strong>Run:</strong> Now, when <code class="language-plaintext highlighter-rouge">crawler.arun</code> is called with this config, it will use <code class="language-plaintext highlighter-rouge">LXMLWebScrapingStrategy</code> instead of the default <code class="language-plaintext highlighter-rouge">WebScrapingStrategy</code> for the initial HTML processing step.</li> </ol> <p>For simple pages, the results from both strategies will often be very similar. The choice typically comes down to performance considerations in more advanced scenarios.</p> <h2 id="a-glimpse-under-the-hood"> <a href="#a-glimpse-under-the-hood" class="anchor-heading" aria-labelledby="a-glimpse-under-the-hood"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> A Glimpse Under the Hood </h2> <p>Inside the <code class="language-plaintext highlighter-rouge">crawl4ai</code> library, the file <code class="language-plaintext highlighter-rouge">content_scraping_strategy.py</code> defines the blueprint and the implementations.</p> <p><strong>The Blueprint (Abstract Base Class):</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified from crawl4ai/content_scraping_strategy.py
</span><span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">.models</span> <span class="kn">import</span> <span class="n">ScrapingResult</span> <span class="c1"># Defines the structure of the result
</span>
<span class="k">class</span> <span class="nc">ContentScrapingStrategy</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="s">"""Abstract base class for content scraping strategies."""</span>

    <span class="o">@</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">scrap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">html</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScrapingResult</span><span class="p">:</span>
        <span class="s">"""
        Synchronous method to scrape content.
        Takes raw HTML, returns structured ScrapingResult.
        """</span>
        <span class="k">pass</span>

    <span class="o">@</span><span class="n">abstractmethod</span>
    <span class="k">async</span> <span class="k">def</span> <span class="nf">ascrap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">html</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScrapingResult</span><span class="p">:</span>
        <span class="s">"""
        Asynchronous method to scrape content.
        Takes raw HTML, returns structured ScrapingResult.
        """</span>
        <span class="k">pass</span>
</code></pre></div></div> <p><strong>The Implementations:</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified from crawl4ai/content_scraping_strategy.py
</span><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span> <span class="c1"># Library used by WebScrapingStrategy
# ... other imports like models ...
</span>
<span class="k">class</span> <span class="nc">WebScrapingStrategy</span><span class="p">(</span><span class="n">ContentScrapingStrategy</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logger</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">logger</span>
        <span class="c1"># ... potentially other setup ...
</span>
    <span class="k">def</span> <span class="nf">scrap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">html</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScrapingResult</span><span class="p">:</span>
        <span class="c1"># 1. Parse HTML using BeautifulSoup
</span>        <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s">'lxml'</span><span class="p">)</span> <span class="c1"># Or another parser
</span>
        <span class="c1"># 2. Find the main content area (maybe using kwargs['css_selector'])
</span>        <span class="c1"># 3. Remove unwanted tags (scripts, styles, nav, footer, ads...)
</span>        <span class="c1"># 4. Extract metadata (title, description...)
</span>        <span class="c1"># 5. Extract all links (&lt;a&gt; tags)
</span>        <span class="c1"># 6. Extract all images (&lt;img&gt; tags) and other media
</span>        <span class="c1"># 7. Get the remaining cleaned HTML text content
</span>
        <span class="c1"># ... complex cleaning and extraction logic using BeautifulSoup methods ...
</span>
        <span class="c1"># 8. Package results into a ScrapingResult object
</span>        <span class="n">cleaned_html_content</span> <span class="o">=</span> <span class="s">"&lt;html&gt;&lt;body&gt;Cleaned content...&lt;/body&gt;&lt;/html&gt;"</span> <span class="c1"># Placeholder
</span>        <span class="n">links_data</span> <span class="o">=</span> <span class="n">Links</span><span class="p">(...)</span>
        <span class="n">media_data</span> <span class="o">=</span> <span class="n">Media</span><span class="p">(...)</span>
        <span class="n">metadata_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s">"title"</span><span class="p">:</span> <span class="s">"Page Title"</span><span class="p">}</span>

        <span class="k">return</span> <span class="n">ScrapingResult</span><span class="p">(</span>
            <span class="n">cleaned_html</span><span class="o">=</span><span class="n">cleaned_html_content</span><span class="p">,</span>
            <span class="n">links</span><span class="o">=</span><span class="n">links_data</span><span class="p">,</span>
            <span class="n">media</span><span class="o">=</span><span class="n">media_data</span><span class="p">,</span>
            <span class="n">metadata</span><span class="o">=</span><span class="n">metadata_dict</span><span class="p">,</span>
            <span class="n">success</span><span class="o">=</span><span class="bp">True</span>
        <span class="p">)</span>

    <span class="k">async</span> <span class="k">def</span> <span class="nf">ascrap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">html</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScrapingResult</span><span class="p">:</span>
        <span class="c1"># Often delegates to the synchronous version for CPU-bound tasks
</span>        <span class="k">return</span> <span class="k">await</span> <span class="n">asyncio</span><span class="p">.</span><span class="n">to_thread</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">scrap</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">html</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified from crawl4ai/content_scraping_strategy.py
</span><span class="kn">from</span> <span class="nn">lxml</span> <span class="kn">import</span> <span class="n">html</span> <span class="k">as</span> <span class="n">lhtml</span> <span class="c1"># Library used by LXMLWebScrapingStrategy
# ... other imports like models ...
</span>
<span class="k">class</span> <span class="nc">LXMLWebScrapingStrategy</span><span class="p">(</span><span class="n">WebScrapingStrategy</span><span class="p">):</span> <span class="c1"># Often inherits for shared logic
</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logger</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">logger</span><span class="p">)</span>
        <span class="c1"># ... potentially LXML specific setup ...
</span>
    <span class="k">def</span> <span class="nf">scrap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">html</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScrapingResult</span><span class="p">:</span>
        <span class="c1"># 1. Parse HTML using lxml
</span>        <span class="n">doc</span> <span class="o">=</span> <span class="n">lhtml</span><span class="p">.</span><span class="n">document_fromstring</span><span class="p">(</span><span class="n">html</span><span class="p">)</span>

        <span class="c1"># 2. Find main content, remove unwanted tags, extract info
</span>        <span class="c1"># ... complex cleaning and extraction logic using lxml's XPath or CSS selectors ...
</span>
        <span class="c1"># 3. Package results into a ScrapingResult object
</span>        <span class="n">cleaned_html_content</span> <span class="o">=</span> <span class="s">"&lt;html&gt;&lt;body&gt;Cleaned LXML content...&lt;/body&gt;&lt;/html&gt;"</span> <span class="c1"># Placeholder
</span>        <span class="n">links_data</span> <span class="o">=</span> <span class="n">Links</span><span class="p">(...)</span>
        <span class="n">media_data</span> <span class="o">=</span> <span class="n">Media</span><span class="p">(...)</span>
        <span class="n">metadata_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s">"title"</span><span class="p">:</span> <span class="s">"Page Title LXML"</span><span class="p">}</span>

        <span class="k">return</span> <span class="n">ScrapingResult</span><span class="p">(</span>
            <span class="n">cleaned_html</span><span class="o">=</span><span class="n">cleaned_html_content</span><span class="p">,</span>
            <span class="n">links</span><span class="o">=</span><span class="n">links_data</span><span class="p">,</span>
            <span class="n">media</span><span class="o">=</span><span class="n">media_data</span><span class="p">,</span>
            <span class="n">metadata</span><span class="o">=</span><span class="n">metadata_dict</span><span class="p">,</span>
            <span class="n">success</span><span class="o">=</span><span class="bp">True</span>
        <span class="p">)</span>

    <span class="c1"># ascrap might also delegate or have specific async optimizations
</span></code></pre></div></div> <p>The key takeaway is that both strategies implement the <code class="language-plaintext highlighter-rouge">scrap</code> (and <code class="language-plaintext highlighter-rouge">ascrap</code>) method, taking raw HTML and returning a structured <code class="language-plaintext highlighter-rouge">ScrapingResult</code>. The <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> can use either one thanks to this common interface.</p> <h2 id="conclusion"> <a href="#conclusion" class="anchor-heading" aria-labelledby="conclusion"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Conclusion </h2> <p>You’ve learned about <code class="language-plaintext highlighter-rouge">ContentScrapingStrategy</code>, Crawl4AI’s “First Pass Editor” for raw HTML.</p> <ul> <li>It tackles the problem of messy HTML by cleaning it and extracting basic structure.</li> <li>It acts as a blueprint, with <code class="language-plaintext highlighter-rouge">WebScrapingStrategy</code> (default, using BeautifulSoup) and <code class="language-plaintext highlighter-rouge">LXMLWebScrapingStrategy</code> (using lxml) as concrete implementations.</li> <li>It’s used automatically by <code class="language-plaintext highlighter-rouge">AsyncWebCrawler</code> after fetching content.</li> <li>You can specify which strategy to use via <code class="language-plaintext highlighter-rouge">CrawlerRunConfig</code>.</li> <li>Its output (cleaned HTML, links, media, metadata) is packaged into a <code class="language-plaintext highlighter-rouge">ScrapingResult</code> and contributes significantly to the final <code class="language-plaintext highlighter-rouge">CrawlResult</code>.</li> </ul> <p>Now that we have this initially cleaned and structured content, we might want to further filter it. What if we only care about the parts of the page that are <em>relevant</em> to a specific topic?</p> <p><strong>Next:</strong> Let’s explore how to filter content for relevance with <a href="05_relevantcontentfilter.md">Chapter 5: Focusing on What Matters - RelevantContentFilter</a>.</p><hr /> <p>Generated by <a href="https://github.com/The-Pocket/Tutorial-Codebase-Knowledge">AI Codebase Knowledge Builder</a></p> </main> <hr> <footer> <p class="text-small text-grey-dk-100 mb-0">Copyright &copy; 2023 Sam Kirk</p> </footer> </div> </div> <div class="search-overlay"></div> </div> <script type="module"> import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.6.0/dist/mermaid.esm.min.mjs'; var config = {} ; mermaid.initialize(config); mermaid.run({ querySelector: '.language-mermaid', }); </script> </body> </html>
