<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Chapter 7: Dispatcher Framework | Two Tutorials for Mojo using Pocket Flow</title> <meta name="generator" content="Jekyll v4.3.4" /> <meta property="og:title" content="Chapter 7: Dispatcher Framework" /> <meta name="author" content="Sam Kirk" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Documentation generated using AI to explain codebases" /> <meta property="og:description" content="Documentation generated using AI to explain codebases" /> <link rel="canonical" href="http://localhost:4000/my-crawl4ai/07_dispatcher_framework_.html" /> <meta property="og:url" content="http://localhost:4000/my-crawl4ai/07_dispatcher_framework_.html" /> <meta property="og:site_name" content="Two Tutorials for Mojo using Pocket Flow" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="Chapter 7: Dispatcher Framework" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Sam Kirk","url":"https://www.linkedin.com/in/samuelkirk"},"description":"Documentation generated using AI to explain codebases","headline":"Chapter 7: Dispatcher Framework","url":"http://localhost:4000/my-crawl4ai/07_dispatcher_framework_.html"}</script> <!-- End Jekyll SEO tag --> <!-- Add Mermaid support --> <script src="https://cdn.jsdelivr.net/npm/mermaid@11.6.0/dist/mermaid.min.js"></script> <script> document.addEventListener("DOMContentLoaded", function() { mermaid.initialize({ startOnLoad: true, theme: "default" }); // Process code blocks document.querySelectorAll('pre code.language-mermaid').forEach(function(block) { // Create a div with class 'mermaid' var mermaidDiv = document.createElement('div'); mermaidDiv.className = 'mermaid'; mermaidDiv.innerHTML = block.textContent; // Replace the parent pre with the mermaid div block.parentNode.parentNode.replaceChild(mermaidDiv, block.parentNode); console.log("Processed Mermaid block:", mermaidDiv.innerHTML.substring(0, 50) + "..."); }); console.log("Mermaid initialization complete. Version:", mermaid.version()); }); </script> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> Two Tutorials for Mojo using Pocket Flow </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </a> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-list-link">README</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Crawl4AI category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/Crawl4AI/" class="nav-list-link">Crawl4AI</a><ul class="nav-list"><li class="nav-list-item "><a href="/Crawl4AI/01_asynccrawlerstrategy.html" class="nav-list-link">AsyncCrawlerStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/01_configuration_system_.html" class="nav-list-link">Chapter 1: Configuration System</a></li><li class="nav-list-item "><a href="/Crawl4AI/02_asyncwebcrawler.html" class="nav-list-link">AsyncWebCrawler</a></li><li class="nav-list-item "><a href="/Crawl4AI/02_asyncwebcrawler_.html" class="nav-list-link">Chapter 2: AsyncWebCrawler</a></li><li class="nav-list-item "><a href="/Crawl4AI/03_content_extraction_pipeline_.html" class="nav-list-link">Chapter 3: Content Extraction Pipeline</a></li><li class="nav-list-item "><a href="/Crawl4AI/03_crawlerrunconfig.html" class="nav-list-link">CrawlerRunConfig</a></li><li class="nav-list-item "><a href="/Crawl4AI/04_contentscrapingstrategy.html" class="nav-list-link">ContentScrapingStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/04_url_filtering___scoring_.html" class="nav-list-link">Chapter 4: URL Filtering & Scoring</a></li><li class="nav-list-item "><a href="/Crawl4AI/05_deep_crawling_system_.html" class="nav-list-link">Chapter 5: Deep Crawling System</a></li><li class="nav-list-item "><a href="/Crawl4AI/05_relevantcontentfilter.html" class="nav-list-link">RelevantContentFilter</a></li><li class="nav-list-item "><a href="/Crawl4AI/06_caching_system_.html" class="nav-list-link">Chapter 6: Caching System</a></li><li class="nav-list-item "><a href="/Crawl4AI/06_extractionstrategy.html" class="nav-list-link">ExtractionStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/07_crawlresult.html" class="nav-list-link">CrawlResult</a></li><li class="nav-list-item "><a href="/Crawl4AI/07_dispatcher_framework_.html" class="nav-list-link">Chapter 7: Dispatcher Framework</a></li><li class="nav-list-item "><a href="/Crawl4AI/08_async_logging_infrastructure_.html" class="nav-list-link">Chapter 8: Async Logging Infrastructure</a></li><li class="nav-list-item "><a href="/Crawl4AI/08_deepcrawlstrategy.html" class="nav-list-link">DeepCrawlStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/09_cachecontext___cachemode.html" class="nav-list-link">CacheContext & CacheMode</a></li><li class="nav-list-item "><a href="/Crawl4AI/09_api___docker_integration_.html" class="nav-list-link">Chapter 9: API & Docker Integration</a></li><li class="nav-list-item "><a href="/Crawl4AI/10_basedispatcher.html" class="nav-list-link">BaseDispatcher</a></li></ul></li><li class="nav-list-item active"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Crawl4ai category" aria-pressed="true"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/my-crawl4AI/" class="nav-list-link">My Tutorial for Crawl4ai</a><ul class="nav-list"><li class="nav-list-item "><a href="/my-crawl4ai/01_configuration_system_.html" class="nav-list-link">Chapter 1: Configuration System</a></li><li class="nav-list-item "><a href="/my-crawl4ai/02_asyncwebcrawler_.html" class="nav-list-link">Chapter 2: AsyncWebCrawler</a></li><li class="nav-list-item "><a href="/my-crawl4ai/03_content_extraction_pipeline_.html" class="nav-list-link">Chapter 3: Content Extraction Pipeline</a></li><li class="nav-list-item "><a href="/my-crawl4ai/04_url_filtering___scoring_.html" class="nav-list-link">Chapter 4: URL Filtering & Scoring</a></li><li class="nav-list-item "><a href="/my-crawl4ai/05_deep_crawling_system_.html" class="nav-list-link">Chapter 5: Deep Crawling System</a></li><li class="nav-list-item "><a href="/my-crawl4ai/06_caching_system_.html" class="nav-list-link">Chapter 6: Caching System</a></li><li class="nav-list-item active"><a href="/my-crawl4ai/07_dispatcher_framework_.html" class="nav-list-link active">Chapter 7: Dispatcher Framework</a></li><li class="nav-list-item "><a href="/my-crawl4ai/08_async_logging_infrastructure_.html" class="nav-list-link">Chapter 8: Async Logging Infrastructure</a></li><li class="nav-list-item "><a href="/my-crawl4ai/09_api___docker_integration_.html" class="nav-list-link">Chapter 9: API & Docker Integration</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Modular's Max category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/modular_max/" class="nav-list-link">My Tutorial for Modular's Max</a><ul class="nav-list"><li class="nav-list-item "><a href="/modular_max/01_settings___settings__class__.html" class="nav-list-link">Chapter 1: Settings Class</a></li><li class="nav-list-item "><a href="/modular_max/02_serving_api_layer__fastapi_app___routers__.html" class="nav-list-link">Chapter 2: Serving API Layer</a></li><li class="nav-list-item "><a href="/modular_max/03_llm_pipeline_orchestrator___tokengeneratorpipeline___.html" class="nav-list-link">Chapter 3: LLM Pipeline Orchestrator</a></li><li class="nav-list-item "><a href="/modular_max/04_model_worker_.html" class="nav-list-link">Chapter 4: Model Worker</a></li><li class="nav-list-item "><a href="/modular_max/05_scheduler___tokengenerationscheduler____embeddingsscheduler___.html" class="nav-list-link">Chapter 5: Scheduler</a></li><li class="nav-list-item "><a href="/modular_max/06_kv_cache_management_.html" class="nav-list-link">Chapter 6: KV Cache Management</a></li><li class="nav-list-item "><a href="/modular_max/07_enginequeue_.html" class="nav-list-link">Chapter 7: EngineQueue</a></li><li class="nav-list-item "><a href="/modular_max/08_telemetry_and_metrics___metrics____metricclient___.html" class="nav-list-link">Chapter 8: Telemetry and Metrics</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Mojo v1 category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/mojo-v1/" class="nav-list-link">My Tutorial for Mojo v1</a><ul class="nav-list"><li class="nav-list-item "><a href="/mojo-v1/01_addressspace_.html" class="nav-list-link">Chapter 1: AddressSpace</a></li><li class="nav-list-item "><a href="/mojo-v1/02_unsafepointer_.html" class="nav-list-link">Chapter 2: UnsafePointer</a></li><li class="nav-list-item "><a href="/mojo-v1/03_indexlist_.html" class="nav-list-link">Chapter 3: IndexList</a></li><li class="nav-list-item "><a href="/mojo-v1/04_dimlist_.html" class="nav-list-link">Chapter 4: DimList</a></li><li class="nav-list-item "><a href="/mojo-v1/05_ndbuffer_.html" class="nav-list-link">Chapter 5: NDBuffer</a></li><li class="nav-list-item "><a href="/mojo-v1/06_n_d_to_1d_indexing_logic__strided_memory_access__.html" class="nav-list-link">Chapter 6: N-D to 1D Indexing Logic</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Mojo v2 category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/mojo-v2/" class="nav-list-link">My Tutorial for Mojo v2</a><ul class="nav-list"><li class="nav-list-item "><a href="/mojo-v2/01_unsafepointer__as_used_by_ndbuffer__.html" class="nav-list-link">Chapter 1: UnsafePointer</a></li><li class="nav-list-item "><a href="/mojo-v2/02_dimlist_and_dim_.html" class="nav-list-link">Chapter 2: DimList and Dim</a></li><li class="nav-list-item "><a href="/mojo-v2/03_ndbuffer_.html" class="nav-list-link">Chapter 3: NDBuffer</a></li><li class="nav-list-item "><a href="/mojo-v2/04_strides_and_offset_computation_.html" class="nav-list-link">Chapter 4: Strides and Offset Computation</a></li><li class="nav-list-item "><a href="/mojo-v2/05_simd_data_access_.html" class="nav-list-link">Chapter 5: SIMD Data Access</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Comparisons category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/comparisons/" class="nav-list-link">Comparisons</a><ul class="nav-list"><li class="nav-list-item "><a href="/comparisons/crawl4ai-versions.html" class="nav-list-link">The original version of Crawl4AI vs. the sanity check I did</a></li><li class="nav-list-item "><a href="/comparisons/mojo-versions.html" class="nav-list-link">The 1st version of the Mojo Tutorial vs. The 2nd version of the Mojo Tutorial</a></li></ul></li><li class="nav-list-item"><a href="/generating/" class="nav-list-link">Generating & Preparing for the Mojo Tutorials using Pocket Flow</a></li><li class="nav-list-item"><a href="/design.html" class="nav-list-link">System Design</a></li></ul> <div class="nav-category">Crawl4AI</div> <ul class="nav-list"></ul> <div class="nav-category">Modular Max</div> <ul class="nav-list"></ul> <div class="nav-category">Mojo (v1)</div> <ul class="nav-list"></ul> <div class="nav-category">Mojo (v2)</div> <ul class="nav-list"></ul> <div class="nav-category">Generating</div> <ul class="nav-list"></ul> <div class="nav-category">AI Design</div> <ul class="nav-list"></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Two Tutorials for Mojo using Pocket Flow" aria-label="Search Two Tutorials for Mojo using Pocket Flow" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="https://github.com/MrBesterTester/pf-understand" class="site-button" > View on GitHub </a> </li> </ul> </nav> </div> <div id="main-content-wrap" class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/my-crawl4AI/">My Tutorial for Crawl4ai</a></li> <li class="breadcrumb-nav-list-item"><span>Chapter 7: Dispatcher Framework</span></li> </ol> </nav> <div id="main-content" class="main-content"> <main> <h1 id="chapter-7-dispatcher-framework"> <a href="#chapter-7-dispatcher-framework" class="anchor-heading" aria-labelledby="chapter-7-dispatcher-framework"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Chapter 7: Dispatcher Framework </h1> <p>In <a href="06_caching_system_.md">Chapter 6: Caching System</a>, we learned how to store and reuse web content to make our crawlers more efficient. Now, let’s explore how to manage multiple crawling operations happening at the same time with the Dispatcher Framework.</p> <h2 id="what-is-the-dispatcher-framework"> <a href="#what-is-the-dispatcher-framework" class="anchor-heading" aria-labelledby="what-is-the-dispatcher-framework"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> What is the Dispatcher Framework? </h2> <p>Imagine you’re running a busy restaurant kitchen. You need a head chef (the dispatcher) who coordinates all the cooks (crawler instances), making sure they don’t overcrowd the kitchen or use too many ingredients at once.</p> <p>The Dispatcher Framework in crawl4ai works the same way - it coordinates multiple crawler instances:</p> <ul> <li>It controls how many web pages are crawled at the same time</li> <li>It makes sure your computer’s memory doesn’t get overwhelmed</li> <li>It ensures websites aren’t bombarded with too many requests at once</li> </ul> <p>Let’s see a simple example of how this works:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">SemaphoreDispatcher</span><span class="p">,</span> <span class="n">CrawlerRunConfig</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">crawl_multiple_sites</span><span class="p">():</span>
    <span class="c1"># Create a dispatcher that allows 3 crawls at a time
</span>    <span class="n">dispatcher</span> <span class="o">=</span> <span class="n">SemaphoreDispatcher</span><span class="p">(</span><span class="n">semaphore_count</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    
    <span class="c1"># List of URLs to crawl
</span>    <span class="n">urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">"https://example.com"</span><span class="p">,</span> <span class="s">"https://example.org"</span><span class="p">,</span> <span class="s">"https://example.net"</span><span class="p">]</span>
    
    <span class="c1"># Create a crawler and run multiple URLs using our dispatcher
</span>    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">results</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun_many</span><span class="p">(</span>
            <span class="n">urls</span><span class="o">=</span><span class="n">urls</span><span class="p">,</span>
            <span class="n">dispatcher</span><span class="o">=</span><span class="n">dispatcher</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="n">CrawlerRunConfig</span><span class="p">()</span>
        <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">results</span>
</code></pre></div></div> <p>In this example, we’re using a <code class="language-plaintext highlighter-rouge">SemaphoreDispatcher</code> to crawl three URLs at the same time, not one after another. This is much faster!</p> <h2 id="two-types-of-dispatchers"> <a href="#two-types-of-dispatchers" class="anchor-heading" aria-labelledby="two-types-of-dispatchers"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Two Types of Dispatchers </h2> <p>The Dispatcher Framework offers two main types of dispatchers, each with different strengths:</p> <h3 id="1-semaphoredispatcher-simple-and-predictable"> <a href="#1-semaphoredispatcher-simple-and-predictable" class="anchor-heading" aria-labelledby="1-semaphoredispatcher-simple-and-predictable"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1. SemaphoreDispatcher: Simple and Predictable </h3> <p>The <code class="language-plaintext highlighter-rouge">SemaphoreDispatcher</code> is like a restaurant with a fixed number of tables. It allows a specific number of crawls to happen at the same time - no more, no less.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">SemaphoreDispatcher</span>

<span class="c1"># Create a dispatcher that allows 5 simultaneous crawls
</span><span class="n">dispatcher</span> <span class="o">=</span> <span class="n">SemaphoreDispatcher</span><span class="p">(</span><span class="n">semaphore_count</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div> <p>This dispatcher is great when:</p> <ul> <li>You want predictable behavior</li> <li>You know exactly how many concurrent crawls your system can handle</li> <li>You want to set a strict limit on resource usage</li> </ul> <h3 id="2-memoryadaptivedispatcher-smart-and-flexible"> <a href="#2-memoryadaptivedispatcher-smart-and-flexible" class="anchor-heading" aria-labelledby="2-memoryadaptivedispatcher-smart-and-flexible"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2. MemoryAdaptiveDispatcher: Smart and Flexible </h3> <p>The <code class="language-plaintext highlighter-rouge">MemoryAdaptiveDispatcher</code> is like a restaurant that adjusts how many tables are available based on how busy the kitchen is. It monitors your computer’s memory and automatically adjusts how many crawls happen at once.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">MemoryAdaptiveDispatcher</span>

<span class="c1"># Create a dispatcher that adapts to memory usage
</span><span class="n">dispatcher</span> <span class="o">=</span> <span class="n">MemoryAdaptiveDispatcher</span><span class="p">(</span>
    <span class="n">memory_threshold_percent</span><span class="o">=</span><span class="mf">90.0</span><span class="p">,</span>  <span class="c1"># Slow down when memory reaches 90%
</span>    <span class="n">max_session_permit</span><span class="o">=</span><span class="mi">20</span>           <span class="c1"># Never exceed 20 simultaneous crawls
</span><span class="p">)</span>
</code></pre></div></div> <p>This dispatcher is perfect when:</p> <ul> <li>You want to maximize efficiency without crashing your program</li> <li>Your system’s available memory changes over time</li> <li>You’re crawling pages with unpredictable memory requirements</li> </ul> <h2 id="managing-rate-limits-with-ratelimiter"> <a href="#managing-rate-limits-with-ratelimiter" class="anchor-heading" aria-labelledby="managing-rate-limits-with-ratelimiter"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Managing Rate Limits with RateLimiter </h2> <p>When crawling websites, it’s important to be polite and not send too many requests too quickly. The <code class="language-plaintext highlighter-rouge">RateLimiter</code> helps with this:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">RateLimiter</span><span class="p">,</span> <span class="n">MemoryAdaptiveDispatcher</span>

<span class="c1"># Create a rate limiter that waits 1-3 seconds between requests
</span><span class="n">rate_limiter</span> <span class="o">=</span> <span class="n">RateLimiter</span><span class="p">(</span>
    <span class="n">base_delay</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">),</span>  <span class="c1"># Wait 1-3 seconds between requests
</span>    <span class="n">max_delay</span><span class="o">=</span><span class="mf">60.0</span><span class="p">,</span>         <span class="c1"># Never wait more than 60 seconds
</span>    <span class="n">max_retries</span><span class="o">=</span><span class="mi">3</span>           <span class="c1"># Try a maximum of 3 times if rate limited
</span><span class="p">)</span>

<span class="c1"># Add the rate limiter to our dispatcher
</span><span class="n">dispatcher</span> <span class="o">=</span> <span class="n">MemoryAdaptiveDispatcher</span><span class="p">(</span><span class="n">rate_limiter</span><span class="o">=</span><span class="n">rate_limiter</span><span class="p">)</span>
</code></pre></div></div> <p>The <code class="language-plaintext highlighter-rouge">RateLimiter</code> tracks each domain separately and adjusts wait times if it detects rate limiting (like HTTP 429 responses).</p> <h2 id="processing-results-in-real-time-with-streaming"> <a href="#processing-results-in-real-time-with-streaming" class="anchor-heading" aria-labelledby="processing-results-in-real-time-with-streaming"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Processing Results in Real-Time with Streaming </h2> <p>Sometimes you don’t want to wait for all URLs to finish crawling before processing results. Streaming allows you to process results as they come in:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">CrawlerRunConfig</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">stream_results</span><span class="p">():</span>
    <span class="n">urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">"https://example.com"</span><span class="p">,</span> <span class="s">"https://example.org"</span><span class="p">,</span> <span class="s">"https://example.net"</span><span class="p">]</span>
    
    <span class="c1"># Enable streaming in the configuration
</span>    <span class="n">config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span><span class="n">stream</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    
    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="c1"># This returns an async generator
</span>        <span class="n">results_generator</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun_many</span><span class="p">(</span><span class="n">urls</span><span class="o">=</span><span class="n">urls</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
        
        <span class="c1"># Process results as they arrive
</span>        <span class="k">async</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results_generator</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Just finished: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">url</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            <span class="c1"># Process each result immediately
</span></code></pre></div></div> <p>With streaming, you can start working with results from fast-loading pages while slower pages are still being crawled.</p> <h2 id="a-complete-example-news-crawler-with-memory-adaptation"> <a href="#a-complete-example-news-crawler-with-memory-adaptation" class="anchor-heading" aria-labelledby="a-complete-example-news-crawler-with-memory-adaptation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> A Complete Example: News Crawler with Memory Adaptation </h2> <p>Let’s put everything together in a more complete example. Imagine we’re building a news crawler that needs to handle many URLs efficiently:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">MemoryAdaptiveDispatcher</span><span class="p">,</span> <span class="n">RateLimiter</span><span class="p">,</span> <span class="n">CrawlerRunConfig</span>
<span class="p">)</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">crawl_news_sites</span><span class="p">():</span>
    <span class="c1"># Create a memory-adaptive dispatcher with rate limiting
</span>    <span class="n">dispatcher</span> <span class="o">=</span> <span class="n">MemoryAdaptiveDispatcher</span><span class="p">(</span>
        <span class="n">memory_threshold_percent</span><span class="o">=</span><span class="mf">85.0</span><span class="p">,</span>  <span class="c1"># Be conservative with memory
</span>        <span class="n">rate_limiter</span><span class="o">=</span><span class="n">RateLimiter</span><span class="p">(</span><span class="n">base_delay</span><span class="o">=</span><span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">))</span>  <span class="c1"># Be extra polite
</span>    <span class="p">)</span>
    
    <span class="c1"># List of news sites to crawl
</span>    <span class="n">news_sites</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">"https://example-news.com/tech"</span><span class="p">,</span>
        <span class="s">"https://example-news.com/business"</span><span class="p">,</span>
        <span class="c1"># ... more URLs ...
</span>    <span class="p">]</span>
    
    <span class="c1"># Configure how we want to crawl
</span>    <span class="n">config</span> <span class="o">=</span> <span class="n">CrawlerRunConfig</span><span class="p">(</span>
        <span class="n">screenshot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>  <span class="c1"># Take screenshots
</span>        <span class="n">stream</span><span class="o">=</span><span class="bp">True</span>       <span class="c1"># Process results as they arrive
</span>    <span class="p">)</span>
    
    <span class="c1"># Run the crawler with our dispatcher
</span>    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">results_stream</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun_many</span><span class="p">(</span>
            <span class="n">urls</span><span class="o">=</span><span class="n">news_sites</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
            <span class="n">dispatcher</span><span class="o">=</span><span class="n">dispatcher</span>
        <span class="p">)</span>
        
        <span class="c1"># Process each result as it completes
</span>        <span class="k">async</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results_stream</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">success</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Successfully crawled: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">url</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
                <span class="c1"># Process the content...
</span>            <span class="k">else</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Failed to crawl: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">url</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div> <p>This example shows how to:</p> <ol> <li>Create a memory-adaptive dispatcher with rate limiting</li> <li>Configure it for cautious memory usage and polite crawling</li> <li>Stream and process results as they become available</li> </ol> <h2 id="what-happens-under-the-hood"> <a href="#what-happens-under-the-hood" class="anchor-heading" aria-labelledby="what-happens-under-the-hood"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> What Happens Under the Hood </h2> <p>When you use the Dispatcher Framework, a lot happens behind the scenes. Let’s look at a simplified view:</p><pre><code class="language-mermaid">sequenceDiagram
    participant App as Your Code
    participant WC as WebCrawler
    participant DP as Dispatcher
    participant RL as RateLimiter
    participant MM as Memory Monitor

    App-&gt;&gt;WC: arun_many(urls, dispatcher)
    WC-&gt;&gt;DP: run_urls(urls, crawler, config)
    
    activate DP
    DP-&gt;&gt;MM: Start monitoring memory
    
    loop For each URL (controlled by dispatcher)
        DP-&gt;&gt;RL: wait_if_needed(url)
        RL--&gt;&gt;DP: OK to proceed
        
        alt Memory usage is normal
            DP-&gt;&gt;WC: arun(url, config)
            WC--&gt;&gt;DP: Return result
        else Memory pressure is high
            DP-&gt;&gt;DP: Re-queue URL with higher wait time
        end
        
        DP-&gt;&gt;App: Yield result (if streaming)
    end
    
    DP-&gt;&gt;MM: Stop monitoring
    DP--&gt;&gt;WC: Return all results
    WC--&gt;&gt;App: Return results
    deactivate DP
</code></pre><p>Here’s what happens step by step:</p> <ol> <li>Your code calls <code class="language-plaintext highlighter-rouge">crawler.arun_many()</code> with a list of URLs and a dispatcher</li> <li>The WebCrawler passes the URLs to the dispatcher’s <code class="language-plaintext highlighter-rouge">run_urls</code> method</li> <li>The dispatcher starts a memory monitor if it’s a <code class="language-plaintext highlighter-rouge">MemoryAdaptiveDispatcher</code></li> <li>For each URL: <ul> <li>The dispatcher checks with the rate limiter if it’s OK to crawl</li> <li>If memory usage is normal, it crawls the URL</li> <li>If memory is under pressure, it might delay some URLs</li> <li>It yields or collects the result</li> </ul> </li> <li>Finally, all results are returned to your code</li> </ol> <h2 id="implementation-details-memoryadaptivedispatcher"> <a href="#implementation-details-memoryadaptivedispatcher" class="anchor-heading" aria-labelledby="implementation-details-memoryadaptivedispatcher"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Implementation Details: MemoryAdaptiveDispatcher </h2> <p>Let’s look at how the <code class="language-plaintext highlighter-rouge">MemoryAdaptiveDispatcher</code> is implemented:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># From crawl4ai/async_dispatcher.py (simplified)
</span><span class="k">class</span> <span class="nc">MemoryAdaptiveDispatcher</span><span class="p">(</span><span class="n">BaseDispatcher</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">memory_threshold_percent</span><span class="o">=</span><span class="mf">90.0</span><span class="p">,</span>
        <span class="n">critical_threshold_percent</span><span class="o">=</span><span class="mf">95.0</span><span class="p">,</span>
        <span class="n">recovery_threshold_percent</span><span class="o">=</span><span class="mf">85.0</span><span class="p">,</span>
        <span class="n">max_session_permit</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">rate_limiter</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">memory_threshold_percent</span> <span class="o">=</span> <span class="n">memory_threshold_percent</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">critical_threshold_percent</span> <span class="o">=</span> <span class="n">critical_threshold_percent</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">max_session_permit</span> <span class="o">=</span> <span class="n">max_session_permit</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">rate_limiter</span> <span class="o">=</span> <span class="n">rate_limiter</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">memory_pressure_mode</span> <span class="o">=</span> <span class="bp">False</span>
</code></pre></div></div> <p>The constructor sets up thresholds for memory management:</p> <ul> <li><code class="language-plaintext highlighter-rouge">memory_threshold_percent</code>: When to start slowing down (90% by default)</li> <li><code class="language-plaintext highlighter-rouge">critical_threshold_percent</code>: When to pause crawling (95% by default)</li> <li><code class="language-plaintext highlighter-rouge">max_session_permit</code>: Maximum concurrent crawls (20 by default)</li> </ul> <p>The dispatcher monitors memory with a background task:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># From the _memory_monitor_task method (simplified)
</span><span class="k">async</span> <span class="k">def</span> <span class="nf">_memory_monitor_task</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="c1"># Check current memory usage
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">current_memory_percent</span> <span class="o">=</span> <span class="n">psutil</span><span class="p">.</span><span class="n">virtual_memory</span><span class="p">().</span><span class="n">percent</span>
        
        <span class="c1"># Enter pressure mode if memory is high
</span>        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">memory_pressure_mode</span> <span class="ow">and</span> <span class="bp">self</span><span class="p">.</span><span class="n">current_memory_percent</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="p">.</span><span class="n">memory_threshold_percent</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">memory_pressure_mode</span> <span class="o">=</span> <span class="bp">True</span>
            
        <span class="c1"># Exit pressure mode if memory is lower
</span>        <span class="k">elif</span> <span class="bp">self</span><span class="p">.</span><span class="n">memory_pressure_mode</span> <span class="ow">and</span> <span class="bp">self</span><span class="p">.</span><span class="n">current_memory_percent</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="p">.</span><span class="n">recovery_threshold_percent</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">memory_pressure_mode</span> <span class="o">=</span> <span class="bp">False</span>
            
        <span class="k">await</span> <span class="n">asyncio</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">check_interval</span><span class="p">)</span>
</code></pre></div></div> <p>This continuously checks memory usage and adjusts the <code class="language-plaintext highlighter-rouge">memory_pressure_mode</code> flag, which affects how URLs are processed.</p> <h2 id="implementation-details-semaphoredispatcher"> <a href="#implementation-details-semaphoredispatcher" class="anchor-heading" aria-labelledby="implementation-details-semaphoredispatcher"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Implementation Details: SemaphoreDispatcher </h2> <p>The <code class="language-plaintext highlighter-rouge">SemaphoreDispatcher</code> is simpler but still powerful:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># From crawl4ai/async_dispatcher.py (simplified)
</span><span class="k">class</span> <span class="nc">SemaphoreDispatcher</span><span class="p">(</span><span class="n">BaseDispatcher</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">semaphore_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">rate_limiter</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">rate_limiter</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">semaphore_count</span> <span class="o">=</span> <span class="n">semaphore_count</span>
        
    <span class="k">async</span> <span class="k">def</span> <span class="nf">crawl_url</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">task_id</span><span class="p">,</span> <span class="n">semaphore</span><span class="p">):</span>
        <span class="k">async</span> <span class="k">with</span> <span class="n">semaphore</span><span class="p">:</span>
            <span class="c1"># Crawl the URL with rate limiting
</span>            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">rate_limiter</span><span class="p">:</span>
                <span class="k">await</span> <span class="bp">self</span><span class="p">.</span><span class="n">rate_limiter</span><span class="p">.</span><span class="n">wait_if_needed</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
                
            <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="p">.</span><span class="n">crawler</span><span class="p">.</span><span class="n">arun</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">result</span>
</code></pre></div></div> <p>The <code class="language-plaintext highlighter-rouge">SemaphoreDispatcher</code> uses an asyncio Semaphore to limit concurrent tasks. When a task is done, it releases its slot, allowing another task to start.</p> <h2 id="advanced-usage-monitoring-crawl-progress"> <a href="#advanced-usage-monitoring-crawl-progress" class="anchor-heading" aria-labelledby="advanced-usage-monitoring-crawl-progress"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Advanced Usage: Monitoring Crawl Progress </h2> <p>You can monitor the progress of your crawls using the <code class="language-plaintext highlighter-rouge">CrawlerMonitor</code>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">crawl4ai</span> <span class="kn">import</span> <span class="n">AsyncWebCrawler</span><span class="p">,</span> <span class="n">MemoryAdaptiveDispatcher</span><span class="p">,</span> <span class="n">CrawlerMonitor</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">monitored_crawl</span><span class="p">():</span>
    <span class="c1"># Create a monitor
</span>    <span class="n">monitor</span> <span class="o">=</span> <span class="n">CrawlerMonitor</span><span class="p">()</span>
    
    <span class="c1"># Create a dispatcher with the monitor
</span>    <span class="n">dispatcher</span> <span class="o">=</span> <span class="n">MemoryAdaptiveDispatcher</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="n">monitor</span><span class="p">)</span>
    
    <span class="c1"># Run your crawl
</span>    <span class="k">async</span> <span class="k">with</span> <span class="n">AsyncWebCrawler</span><span class="p">()</span> <span class="k">as</span> <span class="n">crawler</span><span class="p">:</span>
        <span class="n">results</span> <span class="o">=</span> <span class="k">await</span> <span class="n">crawler</span><span class="p">.</span><span class="n">arun_many</span><span class="p">(</span>
            <span class="n">urls</span><span class="o">=</span><span class="p">[</span><span class="s">"https://example.com"</span><span class="p">,</span> <span class="s">"https://example.org"</span><span class="p">],</span>
            <span class="n">dispatcher</span><span class="o">=</span><span class="n">dispatcher</span>
        <span class="p">)</span>
        
    <span class="c1"># Get statistics about the crawl
</span>    <span class="n">stats</span> <span class="o">=</span> <span class="n">monitor</span><span class="p">.</span><span class="n">get_statistics</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Completed: </span><span class="si">{</span><span class="n">stats</span><span class="p">[</span><span class="s">'completed'</span><span class="p">]</span><span class="si">}</span><span class="s"> URLs"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Failed: </span><span class="si">{</span><span class="n">stats</span><span class="p">[</span><span class="s">'failed'</span><span class="p">]</span><span class="si">}</span><span class="s"> URLs"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Average memory usage: </span><span class="si">{</span><span class="n">stats</span><span class="p">[</span><span class="s">'avg_memory_usage'</span><span class="p">]</span><span class="si">}</span><span class="s"> MB"</span><span class="p">)</span>
</code></pre></div></div> <p>The monitor collects statistics about each URL, including success/failure, memory usage, and timing.</p> <h2 id="conclusion"> <a href="#conclusion" class="anchor-heading" aria-labelledby="conclusion"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Conclusion </h2> <p>The Dispatcher Framework is like having an expert traffic controller for your web crawling operations. It helps you crawl multiple websites simultaneously while being careful about system resources and polite to the websites you’re visiting.</p> <p>In this chapter, we’ve learned:</p> <ul> <li>How to use the <code class="language-plaintext highlighter-rouge">SemaphoreDispatcher</code> for simple concurrent crawling</li> <li>How to use the <code class="language-plaintext highlighter-rouge">MemoryAdaptiveDispatcher</code> for smart resource management</li> <li>How to enforce rate limits with the <code class="language-plaintext highlighter-rouge">RateLimiter</code></li> <li>How to process results in real-time with streaming</li> <li>How the dispatch process works under the hood</li> </ul> <p>With the Dispatcher Framework, you can build efficient, robust, and polite web crawlers that make the most of your system’s resources without overwhelming them.</p> <p>In the next chapter, <a href="08_async_logging_infrastructure_.md">Async Logging Infrastructure</a>, we’ll learn how to track what’s happening in our crawlers with detailed logs, which is especially important when dealing with complex crawling operations.</p><hr /> <p>Generated by <a href="https://github.com/The-Pocket/Tutorial-Codebase-Knowledge">AI Codebase Knowledge Builder</a></p> </main> </div> </div> <div class="search-overlay"></div> </div> <script type="module"> import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.6.0/dist/mermaid.esm.min.mjs'; var config = {} ; mermaid.initialize(config); mermaid.run({ querySelector: '.language-mermaid', }); </script> </body> </html>
