<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Chapter 7: EngineQueue | Two Tutorials for Mojo using Pocket Flow</title> <meta name="generator" content="Jekyll v4.3.4" /> <meta property="og:title" content="Chapter 7: EngineQueue" /> <meta name="author" content="Sam Kirk" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Documentation generated using AI to explain codebases" /> <meta property="og:description" content="Documentation generated using AI to explain codebases" /> <link rel="canonical" href="http://localhost:4000/modular_max/07_enginequeue_.html" /> <meta property="og:url" content="http://localhost:4000/modular_max/07_enginequeue_.html" /> <meta property="og:site_name" content="Two Tutorials for Mojo using Pocket Flow" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="Chapter 7: EngineQueue" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Sam Kirk","url":"https://www.columbia.edu/~zh2408/"},"description":"Documentation generated using AI to explain codebases","headline":"Chapter 7: EngineQueue","url":"http://localhost:4000/modular_max/07_enginequeue_.html"}</script> <!-- End Jekyll SEO tag --> <!-- Add Mermaid support --> <script src="https://cdn.jsdelivr.net/npm/mermaid@11.6.0/dist/mermaid.min.js"></script> <script> document.addEventListener("DOMContentLoaded", function() { mermaid.initialize({ startOnLoad: true, theme: "default" }); // Process code blocks document.querySelectorAll('pre code.language-mermaid').forEach(function(block) { // Create a div with class 'mermaid' var mermaidDiv = document.createElement('div'); mermaidDiv.className = 'mermaid'; mermaidDiv.innerHTML = block.textContent; // Replace the parent pre with the mermaid div block.parentNode.parentNode.replaceChild(mermaidDiv, block.parentNode); console.log("Processed Mermaid block:", mermaidDiv.innerHTML.substring(0, 50) + "..."); }); console.log("Mermaid initialization complete. Version:", mermaid.version()); }); </script> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> Two Tutorials for Mojo using Pocket Flow </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </a> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Crawl4ai category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/my-crawl4AI/" class="nav-list-link">My Tutorial for Crawl4ai</a><ul class="nav-list"><li class="nav-list-item "><a href="/my-crawl4ai/01_configuration_system_.html" class="nav-list-link">Chapter 1: Configuration System</a></li><li class="nav-list-item "><a href="/my-crawl4ai/02_asyncwebcrawler_.html" class="nav-list-link">Chapter 2: AsyncWebCrawler</a></li><li class="nav-list-item "><a href="/my-crawl4ai/03_content_extraction_pipeline_.html" class="nav-list-link">Chapter 3: Content Extraction Pipeline</a></li><li class="nav-list-item "><a href="/my-crawl4ai/04_url_filtering___scoring_.html" class="nav-list-link">Chapter 4: URL Filtering & Scoring</a></li><li class="nav-list-item "><a href="/my-crawl4ai/05_deep_crawling_system_.html" class="nav-list-link">Chapter 5: Deep Crawling System</a></li><li class="nav-list-item "><a href="/my-crawl4ai/06_caching_system_.html" class="nav-list-link">Chapter 6: Caching System</a></li><li class="nav-list-item "><a href="/my-crawl4ai/07_dispatcher_framework_.html" class="nav-list-link">Chapter 7: Dispatcher Framework</a></li><li class="nav-list-item "><a href="/my-crawl4ai/08_async_logging_infrastructure_.html" class="nav-list-link">Chapter 8: Async Logging Infrastructure</a></li><li class="nav-list-item "><a href="/my-crawl4ai/09_api___docker_integration_.html" class="nav-list-link">Chapter 9: API & Docker Integration</a></li></ul></li><li class="nav-list-item"><a href="/design.html" class="nav-list-link">System Design</a></li><li class="nav-list-item active"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Modular's Max category" aria-pressed="true"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/modular_max/" class="nav-list-link">My Tutorial for Modular's Max</a><ul class="nav-list"><li class="nav-list-item "><a href="/modular_max/01_settings___settings__class__.html" class="nav-list-link">Chapter 1: Settings Class</a></li><li class="nav-list-item "><a href="/modular_max/02_serving_api_layer__fastapi_app___routers__.html" class="nav-list-link">Chapter 2: Serving API Layer</a></li><li class="nav-list-item "><a href="/modular_max/03_llm_pipeline_orchestrator___tokengeneratorpipeline___.html" class="nav-list-link">Chapter 3: LLM Pipeline Orchestrator</a></li><li class="nav-list-item "><a href="/modular_max/04_model_worker_.html" class="nav-list-link">Chapter 4: Model Worker</a></li><li class="nav-list-item "><a href="/modular_max/05_scheduler___tokengenerationscheduler____embeddingsscheduler___.html" class="nav-list-link">Chapter 5: Scheduler</a></li><li class="nav-list-item "><a href="/modular_max/06_kv_cache_management_.html" class="nav-list-link">Chapter 6: KV Cache Management</a></li><li class="nav-list-item active"><a href="/modular_max/07_enginequeue_.html" class="nav-list-link active">Chapter 7: EngineQueue</a></li><li class="nav-list-item "><a href="/modular_max/08_telemetry_and_metrics___metrics____metricclient___.html" class="nav-list-link">Chapter 8: Telemetry and Metrics</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Mojo v1 category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/mojo-v1/" class="nav-list-link">My Tutorial for Mojo v1</a><ul class="nav-list"><li class="nav-list-item "><a href="/mojo-v1/01_addressspace_.html" class="nav-list-link">Chapter 1: AddressSpace</a></li><li class="nav-list-item "><a href="/mojo-v1/02_unsafepointer_.html" class="nav-list-link">Chapter 2: UnsafePointer</a></li><li class="nav-list-item "><a href="/mojo-v1/03_indexlist_.html" class="nav-list-link">Chapter 3: IndexList</a></li><li class="nav-list-item "><a href="/mojo-v1/04_dimlist_.html" class="nav-list-link">Chapter 4: DimList</a></li><li class="nav-list-item "><a href="/mojo-v1/05_ndbuffer_.html" class="nav-list-link">Chapter 5: NDBuffer</a></li><li class="nav-list-item "><a href="/mojo-v1/06_n_d_to_1d_indexing_logic__strided_memory_access__.html" class="nav-list-link">Chapter 6: N-D to 1D Indexing Logic</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in My Tutorial for Mojo v2 category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/mojo-v2/" class="nav-list-link">My Tutorial for Mojo v2</a><ul class="nav-list"><li class="nav-list-item "><a href="/mojo-v2/01_unsafepointer__as_used_by_ndbuffer__.html" class="nav-list-link">Chapter 1: UnsafePointer</a></li><li class="nav-list-item "><a href="/mojo-v2/02_dimlist_and_dim_.html" class="nav-list-link">Chapter 2: DimList and Dim</a></li><li class="nav-list-item "><a href="/mojo-v2/03_ndbuffer_.html" class="nav-list-link">Chapter 3: NDBuffer</a></li><li class="nav-list-item "><a href="/mojo-v2/04_strides_and_offset_computation_.html" class="nav-list-link">Chapter 4: Strides and Offset Computation</a></li><li class="nav-list-item "><a href="/mojo-v2/05_simd_data_access_.html" class="nav-list-link">Chapter 5: SIMD Data Access</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Crawl4AI category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/Crawl4AI/" class="nav-list-link">Crawl4AI</a><ul class="nav-list"><li class="nav-list-item "><a href="/Crawl4AI/01_asynccrawlerstrategy.html" class="nav-list-link">AsyncCrawlerStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/01_configuration_system_.html" class="nav-list-link">Chapter 1: Configuration System</a></li><li class="nav-list-item "><a href="/Crawl4AI/02_asyncwebcrawler.html" class="nav-list-link">AsyncWebCrawler</a></li><li class="nav-list-item "><a href="/Crawl4AI/02_asyncwebcrawler_.html" class="nav-list-link">Chapter 2: AsyncWebCrawler</a></li><li class="nav-list-item "><a href="/Crawl4AI/03_content_extraction_pipeline_.html" class="nav-list-link">Chapter 3: Content Extraction Pipeline</a></li><li class="nav-list-item "><a href="/Crawl4AI/03_crawlerrunconfig.html" class="nav-list-link">CrawlerRunConfig</a></li><li class="nav-list-item "><a href="/Crawl4AI/04_contentscrapingstrategy.html" class="nav-list-link">ContentScrapingStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/04_url_filtering___scoring_.html" class="nav-list-link">Chapter 4: URL Filtering & Scoring</a></li><li class="nav-list-item "><a href="/Crawl4AI/05_deep_crawling_system_.html" class="nav-list-link">Chapter 5: Deep Crawling System</a></li><li class="nav-list-item "><a href="/Crawl4AI/05_relevantcontentfilter.html" class="nav-list-link">RelevantContentFilter</a></li><li class="nav-list-item "><a href="/Crawl4AI/06_caching_system_.html" class="nav-list-link">Chapter 6: Caching System</a></li><li class="nav-list-item "><a href="/Crawl4AI/06_extractionstrategy.html" class="nav-list-link">ExtractionStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/07_crawlresult.html" class="nav-list-link">CrawlResult</a></li><li class="nav-list-item "><a href="/Crawl4AI/07_dispatcher_framework_.html" class="nav-list-link">Chapter 7: Dispatcher Framework</a></li><li class="nav-list-item "><a href="/Crawl4AI/08_deepcrawlstrategy.html" class="nav-list-link">DeepCrawlStrategy</a></li><li class="nav-list-item "><a href="/Crawl4AI/08_async_logging_infrastructure_.html" class="nav-list-link">Chapter 8: Async Logging Infrastructure</a></li><li class="nav-list-item "><a href="/Crawl4AI/09_api___docker_integration_.html" class="nav-list-link">Chapter 9: API & Docker Integration</a></li><li class="nav-list-item "><a href="/Crawl4AI/09_cachecontext___cachemode.html" class="nav-list-link">CacheContext & CacheMode</a></li><li class="nav-list-item "><a href="/Crawl4AI/10_basedispatcher.html" class="nav-list-link">BaseDispatcher</a></li></ul></li></ul> <div class="nav-category">Crawl4AI</div> <ul class="nav-list"></ul> <div class="nav-category">Modular Max</div> <ul class="nav-list"></ul> <div class="nav-category">Mojo (v1)</div> <ul class="nav-list"></ul> <div class="nav-category">Mojo (v2)</div> <ul class="nav-list"></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Two Tutorials for Mojo using Pocket Flow" aria-label="Search Two Tutorials for Mojo using Pocket Flow" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="https://github.com/MrBesterTester/pf-understand" class="site-button" > View on GitHub </a> </li> </ul> </nav> </div> <div id="main-content-wrap" class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/modular_max/">My Tutorial for Modular's Max</a></li> <li class="breadcrumb-nav-list-item"><span>Chapter 7: EngineQueue</span></li> </ol> </nav> <div id="main-content" class="main-content"> <main> <h1 id="chapter-7-enginequeue"> <a href="#chapter-7-enginequeue" class="anchor-heading" aria-labelledby="chapter-7-enginequeue"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Chapter 7: EngineQueue </h1> <p>Welcome back! In <a href="06_kv_cache_management_.md">Chapter 6: KV Cache Management</a>, we learned how <code class="language-plaintext highlighter-rouge">modular</code> intelligently manages memory for ongoing text generation using a “smart scratchpad” called the KV Cache. We’ve seen the <a href="03_llm_pipeline_orchestrator___tokengeneratorpipeline___.md">LLM Pipeline Orchestrator (<code class="language-plaintext highlighter-rouge">TokenGeneratorPipeline</code>)</a> prepare requests and the <a href="04_model_worker_.md">Model Worker</a> (with its <a href="05_scheduler___tokengenerationscheduler____embeddingsscheduler___.md">Scheduler (<code class="language-plaintext highlighter-rouge">TokenGenerationScheduler</code>, <code class="language-plaintext highlighter-rouge">EmbeddingsScheduler</code>)</a>) do the heavy AI lifting.</p> <p>But how do these two major components, which actually run in <em>different processes</em> (like separate offices in a building), talk to each other? If the <code class="language-plaintext highlighter-rouge">TokenGeneratorPipeline</code> wants to send a new story prompt to the <code class="language-plaintext highlighter-rouge">Model Worker</code>, how does it do that? And how does the <code class="language-plaintext highlighter-rouge">Model Worker</code> send the generated story back?</p> <p>This is where the <strong><code class="language-plaintext highlighter-rouge">EngineQueue</code></strong> steps in. It’s the primary communication backbone of <code class="language-plaintext highlighter-rouge">modular</code>.</p> <h2 id="what-problem-does-enginequeue-solve"> <a href="#what-problem-does-enginequeue-solve" class="anchor-heading" aria-labelledby="what-problem-does-enginequeue-solve"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> What Problem Does <code class="language-plaintext highlighter-rouge">EngineQueue</code> Solve? </h2> <p>Imagine a large organization with a main office (our API server) and a specialized research lab (our Model Worker). The main office receives customer requests (like “analyze this sample”), and the lab has the special equipment and experts to do the analysis.</p> <ul> <li>The main office can’t just shout across town to the lab.</li> <li>The lab can’t just appear in the main office with the results.</li> <li>They need a reliable way to send documents (data) back and forth.</li> </ul> <p>This is exactly the situation between our main API server process and the Model Worker process. They operate independently. The <code class="language-plaintext highlighter-rouge">EngineQueue</code> solves this by providing a robust and efficient <strong>inter-process communication (IPC)</strong> mechanism. Think of it as a sophisticated, multi-lane pneumatic tube system connecting the main office and the research lab.</p> <p>It allows:</p> <ul> <li>The API server (via the <code class="language-plaintext highlighter-rouge">TokenGeneratorPipeline</code>) to send new tasks (like “generate text for this prompt”) to the Model Worker.</li> <li>The Model Worker to send results (the generated text) back to the API server.</li> <li>A way to send cancellation signals if a task needs to be stopped early.</li> </ul> <p>Without <code class="language-plaintext highlighter-rouge">EngineQueue</code>, these two core parts of <code class="language-plaintext highlighter-rouge">modular</code> couldn’t cooperate!</p> <h2 id="meet-the-enginequeue-the-pneumatic-tube-system"> <a href="#meet-the-enginequeue-the-pneumatic-tube-system" class="anchor-heading" aria-labelledby="meet-the-enginequeue-the-pneumatic-tube-system"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Meet the <code class="language-plaintext highlighter-rouge">EngineQueue</code>: The Pneumatic Tube System </h2> <p>The <code class="language-plaintext highlighter-rouge">EngineQueue</code> isn’t just one tube; it’s a set of specialized inter-process queues designed for high-performance message passing. Each queue is like a dedicated pneumatic tube for a specific type of “document”:</p> <ol> <li><strong>Request Queue (<code class="language-plaintext highlighter-rouge">request_q</code>)</strong>: Carries new tasks (e.g., tokenized prompts) from the <code class="language-plaintext highlighter-rouge">TokenGeneratorPipeline</code> (in the main API server process) to the <code class="language-plaintext highlighter-rouge">Scheduler</code> (in the Model Worker process). <ul> <li><em>Analogy</em>: A tube labeled “NEW WORK ORDERS” going from the main office to the lab.</li> </ul> </li> <li><strong>Response Queue (<code class="language-plaintext highlighter-rouge">response_q</code>)</strong>: Carries completed results (e.g., generated tokens or embeddings) from the <code class="language-plaintext highlighter-rouge">Scheduler</code> back to the <code class="language-plaintext highlighter-rouge">TokenGeneratorPipeline</code>. <ul> <li><em>Analogy</em>: A tube labeled “COMPLETED RESULTS” going from the lab back to the main office.</li> </ul> </li> <li><strong>Cancellation Queue (<code class="language-plaintext highlighter-rouge">cancel_q</code>)</strong>: Carries signals to tell the <code class="language-plaintext highlighter-rouge">Scheduler</code> to stop working on a specific task if it’s no longer needed. <ul> <li><em>Analogy</em>: An express tube labeled “URGENT: STOP TASK XYZ” going to the lab.</li> </ul> </li> </ol> <p><code class="language-plaintext highlighter-rouge">modular</code> can use different technologies for these queues, primarily:</p> <ul> <li><strong>Standard Python <code class="language-plaintext highlighter-rouge">multiprocessing.Queue</code></strong>: A built-in Python way to share data between processes. Good and reliable.</li> <li><strong>ZMQ (ZeroMQ)</strong>: A high-performance messaging library. Often faster, especially for more complex scenarios or larger data, but adds an external dependency.</li> </ul> <p>The <code class="language-plaintext highlighter-rouge">EngineQueue</code> abstraction allows <code class="language-plaintext highlighter-rouge">modular</code> to potentially switch between these underlying technologies based on configuration or needs.</p> <h2 id="how-it-works-a-simplified-flow"> <a href="#how-it-works-a-simplified-flow" class="anchor-heading" aria-labelledby="how-it-works-a-simplified-flow"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> How It Works: A Simplified Flow </h2> <p>Let’s trace how a request for text generation flows through the <code class="language-plaintext highlighter-rouge">EngineQueue</code>:</p> <ol> <li> <p><strong>API Server Gets a Request</strong>: A user asks <code class="language-plaintext highlighter-rouge">modular</code> to write a poem. The <a href="02_serving_api_layer__fastapi_app___routers__.md">Serving API Layer (FastAPI App &amp; Routers)</a> passes this to the <code class="language-plaintext highlighter-rouge">TokenGeneratorPipeline</code>.</p> </li> <li><strong>Pipeline Prepares and Sends to <code class="language-plaintext highlighter-rouge">EngineQueue</code></strong>: <ul> <li>The <code class="language-plaintext highlighter-rouge">TokenGeneratorPipeline</code> tokenizes the poem prompt (“Write a poem about a cat”).</li> <li>It now needs to send this to the <code class="language-plaintext highlighter-rouge">Model Worker</code>.</li> <li>It calls a method on the <code class="language-plaintext highlighter-rouge">EngineQueue</code> (like <code class="language-plaintext highlighter-rouge">stream()</code>), which internally puts the tokenized prompt and a unique request ID onto the <strong>request queue (<code class="language-plaintext highlighter-rouge">request_q</code>)</strong>.</li> </ul> </li> <li><strong>Model Worker’s Scheduler Picks Up the Task</strong>: <ul> <li>The <code class="language-plaintext highlighter-rouge">Scheduler</code> inside the <code class="language-plaintext highlighter-rouge">Model Worker</code> process is constantly watching the <strong>request queue (<code class="language-plaintext highlighter-rouge">request_q</code>)</strong>.</li> <li>It sees the new poem prompt, takes it off the queue, and prepares to feed it to the AI model.</li> </ul> </li> <li> <p><strong>Model Worker Generates Text</strong>: The AI model in the <code class="language-plaintext highlighter-rouge">Model Worker</code> starts generating the poem, token by token.</p> </li> <li><strong>Scheduler Sends Results via <code class="language-plaintext highlighter-rouge">EngineQueue</code></strong>: <ul> <li>As each token (e.g., “The”, “fluffy”, “cat”) is generated, the <code class="language-plaintext highlighter-rouge">Scheduler</code> takes this result.</li> <li>It puts the generated token (associated with the original request ID) onto the <strong>response queue (<code class="language-plaintext highlighter-rouge">response_q</code>)</strong>.</li> </ul> </li> <li><strong>Pipeline Receives Results</strong>: <ul> <li>Back in the main API server process, the <code class="language-plaintext highlighter-rouge">EngineQueue</code> (specifically, a helper task it runs called <code class="language-plaintext highlighter-rouge">response_worker</code>) is watching the <strong>response queue (<code class="language-plaintext highlighter-rouge">response_q</code>)</strong>.</li> <li>It sees the incoming tokens for the poem, takes them off the queue, and passes them to the correct part of the <code class="language-plaintext highlighter-rouge">TokenGeneratorPipeline</code> that is waiting for them.</li> <li>The <code class="language-plaintext highlighter-rouge">TokenGeneratorPipeline</code> then decodes these tokens back into text and sends the poem to the user.</li> </ul> </li> <li><strong>What if the User Cancels?</strong>: <ul> <li>If the user cancels the request while the poem is being generated, the <code class="language-plaintext highlighter-rouge">TokenGeneratorPipeline</code> can send a message with the request ID to the <strong>cancellation queue (<code class="language-plaintext highlighter-rouge">cancel_q</code>)</strong>.</li> <li>The <code class="language-plaintext highlighter-rouge">Scheduler</code> in the Model Worker checks this queue and, if it sees the cancellation, stops generating the poem.</li> </ul> </li> </ol> <p>This system ensures that the main server and the model worker can work independently but stay perfectly synchronized.</p> <h2 id="visualizing-the-flow"> <a href="#visualizing-the-flow" class="anchor-heading" aria-labelledby="visualizing-the-flow"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Visualizing the Flow </h2> <p>Here’s how data moves for a typical request:</p><pre><code class="language-mermaid">sequenceDiagram
    participant TGP as TokenGeneratorPipeline (Main Process)
    participant EngQ_Req as EngineQueue (request_q)
    participant Sched as Scheduler (Model Worker Process)
    participant AIModel as AI Model
    participant EngQ_Resp as EngineQueue (response_q)

    TGP-&gt;&gt;EngQ_Req: Put (Request ID, Tokenized Prompt)
    EngQ_Req--&gt;&gt;Sched: Get (Request ID, Tokenized Prompt)
    Sched-&gt;&gt;AIModel: Process Prompt
    AIModel--&gt;&gt;Sched: Generated Token(s)
    Sched-&gt;&gt;EngQ_Resp: Put (Request ID, Generated Token(s))
    EngQ_Resp--&gt;&gt;TGP: Get (Request ID, Generated Token(s))
    TGP-&gt;&gt;TGP: Decode tokens, send to user
</code></pre><h2 id="under-the-hood-key-code-aspects"> <a href="#under-the-hood-key-code-aspects" class="anchor-heading" aria-labelledby="under-the-hood-key-code-aspects"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Under the Hood: Key Code Aspects </h2> <p>The main logic for <code class="language-plaintext highlighter-rouge">EngineQueue</code> is in <code class="language-plaintext highlighter-rouge">src/max/serve/scheduler/queues.py</code>.</p> <h3 id="the-enginequeue-class"> <a href="#the-enginequeue-class" class="anchor-heading" aria-labelledby="the-enginequeue-class"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The <code class="language-plaintext highlighter-rouge">EngineQueue</code> Class </h3> <p>This class brings together the request, response, and cancellation queues.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified from: src/max/serve/scheduler/queues.py
</span>
<span class="k">class</span> <span class="nc">EngineQueue</span><span class="p">(</span><span class="n">Generic</span><span class="p">[</span><span class="n">ReqId</span><span class="p">,</span> <span class="n">ReqInput</span><span class="p">,</span> <span class="n">ReqOutput</span><span class="p">]):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">context</span><span class="p">:</span> <span class="n">multiprocessing</span><span class="p">.</span><span class="n">context</span><span class="p">.</span><span class="n">BaseContext</span><span class="p">,</span> <span class="c1"># For creating queues
</span>        <span class="n">worker_pc</span><span class="p">:</span> <span class="n">ProcessControl</span><span class="p">,</span> <span class="c1"># To monitor Model Worker health
</span>        <span class="n">queue_type</span><span class="p">:</span> <span class="n">QueueType</span> <span class="o">=</span> <span class="n">QueueType</span><span class="p">.</span><span class="n">ZMQ</span><span class="p">,</span> <span class="c1"># ZMQ or MP
</span>    <span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">request_q</span> <span class="o">=</span> <span class="n">create_queue</span><span class="p">(</span><span class="n">queue_type</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">response_q</span> <span class="o">=</span> <span class="n">create_queue</span><span class="p">(</span><span class="n">queue_type</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">cancel_q</span> <span class="o">=</span> <span class="n">create_queue</span><span class="p">(</span><span class="n">queue_type</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        
        <span class="c1"># For tracking responses to specific requests
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">pending_out_queues</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="n">ReqId</span><span class="p">,</span> <span class="n">asyncio</span><span class="p">.</span><span class="n">Queue</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">worker_pc</span> <span class="o">=</span> <span class="n">worker_pc</span> <span class="c1"># ProcessControl for Model Worker
</span>        <span class="c1"># ...
</span></code></pre></div></div> <ul> <li><code class="language-plaintext highlighter-rouge">context</code>: A multiprocessing context, used by <code class="language-plaintext highlighter-rouge">create_queue</code> to make either ZMQ or standard <code class="language-plaintext highlighter-rouge">multiprocessing.Queue</code> instances.</li> <li><code class="language-plaintext highlighter-rouge">worker_pc</code>: A <code class="language-plaintext highlighter-rouge">ProcessControl</code> object. <code class="language-plaintext highlighter-rouge">EngineQueue</code> uses this to check if the Model Worker process is still healthy.</li> <li><code class="language-plaintext highlighter-rouge">pending_out_queues</code>: This is a clever part! When <code class="language-plaintext highlighter-rouge">TokenGeneratorPipeline</code> sends a request, <code class="language-plaintext highlighter-rouge">EngineQueue</code> creates a temporary, in-memory <code class="language-plaintext highlighter-rouge">asyncio.Queue</code> just for that request’s responses. This dictionary maps the request ID to its dedicated response queue.</li> </ul> <h3 id="sending-a-request-the-stream-method"> <a href="#sending-a-request-the-stream-method" class="anchor-heading" aria-labelledby="sending-a-request-the-stream-method"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Sending a Request: The <code class="language-plaintext highlighter-rouge">stream</code> Method </h3> <p>When the <code class="language-plaintext highlighter-rouge">TokenGeneratorPipeline</code> wants to send a request and get a stream of responses, it uses <code class="language-plaintext highlighter-rouge">engine_queue.stream()</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified from: src/max/serve/scheduler/queues.py
</span>
    <span class="o">@</span><span class="n">contextlib</span><span class="p">.</span><span class="n">contextmanager</span>
    <span class="k">def</span> <span class="nf">open_channel</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">req_id</span><span class="p">:</span> <span class="n">ReqId</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">ReqInput</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="n">asyncio</span><span class="p">.</span><span class="n">Queue</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">]:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Create a temporary asyncio.Queue for this request's responses
</span>            <span class="n">out_queue</span><span class="p">:</span> <span class="n">asyncio</span><span class="p">.</span><span class="n">Queue</span> <span class="o">=</span> <span class="n">asyncio</span><span class="p">.</span><span class="n">Queue</span><span class="p">()</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">pending_out_queues</span><span class="p">[</span><span class="n">req_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">out_queue</span>
            
            <span class="c1"># Put the actual request onto the inter-process request_q
</span>            <span class="bp">self</span><span class="p">.</span><span class="n">request_q</span><span class="p">.</span><span class="n">put_nowait</span><span class="p">((</span><span class="n">req_id</span><span class="p">,</span> <span class="n">data</span><span class="p">))</span>
            <span class="k">yield</span> <span class="n">out_queue</span> <span class="c1"># The pipeline will listen to this out_queue
</span>        <span class="k">finally</span><span class="p">:</span>
            <span class="c1"># Clean up when done
</span>            <span class="k">del</span> <span class="bp">self</span><span class="p">.</span><span class="n">pending_out_queues</span><span class="p">[</span><span class="n">req_id</span><span class="p">]</span>

    <span class="k">async</span> <span class="k">def</span> <span class="nf">stream</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">req_id</span><span class="p">:</span> <span class="n">ReqId</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">ReqInput</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AsyncGenerator</span><span class="p">[</span><span class="n">ReqOutput</span><span class="p">,</span> <span class="bp">None</span><span class="p">]:</span>
        <span class="c1"># open_channel sets up the temporary queue and sends to request_q
</span>        <span class="k">with</span> <span class="bp">self</span><span class="p">.</span><span class="n">open_channel</span><span class="p">(</span><span class="n">req_id</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> <span class="k">as</span> <span class="n">queue_for_this_req</span><span class="p">:</span>
            <span class="c1"># Wait for items on the temporary queue
</span>            <span class="k">while</span> <span class="p">(</span><span class="n">item</span> <span class="p">:</span><span class="o">=</span> <span class="k">await</span> <span class="n">queue_for_this_req</span><span class="p">.</span><span class="n">get</span><span class="p">())</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">STOP_STREAM</span><span class="p">:</span>
                <span class="k">yield</span> <span class="n">item</span> <span class="c1"># Yield each response item
</span></code></pre></div></div> <ol> <li><code class="language-plaintext highlighter-rouge">open_channel</code> is a context manager. It: <ul> <li>Creates a standard <code class="language-plaintext highlighter-rouge">asyncio.Queue</code> (just for this one request, <code class="language-plaintext highlighter-rouge">req_id</code>).</li> <li>Stores this queue in <code class="language-plaintext highlighter-rouge">self.pending_out_queues</code> using <code class="language-plaintext highlighter-rouge">req_id</code> as the key.</li> <li>Puts the <code class="language-plaintext highlighter-rouge">(req_id, data)</code> tuple onto the actual <code class="language-plaintext highlighter-rouge">self.request_q</code> (which is an inter-process queue like ZMQ or <code class="language-plaintext highlighter-rouge">mp.Queue</code>).</li> <li><code class="language-plaintext highlighter-rouge">yield out_queue</code>: The <code class="language-plaintext highlighter-rouge">stream</code> method gets this temporary <code class="language-plaintext highlighter-rouge">out_queue</code>.</li> </ul> </li> <li>The <code class="language-plaintext highlighter-rouge">stream</code> method then asynchronously waits (<code class="language-plaintext highlighter-rouge">await queue_for_this_req.get()</code>) for responses to appear on this temporary <code class="language-plaintext highlighter-rouge">out_queue</code> and yields them one by one. <code class="language-plaintext highlighter-rouge">STOP_STREAM</code> is a special signal that means the response is finished.</li> </ol> <h3 id="receiving-responses-the-response_worker-method"> <a href="#receiving-responses-the-response_worker-method" class="anchor-heading" aria-labelledby="receiving-responses-the-response_worker-method"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Receiving Responses: The <code class="language-plaintext highlighter-rouge">response_worker</code> Method </h3> <p>So, who puts items onto that temporary <code class="language-plaintext highlighter-rouge">out_queue</code>? A helper method called <code class="language-plaintext highlighter-rouge">response_worker</code> does this. It runs as an asynchronous task within the main API server process (started by the <code class="language-plaintext highlighter-rouge">TokenGeneratorPipeline</code> when it initializes).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified from: src/max/serve/scheduler/queues.py
</span>
    <span class="k">async</span> <span class="k">def</span> <span class="nf">response_worker</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">while</span> <span class="bp">True</span><span class="p">:</span> <span class="c1"># Loop forever
</span>                <span class="c1"># Check if the Model Worker process is still healthy
</span>                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">is_worker_healthy</span><span class="p">():</span>
                    <span class="c1"># Handle error, maybe stop
</span>                    <span class="n">logger</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="s">"Model worker process is not healthy"</span><span class="p">)</span>
                    <span class="k">raise</span> <span class="nb">Exception</span><span class="p">(</span><span class="s">"Worker failed!"</span><span class="p">)</span>
                
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># Get a batch of responses from the inter-process response_q
</span>                    <span class="c1"># responses_batch is like: [{req_id1: token_A, req_id2: token_B}, ...]
</span>                    <span class="n">responses_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">response_q</span><span class="p">.</span><span class="n">get_nowait</span><span class="p">()</span>
                    
                    <span class="k">for</span> <span class="n">responses_in_item</span> <span class="ow">in</span> <span class="n">responses_batch</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">req_id</span><span class="p">,</span> <span class="n">response_data</span> <span class="ow">in</span> <span class="n">responses_in_item</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
                            <span class="c1"># Find the temporary asyncio.Queue for this req_id
</span>                            <span class="k">if</span> <span class="n">req_id</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">pending_out_queues</span><span class="p">:</span>
                                <span class="c1"># Put the response data onto that specific queue
</span>                                <span class="k">await</span> <span class="bp">self</span><span class="p">.</span><span class="n">pending_out_queues</span><span class="p">[</span><span class="n">req_id</span><span class="p">].</span><span class="n">put</span><span class="p">(</span><span class="n">response_data</span><span class="p">)</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="c1"># Request might have been cancelled or finished
</span>                                <span class="c1"># self.cancel_q.put_nowait([req_id]) # Example
</span>                                <span class="k">pass</span>
                <span class="k">except</span> <span class="n">queue</span><span class="p">.</span><span class="n">Empty</span><span class="p">:</span> <span class="c1"># queue is the standard Python queue module
</span>                    <span class="k">await</span> <span class="n">asyncio</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># brief pause if response_q is empty
</span>        <span class="k">finally</span><span class="p">:</span>
            <span class="n">logger</span><span class="p">.</span><span class="n">debug</span><span class="p">(</span><span class="s">"Response worker stopping."</span><span class="p">)</span>
</code></pre></div></div> <p>The <code class="language-plaintext highlighter-rouge">response_worker</code>:</p> <ol> <li>Continuously checks the main inter-process <code class="language-plaintext highlighter-rouge">self.response_q</code> for incoming messages from the Model Worker.</li> <li>When it gets a response, it looks up the <code class="language-plaintext highlighter-rouge">req_id</code> in <code class="language-plaintext highlighter-rouge">self.pending_out_queues</code> to find the specific <code class="language-plaintext highlighter-rouge">asyncio.Queue</code> created for that request.</li> <li>It then <code class="language-plaintext highlighter-rouge">put</code>s the <code class="language-plaintext highlighter-rouge">response_data</code> onto that <code class="language-plaintext highlighter-rouge">asyncio.Queue</code>.</li> <li>This wakes up the <code class="language-plaintext highlighter-rouge">stream()</code> method (which was <code class="language-plaintext highlighter-rouge">await</code>ing on that <code class="language-plaintext highlighter-rouge">asyncio.Queue</code>), allowing it to yield the response to the <code class="language-plaintext highlighter-rouge">TokenGeneratorPipeline</code>. It also includes important health checks for the Model Worker using <code class="language-plaintext highlighter-rouge">self.is_worker_healthy()</code>.</li> </ol> <h3 id="the-actual-queue-implementations-maxqueue-mpqueue-zmqqueue"> <a href="#the-actual-queue-implementations-maxqueue-mpqueue-zmqqueue" class="anchor-heading" aria-labelledby="the-actual-queue-implementations-maxqueue-mpqueue-zmqqueue"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Actual Queue Implementations: <code class="language-plaintext highlighter-rouge">MaxQueue</code>, <code class="language-plaintext highlighter-rouge">MpQueue</code>, <code class="language-plaintext highlighter-rouge">ZmqQueue</code> </h3> <p><code class="language-plaintext highlighter-rouge">EngineQueue</code> uses an abstraction called <code class="language-plaintext highlighter-rouge">MaxQueue</code> (<code class="language-plaintext highlighter-rouge">src/max/serve/scheduler/max_queue.py</code>) which defines a common interface (<code class="language-plaintext highlighter-rouge">put_nowait</code>, <code class="language-plaintext highlighter-rouge">get_nowait</code>, <code class="language-plaintext highlighter-rouge">qsize</code>, <code class="language-plaintext highlighter-rouge">empty</code>). Then, <code class="language-plaintext highlighter-rouge">modular</code> provides concrete implementations:</p> <ul> <li><strong><code class="language-plaintext highlighter-rouge">MpQueue</code> (<code class="language-plaintext highlighter-rouge">src/max/serve/scheduler/mp_queue.py</code>)</strong>: This is a wrapper around Python’s standard <code class="language-plaintext highlighter-rouge">multiprocessing.Queue</code>. <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified from: src/max/serve/scheduler/mp_queue.py
</span><span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="kn">import</span> <span class="n">context</span><span class="p">,</span> <span class="n">queues</span>
<span class="kn">import</span> <span class="nn">queue</span> <span class="c1"># Standard Python queue module for exceptions
</span>    
<span class="k">class</span> <span class="nc">MpQueue</span><span class="p">(</span><span class="n">MaxQueue</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctx</span><span class="p">:</span> <span class="n">context</span><span class="p">.</span><span class="n">BaseContext</span><span class="p">,</span> <span class="p">...):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">queue</span><span class="p">:</span> <span class="n">queues</span><span class="p">.</span><span class="n">Queue</span> <span class="o">=</span> <span class="n">ctx</span><span class="p">.</span><span class="n">Queue</span><span class="p">(...)</span> <span class="c1"># Creates a multiprocessing.Queue
</span>        <span class="c1"># self.counter = AtomicInt(ctx, 0) # For qsize on macOS
</span>        <span class="p">...</span>

    <span class="k">def</span> <span class="nf">get_nowait</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># x = self.queue.get(block=False) # Attempt to get immediately
</span>            <span class="c1"># self.counter.dec()
</span>            <span class="c1"># return x
</span>            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">queue</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">block</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mf">0.005</span><span class="p">)</span> <span class="c1"># Small timeout
</span>        <span class="k">except</span> <span class="n">queue</span><span class="p">.</span><span class="n">Empty</span><span class="p">:</span> <span class="c1"># Catches standard queue.Empty
</span>            <span class="k">raise</span> <span class="n">queue</span><span class="p">.</span><span class="n">Empty</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">put_nowait</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># self.queue.put(item, block=False) # Attempt to put immediately
</span>        <span class="c1"># self.counter.inc()
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">queue</span><span class="p">.</span><span class="n">put</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">block</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div> </div> <p>It uses the standard <code class="language-plaintext highlighter-rouge">ctx.Queue()</code> to create the underlying inter-process queue.</p> </li> <li><strong><code class="language-plaintext highlighter-rouge">ZmqQueue</code> (<code class="language-plaintext highlighter-rouge">src/max/serve/scheduler/zmq_queue.py</code>)</strong>: This uses ZeroMQ sockets for potentially higher performance. <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simplified from: src/max/serve/scheduler/zmq_queue.py
</span><span class="kn">import</span> <span class="nn">zmq</span> <span class="c1"># ZeroMQ library
</span><span class="kn">import</span> <span class="nn">queue</span> <span class="c1"># Standard Python queue module for exceptions
</span>
<span class="k">class</span> <span class="nc">ZmqQueue</span><span class="p">(</span><span class="n">MaxQueue</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="p">...):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">zmq_ipc_path</span> <span class="o">=</span> <span class="n">_generate_zmq_ipc_path</span><span class="p">()</span> <span class="c1"># e.g., "ipc:///tmp/some-uuid"
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">zmq_pull_socket</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">zmq</span><span class="p">.</span><span class="n">Socket</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># For receiving
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">zmq_push_socket</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">zmq</span><span class="p">.</span><span class="n">Socket</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># For sending
</span>        <span class="c1"># ... (counter for qsize)
</span>    
    <span class="k">def</span> <span class="nf">_get_or_init_pull_socket</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">zmq</span><span class="p">.</span><span class="n">Socket</span><span class="p">:</span>
        <span class="c1"># Creates/returns a ZMQ PULL socket connected to zmq_ipc_path
</span>        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">zmq_pull_socket</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="c1"># zmq_ctx = self._get_or_init_zmq_ctx() # Gets a ZMQ context
</span>            <span class="c1"># self.zmq_pull_socket = _open_zmq_socket(zmq_ctx, self.zmq_ipc_path, zmq.PULL)
</span>            <span class="k">pass</span> <span class="c1"># Simplified
</span>        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">zmq_pull_socket</span>

    <span class="k">def</span> <span class="nf">_get_or_init_push_socket</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">zmq</span><span class="p">.</span><span class="n">Socket</span><span class="p">:</span>
        <span class="c1"># Creates/returns a ZMQ PUSH socket bound to zmq_ipc_path
</span>        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">zmq_push_socket</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">pass</span> <span class="c1"># Simplified
</span>        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">zmq_push_socket</span>

    <span class="k">def</span> <span class="nf">get_nowait</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="c1"># pull_socket = self._get_or_init_pull_socket()
</span>        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># return pull_socket.recv_pyobj(flags=zmq.NOBLOCK) # Receive Python object
</span>            <span class="k">pass</span> <span class="c1"># Simplified - actual call to ZMQ
</span>        <span class="k">except</span> <span class="n">zmq</span><span class="p">.</span><span class="n">ZMQError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">e</span><span class="p">.</span><span class="n">errno</span> <span class="o">==</span> <span class="n">zmq</span><span class="p">.</span><span class="n">EAGAIN</span><span class="p">:</span> <span class="c1"># Means no message waiting
</span>                <span class="k">raise</span> <span class="n">queue</span><span class="p">.</span><span class="n">Empty</span><span class="p">()</span>
            <span class="k">raise</span> <span class="c1"># Other ZMQ error
</span>    
    <span class="k">def</span> <span class="nf">put_nowait</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># push_socket = self._get_or_init_push_socket()
</span>        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># push_socket.send_pyobj(item, flags=zmq.NOBLOCK) # Send Python object
</span>            <span class="k">pass</span> <span class="c1"># Simplified - actual call to ZMQ
</span>        <span class="k">except</span> <span class="n">zmq</span><span class="p">.</span><span class="n">ZMQError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">e</span><span class="p">.</span><span class="n">errno</span> <span class="o">==</span> <span class="n">zmq</span><span class="p">.</span><span class="n">EAGAIN</span><span class="p">:</span> <span class="c1"># Means send buffer is full (or receiver not ready)
</span>                <span class="c1"># ZmqQueue might retry or raise queue.Full() here
</span>                <span class="k">pass</span>
            <span class="k">raise</span> <span class="c1"># Other ZMQ error
</span></code></pre></div> </div> <p>ZMQ uses a “socket” paradigm. One end creates a <code class="language-plaintext highlighter-rouge">PUSH</code> socket and sends messages. The other end creates a <code class="language-plaintext highlighter-rouge">PULL</code> socket and receives them. <code class="language-plaintext highlighter-rouge">_generate_zmq_ipc_path()</code> creates a unique file system path that ZMQ uses for local inter-process communication.</p> </li> </ul> <p>The choice between <code class="language-plaintext highlighter-rouge">QueueType.ZMQ</code> and <code class="language-plaintext highlighter-rouge">QueueType.MP</code> is typically determined by settings loaded from the <a href="01_settings___settings__class__.md">Settings (<code class="language-plaintext highlighter-rouge">Settings</code> class)</a> when <code class="language-plaintext highlighter-rouge">modular</code> starts.</p> <h2 id="why-different-queue-types"> <a href="#why-different-queue-types" class="anchor-heading" aria-labelledby="why-different-queue-types"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Why Different Queue Types? </h2> <ul> <li><strong><code class="language-plaintext highlighter-rouge">multiprocessing.Queue</code> (<code class="language-plaintext highlighter-rouge">MP</code>)</strong>: <ul> <li><strong>Pros</strong>: Built into Python, easy to use, no external dependencies. Generally reliable for many use cases.</li> <li><strong>Cons</strong>: Can sometimes have performance limitations with very high throughput or very large messages due to its underlying implementation (often uses pipes and pickling).</li> </ul> </li> <li><strong>ZeroMQ (<code class="language-plaintext highlighter-rouge">ZMQ</code>)</strong>: <ul> <li><strong>Pros</strong>: Designed for high-performance messaging. Can handle large volumes of data and high message rates more efficiently. Offers more advanced messaging patterns (though <code class="language-plaintext highlighter-rouge">modular</code> uses a simple PUSH/PULL here).</li> <li><strong>Cons</strong>: Adds an external dependency (the <code class="language-plaintext highlighter-rouge">pyzmq</code> library and its underlying C library). Can be slightly more complex to set up and debug.</li> </ul> </li> </ul> <p><code class="language-plaintext highlighter-rouge">modular</code> provides both options to allow users to choose based on their specific performance needs and deployment environment. For many typical scenarios, <code class="language-plaintext highlighter-rouge">multiprocessing.Queue</code> is sufficient. For demanding, high-throughput applications, ZMQ might offer an edge.</p> <h2 id="conclusion"> <a href="#conclusion" class="anchor-heading" aria-labelledby="conclusion"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Conclusion </h2> <p>The <code class="language-plaintext highlighter-rouge">EngineQueue</code> is the vital communication backbone that enables the main API server process and the separate Model Worker process to work together seamlessly. It acts like a sophisticated pneumatic tube system, with dedicated queues for requests, responses, and cancellation signals.</p> <p>By abstracting the underlying queue technology (be it standard multiprocessing queues or high-performance ZMQ), <code class="language-plaintext highlighter-rouge">EngineQueue</code> ensures reliable and efficient message passing. This separation allows the API server to remain responsive while the Model Worker crunches through demanding AI tasks.</p> <p>Now that we’ve seen how different parts of <code class="language-plaintext highlighter-rouge">modular</code> communicate, how do we keep an eye on what’s happening inside? How do we measure performance and gather diagnostic information? That’s where our next chapter comes in: <a href="08_telemetry_and_metrics___metrics____metricclient___.md">Telemetry and Metrics (<code class="language-plaintext highlighter-rouge">METRICS</code>, <code class="language-plaintext highlighter-rouge">MetricClient</code>)</a>.</p><hr /> <p>Generated by <a href="https://github.com/The-Pocket/Tutorial-Codebase-Knowledge">AI Codebase Knowledge Builder</a></p> </main> <hr> <footer> <p class="text-small text-grey-dk-100 mb-0">Copyright &copy; 2023 Sam Kirk</p> </footer> </div> </div> <div class="search-overlay"></div> </div> <script type="module"> import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.6.0/dist/mermaid.esm.min.mjs'; var config = {} ; mermaid.initialize(config); mermaid.run({ querySelector: '.language-mermaid', }); </script> </body> </html>
